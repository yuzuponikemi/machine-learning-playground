# 拡散モデル学習カリキュラム計画

## 📚 概要

このカリキュラムは、機械学習の基礎を学習済みの学習者が、生成モデルの理論から始めて最終的にStable Diffusionのような画像生成AIを理解・実装できるようになることを目指します。

### 学習の流れ

```
正規分布 → 最尤推定 → 多次元正規分布 → 混合ガウスモデル → EMアルゴリズム
    ↓
PyTorch基礎 → VAE → 拡散モデル理論 → 拡散モデル実装 → 応用
```

### 特徴

- ✅ **15個の包括的なノートブック**: 確率統計の基礎から最新の拡散モデルまで
- ✅ **PyTorchベース**: 実践的なディープラーニング実装
- ✅ **段階的な学習**: 小さな学びを積み重ねながらステップアップ
- ✅ **理論と実装のバランス**: 数学的背景と実装コードの両方を提供
- ✅ **視覚的な理解**: 豊富な可視化で直感的に理解

---

## 🎯 前提知識

このカリキュラムを始める前に、以下の知識があることが推奨されます：

- ✅ Pythonプログラミングの基礎
- ✅ NumPy、Matplotlibの基本的な使い方
- ✅ 機械学習の基本概念（回帰、分類、訓練・テストデータ）
- ✅ 基礎的な数学（微分、行列計算、確率の基本）

**推奨**: このリポジトリのノートブック00-12（機械学習基礎コース）を完了していること

---

## 📖 カリキュラム詳細

### Phase 1: 確率統計の基礎（推定時間: 10-12時間）

#### Notebook 30: 正規分布と確率の基礎
**ファイル名**: `notebooks/generative/30_probability_and_normal_distribution_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★☆☆☆（初級） |
| **カテゴリ** | 基礎 |

**📋 学習目標**
- [ ] 確率変数と確率分布の概念を理解できる
- [ ] 正規分布の確率密度関数を説明できる
- [ ] 期待値と分散を計算できる
- [ ] 中心極限定理を実験で確認できる
- [ ] Pythonで正規分布を扱えるようになる

**🎓 主な内容**
1. 確率の基礎
   - 確率変数と確率分布
   - 離散分布と連続分布
   - 期待値と分散の定義
2. 正規分布
   - 確率密度関数の式と意味
   - パラメータ（平均μ、標準偏差σ）の役割
   - Pythonでの実装（scipy.stats）
3. 中心極限定理
   - 定理の説明と重要性
   - 様々な分布での実験
   - サンプル和の確率分布
4. 実世界での応用
   - 身長、体重などの自然現象
   - 測定誤差のモデリング

**📊 実装内容**
```python
# 正規分布の可視化
# 中心極限定理の実験
# 様々なパラメータでの正規分布の比較
```

---

#### Notebook 31: 最尤推定と生成モデルの基礎
**ファイル名**: `notebooks/generative/31_maximum_likelihood_estimation_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★★☆☆（中級） |
| **カテゴリ** | 基礎 |

**📋 学習目標**
- [ ] 生成モデルの概念を理解できる
- [ ] 母集団とサンプルの違いを説明できる
- [ ] 最尤推定の理論を理解できる
- [ ] 正規分布のパラメータを推定できる
- [ ] 生成モデルで新しいデータを生成できる

**🎓 主な内容**
1. 生成モデルの概要
   - 生成モデルとは何か
   - 識別モデルとの違い
   - 母集団とサンプル
2. 実データを使った生成モデル
   - 身長データセットの分析
   - 正規分布によるモデリング
3. 最尤推定の理論
   - 尤度関数の定義
   - 対数尤度の最大化
   - 微分を使った最適化
   - 正規分布の最尤推定の導出
4. 生成モデルの用途
   - 新しいデータの生成
   - 異常検知（確率の計算）
   - データ拡張

**📊 実装内容**
```python
# 実データからのパラメータ推定
# 最尤推定の実装
# 生成モデルによるデータ生成
# 尤度の可視化
```

---

#### Notebook 32: 多次元正規分布と共分散
**ファイル名**: `notebooks/generative/32_multivariate_normal_distribution_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★★☆☆（中級） |
| **カテゴリ** | 基礎 |

**📋 学習目標**
- [ ] 多次元配列とベクトル演算を使いこなせる
- [ ] 多次元正規分布の式を理解できる
- [ ] 共分散行列の意味を説明できる
- [ ] 2次元正規分布を可視化できる
- [ ] 多次元データの最尤推定ができる

**🎓 主な内容**
1. NumPyと多次元配列
   - 多次元配列の基礎
   - 要素ごとの演算
   - ベクトルの内積と行列積
   - ブロードキャスティング
2. 多次元正規分布
   - 確率密度関数の式
   - 平均ベクトルと共分散行列
   - Pythonでの実装
3. 2次元正規分布の可視化
   - 3Dグラフの描画
   - 等高線プロット
   - 共分散行列と分布の形状の関係
4. 多次元正規分布の最尤推定
   - パラメータの推定式
   - 実データでの推定
   - 身長・体重データの分析

**📊 実装内容**
```python
# 多次元正規分布の実装
# 3D可視化と等高線プロット
# 共分散行列の効果の視覚化
# 実データでの最尤推定
```

---

### Phase 2: 混合モデルと最適化（推定時間: 8-10時間）

#### Notebook 33: 混合ガウスモデル（GMM）
**ファイル名**: `notebooks/generative/33_gaussian_mixture_models_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★★☆☆（中級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] 多峰性分布の概念を理解できる
- [ ] 混合ガウスモデル（GMM）の式を説明できる
- [ ] GMMでデータを生成できる
- [ ] GMMのパラメータ推定の難しさを理解できる

**🎓 主な内容**
1. 多峰性分布
   - 単峰性 vs 多峰性
   - 実世界の多峰性分布の例
   - データセットの作成
2. GMMによるデータ生成
   - 混合係数の概念
   - 複数の正規分布の組み合わせ
   - データ生成プロセスの実装
3. GMMの数式
   - 条件付き確率と周辺確率の復習
   - GMMの確率密度関数
   - 潜在変数の導入
4. パラメータ推定の難所
   - 単純な最尤推定が困難な理由
   - EMアルゴリズムの必要性

**📊 実装内容**
```python
# 多峰性データの生成
# GMMの実装
# 様々な混合数での実験
# パラメータの影響の可視化
```

---

#### Notebook 34: EMアルゴリズム
**ファイル名**: `notebooks/generative/34_expectation_maximization_algorithm_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 150-180分 |
| **難易度** | ★★★★☆（上級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] KLダイバージェンスの概念を理解できる
- [ ] ELBO（エビデンスの下界）を説明できる
- [ ] EMアルゴリズムの導出を理解できる
- [ ] GMMにEMアルゴリズムを適用できる
- [ ] EMアルゴリズムを実装できる

**🎓 主な内容**
1. KLダイバージェンス
   - 確率分布間の距離
   - KLダイバージェンスの定義
   - 最尤推定との関係
2. EMアルゴリズムの導出①
   - 潜在変数を持つモデル
   - 任意の確率分布q(z)の導入
3. EMアルゴリズムの導出②
   - ELBO（Evidence Lower BOund）
   - Eステップ: 事後確率の計算
   - Mステップ: パラメータの更新
   - 対数尤度の単調増加性の証明
4. GMMへの適用
   - EステップとMステップの具体的な式
   - 責任率（responsibility）の計算
5. 実装と実験
   - EMアルゴリズムの完全実装
   - 収束の可視化
   - クラスタリング結果の評価

**📊 実装内容**
```python
# KLダイバージェンスの計算と可視化
# EMアルゴリズムの実装
# GMMの学習過程の可視化
# 様々な初期値での実験
```

---

### Phase 3: PyTorchとニューラルネットワーク（推定時間: 8-10時間）

#### Notebook 35: PyTorch基礎と勾配法
**ファイル名**: `notebooks/generative/35_pytorch_fundamentals_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★☆☆☆（初級） |
| **カテゴリ** | 基礎 |

**📋 学習目標**
- [ ] PyTorchのテンソル演算を使いこなせる
- [ ] 自動微分の仕組みを理解できる
- [ ] 勾配降下法を実装できる
- [ ] 線形回帰をPyTorchで実装できる
- [ ] オプティマイザを使ってパラメータを更新できる

**🎓 主な内容**
1. PyTorchの基礎
   - PyTorchのインストール
   - テンソルの作成と演算
   - NumPyとの相互変換
   - GPU vs CPU
2. 自動微分と勾配法
   - autograd の仕組み
   - 勾配の計算
   - 勾配降下法の実装
3. 線形回帰
   - トイ・データセットの作成
   - 損失関数（MSE）
   - 勾配降下法での最適化
4. PyTorchのモジュール
   - nn.Parameter と nn.Module
   - オプティマイザ（SGD, Adam）
   - 学習ループの実装

**📊 実装内容**
```python
# テンソル演算の練習
# 自動微分のデモ
# 線形回帰の実装（スクラッチ）
# nn.Module を使った実装
# オプティマイザの比較
```

---

#### Notebook 36: ニューラルネットワークとMNIST
**ファイル名**: `notebooks/generative/36_neural_networks_mnist_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★★☆☆（中級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] 多層パーセプトロンを実装できる
- [ ] 活性化関数の役割を理解できる
- [ ] MNISTデータセットを扱えるようになる
- [ ] DataLoaderを使ってバッチ学習ができる
- [ ] 学習曲線を可視化して過学習を検出できる

**🎓 主な内容**
1. ニューラルネットワークの基礎
   - 線形変換と活性化関数
   - ReLU、Sigmoid、Tanh の比較
   - 多層構造の実装
2. 非線形データセット
   - XORデータセットでの実験
   - 決定境界の可視化
   - 層数と性能の関係
3. torchvisionとMNIST
   - torchvisionのインストール
   - MNISTデータセットの読み込み
   - データの前処理と正規化
   - DataLoaderの使い方
4. 画像分類モデル
   - CNNを使わないMLPでの分類
   - 訓練ループの実装
   - 検証データでの評価
   - 学習曲線の可視化

**📊 実装内容**
```python
# 活性化関数の比較
# XORデータセットでの実験
# MNISTデータローダの実装
# MLPによる画像分類
# 学習過程の可視化
```

---

### Phase 4: 変分オートエンコーダ（推定時間: 6-8時間）

#### Notebook 37: 変分オートエンコーダ（VAE）の理論
**ファイル名**: `notebooks/generative/37_variational_autoencoder_theory_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 120-150分 |
| **難易度** | ★★★★☆（上級） |
| **カテゴリ** | 理論 |

**📋 学習目標**
- [ ] VAEとGMMの関係を理解できる
- [ ] エンコーダとデコーダの役割を説明できる
- [ ] VAEのELBOを導出できる
- [ ] 変数変換トリック（reparameterization trick）を理解できる
- [ ] VAEがなぜ生成モデルとして機能するかを説明できる

**🎓 主な内容**
1. VAEとデコーダ
   - 1つの正規分布による生成モデル
   - GMMによる生成モデル
   - VAE: ニューラルネットワークによる無限混合モデル
   - デコーダ p(x|z) の役割
2. VAEとエンコーダ
   - EMアルゴリズムの限界
   - エンコーダ q(z|x) による近似
   - アモータイズされた推論
3. ELBOの最適化
   - VAEの目的関数
   - 再構成誤差 + KL正則化項
   - 変数変換トリック
   - 勾配の逆伝播
4. VAEの幾何学的解釈
   - 潜在空間の可視化
   - 滑らかな補間
   - 潜在変数の意味

**📊 実装内容**
```python
# GMMとVAEの対応の図解
# ELBOの各項の計算
# 変数変換トリックのデモ
# 概念図の可視化
```

---

#### Notebook 38: 変分オートエンコーダ（VAE）の実装
**ファイル名**: `notebooks/generative/38_variational_autoencoder_implementation_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 150-180分 |
| **難易度** | ★★★★☆（上級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] VAEのエンコーダとデコーダを実装できる
- [ ] ELBO損失関数を実装できる
- [ ] MNISTでVAEを訓練できる
- [ ] 潜在空間を可視化できる
- [ ] VAEで新しい画像を生成できる

**🎓 主な内容**
1. VAEアーキテクチャ
   - エンコーダネットワーク（x → μ, σ）
   - サンプリング層
   - デコーダネットワーク（z → x'）
2. 損失関数の実装
   - 再構成誤差（BCE or MSE）
   - KLダイバージェンス項
   - β-VAE（KL項の重み付け）
3. 訓練と評価
   - 訓練ループの実装
   - 再構成画像の可視化
   - 損失の推移
4. 潜在空間の探索
   - 2次元潜在空間の可視化
   - 潜在空間での補間
   - 潜在変数の算術演算
5. 新しい画像の生成
   - ランダムサンプリング
   - 条件付き生成の試み

**📊 実装内容**
```python
# VAEの完全実装
# MNISTでの訓練
# 再構成画像の比較
# 潜在空間の可視化
# 新しい画像の生成
# 潜在空間での補間
```

---

### Phase 5: 拡散モデルの理論（推定時間: 8-10時間）

#### Notebook 39: 拡散モデルの理論（基礎編）
**ファイル名**: `notebooks/generative/39_diffusion_models_theory_basics_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 150-180分 |
| **難易度** | ★★★★☆（上級） |
| **カテゴリ** | 理論 |

**📋 学習目標**
- [ ] VAEから拡散モデルへの発展を理解できる
- [ ] 拡散過程（forward process）を説明できる
- [ ] 逆拡散過程（reverse process）を説明できる
- [ ] 拡散モデルの直感的な理解を得る

**🎓 主な内容**
1. VAEから拡散モデルへ
   - VAEの復習（1層の潜在変数）
   - 階層型VAE（多層の潜在変数）
   - マルコフ連鎖としての拡散過程
2. 拡散過程（Forward Process）
   - q(x_t | x_{t-1}) の定義
   - ガウスノイズの段階的な追加
   - T ステップ後の完全なノイズ
3. 逆拡散過程（Reverse Process）
   - p(x_{t-1} | x_t) の定義
   - ノイズ除去のプロセス
   - ニューラルネットワークによる学習
4. 拡散モデルの直感
   - なぜ段階的にノイズを除去するのか
   - スコアベース生成モデルとの関係
   - 視覚的な理解

**📊 実装内容**
```python
# 拡散過程の可視化（画像へのノイズ追加）
# 各タイムステップでの画像の変化
# ノイズスケジュールの比較
# 概念図のアニメーション
```

---

#### Notebook 40: 拡散モデルの理論（ELBO導出編）
**ファイル名**: `notebooks/generative/40_diffusion_models_theory_elbo_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 180-240分 |
| **難易度** | ★★★★★（最上級） |
| **カテゴリ** | 理論 |

**📋 学習目標**
- [ ] 拡散モデルのELBOを導出できる
- [ ] q(x_t | x_0) の閉形式を導出できる
- [ ] q(x_{t-1} | x_t, x_0) の式を理解できる
- [ ] 簡略化された訓練目標を理解できる

**🎓 主な内容**
1. ELBOの計算①
   - 拡散モデルの対数尤度
   - ELBOの式展開
   - T個の項への分解
2. ELBOの計算②
   - q(x_t | x_0) の導出
   - α_t, β_t の定義
   - 任意のタイムステップでのノイズ追加
3. ELBOの計算③
   - q(x_{t-1} | x_t, x_0) の導出
   - ベイズの定理の適用
   - 正規分布の積の計算
4. 簡略化された目標関数
   - ノイズ予測としての定式化
   - L_simple の導出
   - 実装上の利点

**📊 実装内容**
```python
# q(x_t | x_0) の検証
# ノイズスケジュールの効果
# q(x_{t-1} | x_t, x_0) の可視化
# 各損失項の計算と比較
```

---

### Phase 6: 拡散モデルの実装（推定時間: 10-12時間）

#### Notebook 41: U-Netと位置エンコーディング
**ファイル名**: `notebooks/generative/41_unet_positional_encoding_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 150-180分 |
| **難易度** | ★★★★☆（上級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] U-Netアーキテクチャを理解できる
- [ ] U-Netを実装できる
- [ ] 正弦波位置エンコーディングを理解できる
- [ ] タイムステップ情報をネットワークに組み込める

**🎓 主な内容**
1. U-Net
   - U-Netの構造（エンコーダ・デコーダ + スキップ接続）
   - なぜ画像生成にU-Netを使うのか
   - ダウンサンプリングとアップサンプリング
   - U-Netの実装（PyTorch）
2. 正弦波位置エンコーディング
   - Transformerでの位置エンコーディング
   - 拡散モデルでのタイムステップエンコーディング
   - sin/cosを使った埋め込み
   - 実装と可視化
3. U-Netへの統合
   - タイムステップの埋め込み
   - 特徴マップへの加算
   - 完全なU-Netの実装

**📊 実装内容**
```python
# U-Netブロックの実装
# エンコーダ・デコーダの実装
# 正弦波位置エンコーディングの実装
# タイムステップ埋め込みの可視化
# 完全なU-Netの動作確認
```

---

#### Notebook 42: 拡散モデルの実装（基礎編）
**ファイル名**: `notebooks/generative/42_diffusion_model_implementation_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 180-240分 |
| **難易度** | ★★★★★（最上級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] 拡散過程を実装できる
- [ ] 逆拡散過程を実装できる
- [ ] ノイズ予測モデルを訓練できる
- [ ] 拡散モデルで画像を生成できる

**🎓 主な内容**
1. 拡散過程の実装
   - q(x_t | x_{t-1}) からのサンプリング
   - q(x_t | x_0) からのサンプリング
   - ノイズスケジュールの実装
   - Diffuser クラスの実装
2. ノイズ予測モデル
   - U-Netをノイズ予測器として使用
   - 入力: x_t, t → 出力: ε_θ(x_t, t)
   - 損失関数: MSE(ε, ε_θ)
3. 訓練ループ
   - ランダムなタイムステップでの訓練
   - バッチごとのノイズ追加
   - モデルの更新
   - 損失の記録
4. サンプリング（画像生成）
   - ワンステップのデノイズ処理
   - T ステップの反復
   - 生成画像の可視化
5. MNISTでの実験
   - データローダの準備
   - 訓練の実行
   - 生成品質の評価

**📊 実装内容**
```python
# 拡散過程の実装
# ノイズスケジュールの比較
# 訓練ループの実装
# サンプリングアルゴリズムの実装
# 生成画像の評価
# 訓練過程のアニメーション
```

---

#### Notebook 43: 拡散モデルの学習と評価
**ファイル名**: `notebooks/generative/43_diffusion_model_training_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 180-240分 |
| **難易度** | ★★★★★（最上級） |
| **カテゴリ** | 実践 |

**📋 学習目標**
- [ ] 拡散モデルを本格的に訓練できる
- [ ] ハイパーパラメータをチューニングできる
- [ ] 生成品質を評価できる
- [ ] より大きなデータセットで実験できる

**🎓 主な内容**
1. 訓練の最適化
   - バッチサイズの調整
   - 学習率のスケジューリング
   - EMAによるパラメータの平滑化
   - チェックポイントの保存
2. ハイパーパラメータ
   - ノイズスケジュールの選択（linear, cosine）
   - タイムステップ数 T
   - モデルのサイズ
   - 訓練エポック数
3. 評価指標
   - 再構成誤差
   - FID（Fréchet Inception Distance）
   - IS（Inception Score）
   - 視覚的な評価
4. 実験
   - MNIST, Fashion-MNIST での訓練
   - CIFAR-10への挑戦（optional）
   - 生成画像の多様性の確認
   - タイムステップごとの画像の変化

**📊 実装内容**
```python
# 最適化されたトレーニングループ
# EMAの実装
# 各種評価指標の実装
# 複数データセットでの実験
# 生成過程のアニメーション
# ハイパーパラメータの比較
```

---

### Phase 7: 拡散モデルの応用（推定時間: 8-10時間）

#### Notebook 44: 条件付き拡散モデル
**ファイル名**: `notebooks/generative/44_conditional_diffusion_models_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 150-180分 |
| **難易度** | ★★★★☆（上級） |
| **カテゴリ** | 応用 |

**📋 学習目標**
- [ ] 条件付き生成モデルの概念を理解できる
- [ ] クラスラベルを条件として組み込める
- [ ] 条件付き拡散モデルを実装できる
- [ ] 指定したクラスの画像を生成できる

**🎓 主な内容**
1. 条件付き生成
   - 無条件生成 vs 条件付き生成
   - p(x|y) のモデリング
   - 条件の種類（クラス、テキスト、画像）
2. クラス条件付き拡散モデル
   - クラスラベルの埋め込み
   - U-Netへの条件の組み込み
   - ε_θ(x_t, t, y) の実装
3. 訓練と生成
   - 条件付き訓練
   - 条件を指定した生成
   - クラスごとの生成品質
4. 実験
   - MNIST（10クラス）での実験
   - クラスごとの可視化
   - 条件の有無での比較

**📊 実装内容**
```python
# クラス埋め込み層の実装
# 条件付きU-Netの実装
# 条件付き訓練ループ
# 指定クラスの画像生成
# クラス別の生成結果の比較
```

---

#### Notebook 45: ガイダンスとStable Diffusion
**ファイル名**: `notebooks/generative/45_guidance_stable_diffusion_v1.ipynb`

| 項目 | 内容 |
|------|------|
| **推定学習時間** | 180-240分 |
| **難易度** | ★★★★★（最上級） |
| **カテゴリ** | 応用 |

**📋 学習目標**
- [ ] スコア関数の概念を理解できる
- [ ] 分類器ガイダンスを説明できる
- [ ] 分類器なしガイダンス（CFG）を実装できる
- [ ] Stable Diffusionの仕組みを理解できる
- [ ] Diffusersライブラリを使えるようになる

**🎓 主な内容**
1. スコア関数
   - スコアベース生成モデル
   - ∇_x log p(x) の意味
   - 拡散モデルとスコアマッチングの関係
2. 分類器ガイダンス
   - 分類器 p(y|x) の利用
   - 条件付きスコアの計算
   - ガイダンススケール w
3. 分類器なしガイダンス（CFG）
   - 分類器不要の条件付き生成
   - 条件付きと無条件の線形結合
   - CFGの実装
   - ガイダンス強度の効果
4. Stable Diffusion
   - Latent Diffusion Model の概念
   - VAEエンコーダ・デコーダ
   - CLIPテキストエンコーダ
   - U-Netの構造
   - アテンションメカニズム
5. Diffusersライブラリ
   - Hugging Face Diffusers の紹介
   - Stable Diffusionの実行
   - テキストから画像生成
   - パラメータのカスタマイズ

**📊 実装内容**
```python
# スコア関数の可視化
# 分類器ガイダンスの実装
# CFGの実装
# ガイダンス強度の比較
# Diffusersライブラリの使用
# Stable Diffusionでの画像生成
# カスタムプロンプトでの実験
```

---

## 📊 カリキュラム全体のまとめ

### 学習時間の見積もり

| Phase | ノートブック数 | 推定時間 | 累計時間 |
|-------|--------------|----------|----------|
| Phase 1: 確率統計の基礎 | 3 | 10-12時間 | 10-12時間 |
| Phase 2: 混合モデルと最適化 | 2 | 8-10時間 | 18-22時間 |
| Phase 3: PyTorchとNN | 2 | 8-10時間 | 26-32時間 |
| Phase 4: VAE | 2 | 6-8時間 | 32-40時間 |
| Phase 5: 拡散モデル理論 | 2 | 8-10時間 | 40-50時間 |
| Phase 6: 拡散モデル実装 | 3 | 10-12時間 | 50-62時間 |
| Phase 7: 応用 | 2 | 8-10時間 | 58-72時間 |
| **合計** | **16** | **58-72時間** | **2-3ヶ月** |

### 難易度分布

| 難易度 | ノートブック数 | 割合 |
|--------|--------------|------|
| ★★☆☆☆（初級） | 2 | 12.5% |
| ★★★☆☆（中級） | 5 | 31.3% |
| ★★★★☆（上級） | 5 | 31.3% |
| ★★★★★（最上級） | 4 | 25.0% |

---

## 🎯 学習成果

このカリキュラムを完了すると、以下ができるようになります：

### 理論的理解
- ✅ 確率統計の基礎から生成モデルまでの流れを理解している
- ✅ 最尤推定とELBOの関係を説明できる
- ✅ VAEと拡散モデルの数学的基礎を理解している
- ✅ 拡散モデルの理論を数式で説明できる

### 実装スキル
- ✅ PyTorchでニューラルネットワークを実装できる
- ✅ VAEを実装し、潜在空間を探索できる
- ✅ 拡散モデルをスクラッチで実装できる
- ✅ 条件付き拡散モデルを実装できる

### 応用力
- ✅ 様々なデータセットで拡散モデルを訓練できる
- ✅ ハイパーパラメータをチューニングできる
- ✅ 生成品質を評価できる
- ✅ Stable Diffusionの仕組みを理解し、使いこなせる

### 実践経験
- ✅ MNIST、Fashion-MNIST、CIFAR-10 などのデータセットで実験
- ✅ 画像生成タスクを完遂
- ✅ 最新のDiffusersライブラリを使用
- ✅ 独自の生成モデルプロジェクトを設計できる

---

## 📚 推奨リソース

### 書籍
- **「機械学習スタートアップシリーズ ベイズ推論による機械学習入門」** 須山敦志
- **「深層学習改訂第2版」** Ian Goodfellow ほか
- **「パターン認識と機械学習（上・下）」** C.M. ビショップ
- **「生成Deep Learning」** David Foster

### 論文
- **DDPM (2020)**: "Denoising Diffusion Probabilistic Models" - Ho et al.
- **Improved DDPM (2021)**: "Improved Denoising Diffusion Probabilistic Models" - Nichol & Dhariwal
- **DDIM (2021)**: "Denoising Diffusion Implicit Models" - Song et al.
- **Classifier Guidance (2021)**: "Diffusion Models Beat GANs" - Dhariwal & Nichol
- **Classifier-Free Guidance (2022)**: "Classifier-Free Diffusion Guidance" - Ho & Salimans
- **Latent Diffusion (2022)**: "High-Resolution Image Synthesis with Latent Diffusion Models" - Rombach et al.

### オンラインリソース
- **Hugging Face Diffusers**: https://huggingface.co/docs/diffusers/
- **Lil'Log by Lilian Weng**: "What are Diffusion Models?"
- **Hugging Face Diffusion Course**: https://github.com/huggingface/diffusion-models-class
- **Annotated Diffusion Model**: https://huggingface.co/blog/annotated-diffusion

### 動画
- **"Diffusion Models | Paper Explanation" by Outlier**
- **"Diffusion models explained" by AI Coffee Break**

---

## 🛠️ 技術スタック

### 必須ライブラリ
```python
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0
scipy>=1.10.0
pillow>=9.5.0
tqdm>=4.65.0
```

### オプショナルライブラリ
```python
diffusers>=0.21.0  # Stable Diffusion用
transformers>=4.30.0  # CLIPエンコーダ用
accelerate>=0.20.0  # 訓練の高速化
```

---

## ✅ 実装時の推奨順序

1. **Phase 1-2 を先に完了** (Notebook 30-34)
   - 確率統計とEMアルゴリズムの基礎を固める
   - これがVAEと拡散モデルの理解に不可欠

2. **Phase 3 でPyTorchに慣れる** (Notebook 35-36)
   - PyTorchの基本操作をマスター
   - 後の実装がスムーズになる

3. **Phase 4 のVAEで生成モデルを体験** (Notebook 37-38)
   - 生成モデルの実装パターンを学ぶ
   - ELBOの実装経験が拡散モデルに活きる

4. **Phase 5 で理論をじっくり学ぶ** (Notebook 39-40)
   - 数式の導出に時間をかける
   - 理解が浅い場合は Phase 1 に戻る

5. **Phase 6 で実装力を磨く** (Notebook 41-43)
   - 最も時間をかけるべきフェーズ
   - デバッグとハイパーパラメータ調整を繰り返す

6. **Phase 7 で応用力を身につける** (Notebook 44-45)
   - 最新の手法を学ぶ
   - 独自のプロジェクトに挑戦

---

## 📝 次のステップ

### カリキュラム完了後の発展
1. **GAN（敵対的生成ネットワーク）の学習**
2. **Transformerベースの生成モデル（GPT, DALL-E）**
3. **Video Diffusion Models**
4. **3D生成モデル**
5. **音声生成モデル**

### プロジェクトアイデア
1. **独自データセットでの拡散モデル訓練**
2. **テキストから画像生成のファインチューニング**
3. **画像編集アプリケーションの開発**
4. **超解像度モデルの実装**
5. **インペインティング（画像修復）**

---

## 📞 サポート

質問や提案がある場合は、GitHubのIssueをご利用ください。

---

**Happy Learning! 🎓✨**

生成モデルの世界へようこそ。このカリキュラムがあなたの学習の助けになれば幸いです。

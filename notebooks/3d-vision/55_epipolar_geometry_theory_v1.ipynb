{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 55. エピポーラ幾何の理論\n",
    "## Epipolar Geometry Theory\n",
    "\n",
    "---\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このノートブックを完了すると、以下ができるようになります：\n",
    "\n",
    "- [ ] エピポーラ幾何の基本概念（エピポール、エピポーラ線、エピポーラ面）を理解する\n",
    "- [ ] 基礎行列（Fundamental Matrix）Fの意味と性質を説明できる\n",
    "- [ ] 本質行列（Essential Matrix）Eの意味と性質を説明できる\n",
    "- [ ] エピポーラ拘束条件を数学的に記述できる\n",
    "- [ ] 8点アルゴリズムでFを推定できる\n",
    "- [ ] RANSACを用いたロバスト推定を理解する\n",
    "- [ ] Eの分解からカメラの相対姿勢（R, t）を復元できる\n",
    "\n",
    "---\n",
    "\n",
    "## 前提知識\n",
    "\n",
    "- 51: ピンホールカメラモデルと射影変換\n",
    "- 53: 3D座標変換と剛体運動（SO(3), SE(3)）\n",
    "- 54: カメラキャリブレーション（内部パラメータK）\n",
    "- 線形代数：SVD分解、固有値分解\n",
    "\n",
    "**難易度**: ★★★★☆（上級）  \n",
    "**推定学習時間**: 90-120分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. エピポーラ幾何とは\n",
    "\n",
    "**エピポーラ幾何**（Epipolar Geometry）は、2つのカメラ視点から同じ3Dシーンを観測したときに成り立つ幾何学的関係を記述する理論です。\n",
    "\n",
    "### なぜエピポーラ幾何が重要なのか？\n",
    "\n",
    "1. **対応点探索の効率化**: 2D画像間の対応点を1次元探索に削減\n",
    "2. **カメラ姿勢推定**: 2枚の画像から相対的なカメラ位置・姿勢を復元\n",
    "3. **3D復元の基礎**: ステレオビジョン、SfMの数学的基盤\n",
    "4. **外れ値検出**: 誤対応の検出と除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from typing import Tuple, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. エピポーラ幾何の基本要素\n",
    "\n",
    "### 2.1 セットアップ\n",
    "\n",
    "2台のカメラが同じ3D点 $\\mathbf{X}$ を観測する状況を考えます：\n",
    "\n",
    "- **カメラ1**: 中心 $\\mathbf{C}_1$、画像点 $\\mathbf{x}_1$\n",
    "- **カメラ2**: 中心 $\\mathbf{C}_2$、画像点 $\\mathbf{x}_2$\n",
    "\n",
    "### 2.2 基本要素の定義\n",
    "\n",
    "| 要素 | 定義 | 性質 |\n",
    "|------|------|------|\n",
    "| **ベースライン** | $\\mathbf{C}_1$と$\\mathbf{C}_2$を結ぶ線分 | 2つのカメラ中心を接続 |\n",
    "| **エピポール** $\\mathbf{e}_1, \\mathbf{e}_2$ | ベースラインと各画像面の交点 | 相手カメラの投影位置 |\n",
    "| **エピポーラ面** | $\\mathbf{C}_1, \\mathbf{C}_2, \\mathbf{X}$を含む平面 | 各3D点に対して一意に決まる |\n",
    "| **エピポーラ線** $\\mathbf{l}_1, \\mathbf{l}_2$ | エピポーラ面と各画像面の交線 | 対応点はこの線上に存在 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_epipolar_geometry():\n",
    "    \"\"\"エピポーラ幾何の3D可視化\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # カメラ中心\n",
    "    C1 = np.array([0, 0, 0])\n",
    "    C2 = np.array([2, 0, 0.3])\n",
    "    \n",
    "    # 3D点\n",
    "    X = np.array([1.0, 3.0, 1.5])\n",
    "    \n",
    "    # 画像面（簡略化：z=1の平面）\n",
    "    # カメラ1の画像面\n",
    "    img1_corners = np.array([\n",
    "        [-0.5, 1, -0.5],\n",
    "        [0.5, 1, -0.5],\n",
    "        [0.5, 1, 0.5],\n",
    "        [-0.5, 1, 0.5]\n",
    "    ])\n",
    "    \n",
    "    # カメラ2の画像面\n",
    "    img2_corners = np.array([\n",
    "        [1.5, 1, -0.5 + 0.3],\n",
    "        [2.5, 1, -0.5 + 0.3],\n",
    "        [2.5, 1, 0.5 + 0.3],\n",
    "        [1.5, 1, 0.5 + 0.3]\n",
    "    ])\n",
    "    \n",
    "    # 投影点（簡略化）\n",
    "    # カメラ1への投影\n",
    "    t1 = 1.0 / X[1]  # y=1の平面までのスケール\n",
    "    x1 = C1 + t1 * (X - C1)\n",
    "    \n",
    "    # カメラ2への投影\n",
    "    t2 = 1.0 / (X[1] - C2[1]) if X[1] != C2[1] else 0\n",
    "    x2 = C2 + t2 * (X - C2)\n",
    "    x2[1] = 1  # y=1の平面に固定\n",
    "    \n",
    "    # エピポール\n",
    "    # e1: C2をカメラ1に投影\n",
    "    t_e1 = 1.0 / C2[1] if C2[1] != 0 else 0\n",
    "    e1 = C1 + t_e1 * (C2 - C1)\n",
    "    e1[1] = 1\n",
    "    \n",
    "    # e2: C1をカメラ2に投影  \n",
    "    t_e2 = 1.0 / (-C2[1]) if C2[1] != 0 else 0\n",
    "    e2 = C2 + t_e2 * (C1 - C2)\n",
    "    e2[1] = 1\n",
    "    \n",
    "    # プロット\n",
    "    # カメラ中心\n",
    "    ax.scatter(*C1, color='blue', s=200, marker='o', label='Camera 1 Center')\n",
    "    ax.scatter(*C2, color='green', s=200, marker='o', label='Camera 2 Center')\n",
    "    \n",
    "    # 3D点\n",
    "    ax.scatter(*X, color='red', s=200, marker='*', label='3D Point X')\n",
    "    \n",
    "    # ベースライン\n",
    "    ax.plot([C1[0], C2[0]], [C1[1], C2[1]], [C1[2], C2[2]], \n",
    "            'k-', linewidth=3, label='Baseline')\n",
    "    \n",
    "    # 投影光線\n",
    "    ax.plot([C1[0], X[0]], [C1[1], X[1]], [C1[2], X[2]], \n",
    "            'b--', linewidth=2, alpha=0.7, label='Ray from C1')\n",
    "    ax.plot([C2[0], X[0]], [C2[1], X[1]], [C2[2], X[2]], \n",
    "            'g--', linewidth=2, alpha=0.7, label='Ray from C2')\n",
    "    \n",
    "    # 投影点\n",
    "    ax.scatter(*x1, color='blue', s=100, marker='x')\n",
    "    ax.scatter(*x2, color='green', s=100, marker='x')\n",
    "    \n",
    "    # エピポーラ面（三角形として描画）\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    verts = [[C1, C2, X]]\n",
    "    poly = Poly3DCollection(verts, alpha=0.2, facecolor='yellow', edgecolor='orange')\n",
    "    ax.add_collection3d(poly)\n",
    "    \n",
    "    # 画像面（半透明）\n",
    "    for corners, color in [(img1_corners, 'blue'), (img2_corners, 'green')]:\n",
    "        verts = [corners]\n",
    "        poly = Poly3DCollection(verts, alpha=0.1, facecolor=color, edgecolor=color)\n",
    "        ax.add_collection3d(poly)\n",
    "    \n",
    "    # ラベル\n",
    "    ax.text(*C1, '  C₁', fontsize=12)\n",
    "    ax.text(*C2, '  C₂', fontsize=12)\n",
    "    ax.text(*X, '  X', fontsize=12)\n",
    "    ax.text(*x1, '  x₁', fontsize=10)\n",
    "    ax.text(*x2, '  x₂', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Epipolar Geometry Visualization\\n(Yellow: Epipolar Plane)', fontsize=14)\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    # 視点調整\n",
    "    ax.view_init(elev=20, azim=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_epipolar_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 エピポーラ拘束の幾何学的意味\n",
    "\n",
    "**核心的な洞察**：\n",
    "\n",
    "画像1上の点 $\\mathbf{x}_1$ が与えられたとき、対応する3D点 $\\mathbf{X}$ は光線 $\\mathbf{C}_1 \\mathbf{x}_1$ 上のどこかに存在します。\n",
    "\n",
    "この光線をカメラ2に投影すると、**エピポーラ線** $\\mathbf{l}_2$ になります。\n",
    "\n",
    "したがって、$\\mathbf{x}_2$ は必ず $\\mathbf{l}_2$ 上に存在します。\n",
    "\n",
    "$$\\mathbf{x}_2 \\in \\mathbf{l}_2$$\n",
    "\n",
    "これが**エピポーラ拘束**の本質です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_epipolar_constraint_2d():\n",
    "    \"\"\"エピポーラ拘束の2D可視化（画像ペア）\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # 画像サイズ\n",
    "    img_size = (640, 480)\n",
    "    \n",
    "    # 画像1の点\n",
    "    x1 = np.array([320, 200])  # 中央上部\n",
    "    \n",
    "    # エピポール（例）\n",
    "    e1 = np.array([700, 240])  # 画像外（右側）\n",
    "    e2 = np.array([-60, 240])  # 画像外（左側）\n",
    "    \n",
    "    # 画像1\n",
    "    ax1.set_xlim(0, img_size[0])\n",
    "    ax1.set_ylim(img_size[1], 0)  # 画像座標系\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='lightgray', edgecolor='black'))\n",
    "    \n",
    "    # 点とエピポーラ線\n",
    "    ax1.scatter(*x1, color='red', s=200, zorder=5, label='Point x₁')\n",
    "    ax1.scatter(*e1, color='blue', s=100, marker='x', zorder=5, label='Epipole e₁')\n",
    "    \n",
    "    # x1を通るエピポーラ線（e1方向へ）\n",
    "    direction = e1 - x1\n",
    "    t_range = np.linspace(-2, 2, 100)\n",
    "    line_points = x1[:, np.newaxis] + direction[:, np.newaxis] * t_range\n",
    "    ax1.plot(line_points[0], line_points[1], 'b-', linewidth=2, alpha=0.5)\n",
    "    \n",
    "    ax1.set_title('Image 1', fontsize=14)\n",
    "    ax1.set_xlabel('u (pixels)')\n",
    "    ax1.set_ylabel('v (pixels)')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 画像2\n",
    "    ax2.set_xlim(0, img_size[0])\n",
    "    ax2.set_ylim(img_size[1], 0)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='lightgray', edgecolor='black'))\n",
    "    \n",
    "    # エピポーラ線（x1に対応）\n",
    "    # 簡略化：ほぼ水平なエピポーラ線\n",
    "    x2_candidates = np.array([[200, 180], [350, 185], [500, 190]])  # 線上の候補点\n",
    "    x2_true = np.array([350, 185])  # 真の対応点\n",
    "    \n",
    "    ax2.scatter(*e2, color='blue', s=100, marker='x', zorder=5, label='Epipole e₂')\n",
    "    \n",
    "    # エピポーラ線\n",
    "    line_y = 185\n",
    "    ax2.axhline(y=line_y, color='green', linewidth=3, alpha=0.5, label='Epipolar line l₂')\n",
    "    \n",
    "    # 対応点候補\n",
    "    ax2.scatter(x2_candidates[:, 0], x2_candidates[:, 1], \n",
    "                color='orange', s=100, alpha=0.5, label='Candidate points')\n",
    "    ax2.scatter(*x2_true, color='red', s=200, zorder=5, label='True correspondence x₂')\n",
    "    \n",
    "    # 探索範囲の注釈\n",
    "    ax2.annotate('', xy=(600, line_y), xytext=(50, line_y),\n",
    "                 arrowprops=dict(arrowstyle='<->', color='green', lw=2))\n",
    "    ax2.text(320, line_y - 30, '1D Search on Epipolar Line', \n",
    "             ha='center', fontsize=11, color='green')\n",
    "    \n",
    "    ax2.set_title('Image 2', fontsize=14)\n",
    "    ax2.set_xlabel('u (pixels)')\n",
    "    ax2.set_ylabel('v (pixels)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.suptitle('Epipolar Constraint: Search for Correspondence', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"エピポーラ拘束により、2D探索が1D探索に削減されます！\")\n",
    "    print(f\"探索空間: {img_size[0]} × {img_size[1]} = {img_size[0] * img_size[1]:,} pixels\")\n",
    "    print(f\"→ エピポーラ線上: ~{img_size[0]} pixels（{img_size[0] * img_size[1] / img_size[0]:.0f}倍の効率化）\")\n",
    "\n",
    "visualize_epipolar_constraint_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 基礎行列（Fundamental Matrix）F\n",
    "\n",
    "### 3.1 定義\n",
    "\n",
    "**基礎行列** $\\mathbf{F}$ は、2つの画像間のエピポーラ幾何を完全に記述する $3 \\times 3$ 行列です。\n",
    "\n",
    "#### エピポーラ拘束（代数形式）\n",
    "\n",
    "$$\\mathbf{x}_2^\\top \\mathbf{F} \\mathbf{x}_1 = 0$$\n",
    "\n",
    "ここで：\n",
    "- $\\mathbf{x}_1 = (u_1, v_1, 1)^\\top$ : 画像1の同次座標\n",
    "- $\\mathbf{x}_2 = (u_2, v_2, 1)^\\top$ : 画像2の同次座標\n",
    "\n",
    "### 3.2 エピポーラ線の計算\n",
    "\n",
    "- **画像2のエピポーラ線**: $\\mathbf{l}_2 = \\mathbf{F} \\mathbf{x}_1$\n",
    "- **画像1のエピポーラ線**: $\\mathbf{l}_1 = \\mathbf{F}^\\top \\mathbf{x}_2$\n",
    "\n",
    "直線 $\\mathbf{l} = (a, b, c)^\\top$ は $ax + by + c = 0$ を表します。\n",
    "\n",
    "### 3.3 基礎行列の性質\n",
    "\n",
    "| 性質 | 説明 |\n",
    "|------|------|\n",
    "| **ランク** | $\\text{rank}(\\mathbf{F}) = 2$（特異行列） |\n",
    "| **自由度** | 7 DOF（スケール不定性で-1、ランク2拘束で-1） |\n",
    "| **エピポール** | $\\mathbf{F} \\mathbf{e}_1 = \\mathbf{0}$, $\\mathbf{F}^\\top \\mathbf{e}_2 = \\mathbf{0}$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_symmetric(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"3Dベクトルから反対称行列を生成\"\"\"\n",
    "    return np.array([\n",
    "        [0, -v[2], v[1]],\n",
    "        [v[2], 0, -v[0]],\n",
    "        [-v[1], v[0], 0]\n",
    "    ])\n",
    "\n",
    "def compute_fundamental_matrix(K1: np.ndarray, K2: np.ndarray, \n",
    "                                R: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"カメラパラメータから基礎行列を計算\n",
    "    \n",
    "    F = K2^(-T) [t]_x R K1^(-1)\n",
    "    \"\"\"\n",
    "    t_skew = skew_symmetric(t)\n",
    "    E = t_skew @ R  # 本質行列\n",
    "    F = np.linalg.inv(K2).T @ E @ np.linalg.inv(K1)\n",
    "    return F / F[2, 2]  # 正規化\n",
    "\n",
    "def compute_epipolar_line(F: np.ndarray, x: np.ndarray, image: int = 2) -> np.ndarray:\n",
    "    \"\"\"エピポーラ線を計算\n",
    "    \n",
    "    Args:\n",
    "        F: 基礎行列\n",
    "        x: 点の同次座標 (3,)\n",
    "        image: 1なら画像1のエピポーラ線、2なら画像2のエピポーラ線\n",
    "    \n",
    "    Returns:\n",
    "        l: エピポーラ線 (a, b, c) where ax + by + c = 0\n",
    "    \"\"\"\n",
    "    if image == 2:\n",
    "        return F @ x\n",
    "    else:\n",
    "        return F.T @ x\n",
    "\n",
    "# 例: カメラパラメータの設定\n",
    "K = np.array([\n",
    "    [800, 0, 320],\n",
    "    [0, 800, 240],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# カメラ2の相対姿勢（カメラ1からの変換）\n",
    "theta = np.radians(10)  # 10度回転\n",
    "R = np.array([\n",
    "    [np.cos(theta), 0, np.sin(theta)],\n",
    "    [0, 1, 0],\n",
    "    [-np.sin(theta), 0, np.cos(theta)]\n",
    "])  # Y軸周りの回転\n",
    "\n",
    "t = np.array([0.5, 0, 0.1])  # 右へ0.5、前へ0.1移動\n",
    "\n",
    "# 基礎行列の計算\n",
    "F = compute_fundamental_matrix(K, K, R, t)\n",
    "\n",
    "print(\"カメラ内部パラメータ K:\")\n",
    "print(K)\n",
    "print(f\"\\n回転行列 R (Y軸周り{np.degrees(theta):.1f}度):\")\n",
    "print(R)\n",
    "print(f\"\\n並進ベクトル t: {t}\")\n",
    "print(\"\\n基礎行列 F:\")\n",
    "print(F)\n",
    "print(f\"\\nrank(F) = {np.linalg.matrix_rank(F)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_epipolar_constraint(F: np.ndarray, x1: np.ndarray, x2: np.ndarray):\n",
    "    \"\"\"エピポーラ拘束の検証\"\"\"\n",
    "    # 同次座標に変換\n",
    "    x1_h = np.append(x1, 1) if len(x1) == 2 else x1\n",
    "    x2_h = np.append(x2, 1) if len(x2) == 2 else x2\n",
    "    \n",
    "    # x2^T F x1\n",
    "    constraint = x2_h @ F @ x1_h\n",
    "    return constraint\n",
    "\n",
    "def visualize_epipolar_lines():\n",
    "    \"\"\"複数の点に対するエピポーラ線の可視化\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    img_size = (640, 480)\n",
    "    \n",
    "    # テスト点（画像1）\n",
    "    test_points = np.array([\n",
    "        [200, 150],\n",
    "        [320, 240],\n",
    "        [450, 350],\n",
    "        [100, 400]\n",
    "    ])\n",
    "    \n",
    "    colors = ['red', 'green', 'blue', 'purple']\n",
    "    \n",
    "    # 画像1: 点をプロット\n",
    "    ax1.set_xlim(0, img_size[0])\n",
    "    ax1.set_ylim(img_size[1], 0)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='lightgray', edgecolor='black'))\n",
    "    \n",
    "    for i, (pt, color) in enumerate(zip(test_points, colors)):\n",
    "        ax1.scatter(*pt, color=color, s=150, zorder=5, label=f'Point {i+1}')\n",
    "    \n",
    "    # エピポールを計算（Fの右零空間）\n",
    "    U, S, Vt = np.linalg.svd(F)\n",
    "    e1 = Vt[-1]  # 右零空間（F e1 = 0）\n",
    "    e1 = e1 / e1[2]  # 正規化\n",
    "    \n",
    "    # エピポールの可視化（画像範囲外でも方向を示す）\n",
    "    if 0 <= e1[0] <= img_size[0] and 0 <= e1[1] <= img_size[1]:\n",
    "        ax1.scatter(e1[0], e1[1], color='black', s=200, marker='x', zorder=10, label='Epipole e₁')\n",
    "    else:\n",
    "        ax1.annotate(f'e₁ → ({e1[0]:.0f}, {e1[1]:.0f})', \n",
    "                     xy=(img_size[0]-10, img_size[1]//2), fontsize=10,\n",
    "                     bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    ax1.set_title('Image 1: Points', fontsize=14)\n",
    "    ax1.set_xlabel('u (pixels)')\n",
    "    ax1.set_ylabel('v (pixels)')\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    # 画像2: エピポーラ線をプロット\n",
    "    ax2.set_xlim(0, img_size[0])\n",
    "    ax2.set_ylim(img_size[1], 0)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='lightgray', edgecolor='black'))\n",
    "    \n",
    "    for i, (pt, color) in enumerate(zip(test_points, colors)):\n",
    "        # 同次座標\n",
    "        x1_h = np.array([pt[0], pt[1], 1])\n",
    "        \n",
    "        # エピポーラ線\n",
    "        l2 = compute_epipolar_line(F, x1_h, image=2)\n",
    "        a, b, c = l2\n",
    "        \n",
    "        # 直線を描画（ax + by + c = 0 → y = -(ax + c) / b）\n",
    "        if abs(b) > 1e-6:\n",
    "            x_vals = np.array([0, img_size[0]])\n",
    "            y_vals = -(a * x_vals + c) / b\n",
    "        else:\n",
    "            # 垂直線\n",
    "            x_vals = np.array([-c/a, -c/a])\n",
    "            y_vals = np.array([0, img_size[1]])\n",
    "        \n",
    "        ax2.plot(x_vals, y_vals, color=color, linewidth=2, \n",
    "                 label=f'Epipolar line for Point {i+1}')\n",
    "    \n",
    "    # エピポールe2を計算（F^Tの右零空間）\n",
    "    U, S, Vt = np.linalg.svd(F.T)\n",
    "    e2 = Vt[-1]\n",
    "    e2 = e2 / e2[2]\n",
    "    \n",
    "    if 0 <= e2[0] <= img_size[0] and 0 <= e2[1] <= img_size[1]:\n",
    "        ax2.scatter(e2[0], e2[1], color='black', s=200, marker='x', zorder=10, label='Epipole e₂')\n",
    "    else:\n",
    "        ax2.annotate(f'e₂ → ({e2[0]:.0f}, {e2[1]:.0f})', \n",
    "                     xy=(10, img_size[1]//2), fontsize=10,\n",
    "                     bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    ax2.set_title('Image 2: Epipolar Lines', fontsize=14)\n",
    "    ax2.set_xlabel('u (pixels)')\n",
    "    ax2.set_ylabel('v (pixels)')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.suptitle('Fundamental Matrix: Point → Epipolar Line Mapping', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n全てのエピポーラ線はエピポールe₂を通過します（画像外の場合あり）\")\n",
    "\n",
    "visualize_epipolar_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 本質行列（Essential Matrix）E\n",
    "\n",
    "### 4.1 定義\n",
    "\n",
    "**本質行列** $\\mathbf{E}$ は、**正規化画像座標**（カメラ内部パラメータで正規化済み）に対するエピポーラ拘束を記述します。\n",
    "\n",
    "#### 正規化座標\n",
    "\n",
    "$$\\hat{\\mathbf{x}} = \\mathbf{K}^{-1} \\mathbf{x}$$\n",
    "\n",
    "#### エピポーラ拘束（本質行列）\n",
    "\n",
    "$$\\hat{\\mathbf{x}}_2^\\top \\mathbf{E} \\hat{\\mathbf{x}}_1 = 0$$\n",
    "\n",
    "### 4.2 本質行列の構造\n",
    "\n",
    "$$\\mathbf{E} = [\\mathbf{t}]_\\times \\mathbf{R} = \\mathbf{R} [\\mathbf{R}^\\top \\mathbf{t}]_\\times$$\n",
    "\n",
    "ここで：\n",
    "- $\\mathbf{R}$: カメラ2のカメラ1に対する回転\n",
    "- $\\mathbf{t}$: カメラ2のカメラ1に対する並進\n",
    "- $[\\cdot]_\\times$: 反対称行列（外積を行列積で表現）\n",
    "\n",
    "### 4.3 基礎行列との関係\n",
    "\n",
    "$$\\mathbf{F} = \\mathbf{K}_2^{-\\top} \\mathbf{E} \\mathbf{K}_1^{-1}$$\n",
    "\n",
    "または\n",
    "\n",
    "$$\\mathbf{E} = \\mathbf{K}_2^\\top \\mathbf{F} \\mathbf{K}_1$$\n",
    "\n",
    "### 4.4 本質行列の性質\n",
    "\n",
    "| 性質 | 説明 |\n",
    "|------|------|\n",
    "| **ランク** | $\\text{rank}(\\mathbf{E}) = 2$ |\n",
    "| **特異値** | 2つの等しい非零特異値：$\\sigma_1 = \\sigma_2$, $\\sigma_3 = 0$ |\n",
    "| **自由度** | 5 DOF（回転3 + 並進2、スケール不定） |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_essential_matrix(R: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"本質行列を計算: E = [t]_x R\"\"\"\n",
    "    t_skew = skew_symmetric(t)\n",
    "    E = t_skew @ R\n",
    "    return E\n",
    "\n",
    "def verify_essential_matrix_properties(E: np.ndarray):\n",
    "    \"\"\"本質行列の性質を検証\"\"\"\n",
    "    U, S, Vt = np.linalg.svd(E)\n",
    "    \n",
    "    print(\"=== 本質行列の性質検証 ===\")\n",
    "    print(f\"\\n特異値: {S}\")\n",
    "    print(f\"σ₁ ≈ σ₂: {np.isclose(S[0], S[1], rtol=0.1)}\")\n",
    "    print(f\"σ₃ ≈ 0: {np.isclose(S[2], 0, atol=1e-10)}\")\n",
    "    print(f\"\\nrank(E) = {np.sum(S > 1e-10)}\")\n",
    "    \n",
    "    # det(E) = 0 の検証\n",
    "    print(f\"\\ndet(E) = {np.linalg.det(E):.6f} (should be ≈ 0)\")\n",
    "    \n",
    "    # 2E E^T E - trace(E E^T) E = 0 の検証（内部拘束）\n",
    "    EET = E @ E.T\n",
    "    constraint = 2 * E @ E.T @ E - np.trace(EET) * E\n",
    "    print(f\"\\n内部拘束 ||2EE^TE - tr(EE^T)E|| = {np.linalg.norm(constraint):.6e} (should be ≈ 0)\")\n",
    "\n",
    "# 本質行列の計算と検証\n",
    "E = compute_essential_matrix(R, t)\n",
    "\n",
    "print(\"本質行列 E:\")\n",
    "print(E)\n",
    "print()\n",
    "\n",
    "verify_essential_matrix_properties(E)\n",
    "\n",
    "# F と E の関係を検証\n",
    "print(\"\\n=== F と E の関係検証 ===\")\n",
    "E_from_F = K.T @ F @ K\n",
    "E_from_F = E_from_F / np.linalg.norm(E_from_F) * np.linalg.norm(E)  # スケール調整\n",
    "print(f\"E (直接計算):\")\n",
    "print(E / np.linalg.norm(E))\n",
    "print(f\"\\nK^T F K (F から計算):\")\n",
    "print(E_from_F / np.linalg.norm(E_from_F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 8点アルゴリズム\n",
    "\n",
    "### 5.1 概要\n",
    "\n",
    "**8点アルゴリズム**は、8組以上の対応点から基礎行列 $\\mathbf{F}$ を推定する最も基本的な手法です。\n",
    "\n",
    "### 5.2 アルゴリズム\n",
    "\n",
    "#### ステップ1: エピポーラ拘束の線形化\n",
    "\n",
    "$$\\mathbf{x}_2^\\top \\mathbf{F} \\mathbf{x}_1 = 0$$\n",
    "\n",
    "を展開すると：\n",
    "\n",
    "$$u_2 u_1 f_{11} + u_2 v_1 f_{12} + u_2 f_{13} + v_2 u_1 f_{21} + v_2 v_1 f_{22} + v_2 f_{23} + u_1 f_{31} + v_1 f_{32} + f_{33} = 0$$\n",
    "\n",
    "#### ステップ2: 行列形式\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{f} = \\mathbf{0}$$\n",
    "\n",
    "ここで $\\mathbf{f} = (f_{11}, f_{12}, ..., f_{33})^\\top$ は $\\mathbf{F}$ の要素をベクトル化したものです。\n",
    "\n",
    "#### ステップ3: SVD による解\n",
    "\n",
    "$\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^\\top$ のSVD分解で、$\\mathbf{V}$ の最後の列が $\\mathbf{f}$ の解。\n",
    "\n",
    "#### ステップ4: ランク2への射影\n",
    "\n",
    "$\\mathbf{F}$ の SVD で最小特異値を0に設定し、ランク2を保証。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points(points: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"点の正規化（数値安定性のため）\n",
    "    \n",
    "    平均を原点に、平均距離を√2にスケール\n",
    "    \n",
    "    Returns:\n",
    "        normalized_points: 正規化された点\n",
    "        T: 正規化変換行列\n",
    "    \"\"\"\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered = points - centroid\n",
    "    mean_dist = np.mean(np.linalg.norm(centered, axis=1))\n",
    "    scale = np.sqrt(2) / mean_dist if mean_dist > 0 else 1.0\n",
    "    \n",
    "    T = np.array([\n",
    "        [scale, 0, -scale * centroid[0]],\n",
    "        [0, scale, -scale * centroid[1]],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # 同次座標で変換\n",
    "    points_h = np.hstack([points, np.ones((len(points), 1))])\n",
    "    normalized = (T @ points_h.T).T\n",
    "    \n",
    "    return normalized[:, :2], T\n",
    "\n",
    "def eight_point_algorithm(pts1: np.ndarray, pts2: np.ndarray, \n",
    "                          normalize: bool = True) -> np.ndarray:\n",
    "    \"\"\"8点アルゴリズムによる基礎行列の推定\n",
    "    \n",
    "    Args:\n",
    "        pts1: 画像1の対応点 (N, 2)\n",
    "        pts2: 画像2の対応点 (N, 2)\n",
    "        normalize: 正規化を行うか（推奨: True）\n",
    "    \n",
    "    Returns:\n",
    "        F: 基礎行列 (3, 3)\n",
    "    \"\"\"\n",
    "    assert len(pts1) >= 8, \"8点以上必要です\"\n",
    "    assert len(pts1) == len(pts2), \"対応点の数が一致しません\"\n",
    "    \n",
    "    # 1. 正規化\n",
    "    if normalize:\n",
    "        pts1_norm, T1 = normalize_points(pts1)\n",
    "        pts2_norm, T2 = normalize_points(pts2)\n",
    "    else:\n",
    "        pts1_norm = pts1\n",
    "        pts2_norm = pts2\n",
    "        T1 = T2 = np.eye(3)\n",
    "    \n",
    "    # 2. 行列Aの構築\n",
    "    n = len(pts1)\n",
    "    A = np.zeros((n, 9))\n",
    "    \n",
    "    for i in range(n):\n",
    "        u1, v1 = pts1_norm[i]\n",
    "        u2, v2 = pts2_norm[i]\n",
    "        A[i] = [u2*u1, u2*v1, u2, v2*u1, v2*v1, v2, u1, v1, 1]\n",
    "    \n",
    "    # 3. SVD で解を求める\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    F = Vt[-1].reshape(3, 3)\n",
    "    \n",
    "    # 4. ランク2への射影（特異値拘束）\n",
    "    U_f, S_f, Vt_f = np.linalg.svd(F)\n",
    "    S_f[2] = 0  # 最小特異値を0に\n",
    "    F = U_f @ np.diag(S_f) @ Vt_f\n",
    "    \n",
    "    # 5. 正規化の逆変換\n",
    "    if normalize:\n",
    "        F = T2.T @ F @ T1\n",
    "    \n",
    "    # 正規化\n",
    "    F = F / F[2, 2] if abs(F[2, 2]) > 1e-10 else F / np.linalg.norm(F)\n",
    "    \n",
    "    return F\n",
    "\n",
    "print(\"8点アルゴリズムの実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_correspondences(K: np.ndarray, R: np.ndarray, t: np.ndarray,\n",
    "                                       n_points: int = 50, \n",
    "                                       noise_std: float = 0.0) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"合成対応点の生成\n",
    "    \n",
    "    Returns:\n",
    "        pts1: 画像1の点\n",
    "        pts2: 画像2の点\n",
    "        X_3d: 3D点\n",
    "    \"\"\"\n",
    "    # ランダムな3D点（カメラ前方）\n",
    "    np.random.seed(42)\n",
    "    X_3d = np.random.randn(n_points, 3)\n",
    "    X_3d[:, 2] = np.abs(X_3d[:, 2]) + 3  # Z > 3 (カメラ前方)\n",
    "    X_3d[:, 0] *= 2  # Xの範囲を広げる\n",
    "    X_3d[:, 1] *= 1.5  # Yの範囲を広げる\n",
    "    \n",
    "    # カメラ1への投影（世界座標 = カメラ1座標と仮定）\n",
    "    pts1_h = (K @ X_3d.T).T\n",
    "    pts1 = pts1_h[:, :2] / pts1_h[:, 2:3]\n",
    "    \n",
    "    # カメラ2への投影\n",
    "    # X_cam2 = R @ X_cam1 + t\n",
    "    X_cam2 = (R @ X_3d.T).T + t\n",
    "    pts2_h = (K @ X_cam2.T).T\n",
    "    pts2 = pts2_h[:, :2] / pts2_h[:, 2:3]\n",
    "    \n",
    "    # ノイズ追加\n",
    "    if noise_std > 0:\n",
    "        pts1 += np.random.randn(*pts1.shape) * noise_std\n",
    "        pts2 += np.random.randn(*pts2.shape) * noise_std\n",
    "    \n",
    "    # 画像範囲内の点のみフィルタリング\n",
    "    img_w, img_h = 640, 480\n",
    "    valid = ((pts1[:, 0] >= 0) & (pts1[:, 0] < img_w) & \n",
    "             (pts1[:, 1] >= 0) & (pts1[:, 1] < img_h) &\n",
    "             (pts2[:, 0] >= 0) & (pts2[:, 0] < img_w) & \n",
    "             (pts2[:, 1] >= 0) & (pts2[:, 1] < img_h))\n",
    "    \n",
    "    return pts1[valid], pts2[valid], X_3d[valid]\n",
    "\n",
    "# 合成データの生成\n",
    "pts1, pts2, X_3d = generate_synthetic_correspondences(K, R, t, n_points=100, noise_std=0.5)\n",
    "\n",
    "print(f\"生成された対応点: {len(pts1)} 組\")\n",
    "\n",
    "# 8点アルゴリズムの実行\n",
    "F_estimated = eight_point_algorithm(pts1, pts2, normalize=True)\n",
    "\n",
    "print(\"\\n推定された基礎行列 F:\")\n",
    "print(F_estimated)\n",
    "\n",
    "# 真の基礎行列との比較\n",
    "F_true = compute_fundamental_matrix(K, K, R, t)\n",
    "F_true = F_true / np.linalg.norm(F_true)\n",
    "F_estimated_norm = F_estimated / np.linalg.norm(F_estimated)\n",
    "\n",
    "print(\"\\n真の基礎行列 F (正規化):\")\n",
    "print(F_true)\n",
    "\n",
    "# 符号の不定性を考慮した比較\n",
    "error1 = np.linalg.norm(F_estimated_norm - F_true)\n",
    "error2 = np.linalg.norm(F_estimated_norm + F_true)\n",
    "error = min(error1, error2)\n",
    "print(f\"\\n推定誤差 (Frobenius norm): {error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_correspondences_and_epipolar_lines(pts1, pts2, F, n_show=8):\n",
    "    \"\"\"対応点とエピポーラ線の可視化\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    img_size = (640, 480)\n",
    "    \n",
    "    # ランダムに点を選択\n",
    "    indices = np.random.choice(len(pts1), min(n_show, len(pts1)), replace=False)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(indices)))\n",
    "    \n",
    "    # 画像1\n",
    "    ax1.set_xlim(0, img_size[0])\n",
    "    ax1.set_ylim(img_size[1], 0)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='#f0f0f0', edgecolor='black'))\n",
    "    \n",
    "    # 画像2\n",
    "    ax2.set_xlim(0, img_size[0])\n",
    "    ax2.set_ylim(img_size[1], 0)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='#f0f0f0', edgecolor='black'))\n",
    "    \n",
    "    for i, (idx, color) in enumerate(zip(indices, colors)):\n",
    "        p1, p2 = pts1[idx], pts2[idx]\n",
    "        \n",
    "        # 点をプロット\n",
    "        ax1.scatter(*p1, color=color, s=100, zorder=5)\n",
    "        ax2.scatter(*p2, color=color, s=100, zorder=5, marker='x', linewidths=2)\n",
    "        \n",
    "        # 画像2のエピポーラ線\n",
    "        x1_h = np.array([p1[0], p1[1], 1])\n",
    "        l2 = F @ x1_h\n",
    "        a, b, c = l2\n",
    "        \n",
    "        if abs(b) > 1e-6:\n",
    "            x_vals = np.array([0, img_size[0]])\n",
    "            y_vals = -(a * x_vals + c) / b\n",
    "        else:\n",
    "            x_vals = np.array([-c/a, -c/a])\n",
    "            y_vals = np.array([0, img_size[1]])\n",
    "        \n",
    "        ax2.plot(x_vals, y_vals, color=color, linewidth=1.5, alpha=0.7)\n",
    "        \n",
    "        # エピポーラ拘束の検証\n",
    "        x2_h = np.array([p2[0], p2[1], 1])\n",
    "        constraint = x2_h @ F @ x1_h\n",
    "        \n",
    "        # 点からエピポーラ線までの距離\n",
    "        dist = abs(a * p2[0] + b * p2[1] + c) / np.sqrt(a**2 + b**2)\n",
    "        \n",
    "        if i == 0:\n",
    "            print(f\"点{idx}: 拘束値={constraint:.4f}, エピポーラ線への距離={dist:.2f}px\")\n",
    "    \n",
    "    ax1.set_title('Image 1: Points (circles)', fontsize=14)\n",
    "    ax1.set_xlabel('u (pixels)')\n",
    "    ax1.set_ylabel('v (pixels)')\n",
    "    \n",
    "    ax2.set_title('Image 2: Points (×) and Epipolar Lines', fontsize=14)\n",
    "    ax2.set_xlabel('u (pixels)')\n",
    "    ax2.set_ylabel('v (pixels)')\n",
    "    \n",
    "    plt.suptitle('8-Point Algorithm: Estimated Epipolar Lines', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 全点の平均距離\n",
    "    total_dist = 0\n",
    "    for i in range(len(pts1)):\n",
    "        x1_h = np.array([pts1[i, 0], pts1[i, 1], 1])\n",
    "        x2_h = np.array([pts2[i, 0], pts2[i, 1], 1])\n",
    "        l2 = F @ x1_h\n",
    "        a, b, c = l2\n",
    "        dist = abs(a * pts2[i, 0] + b * pts2[i, 1] + c) / np.sqrt(a**2 + b**2)\n",
    "        total_dist += dist\n",
    "    \n",
    "    print(f\"\\n平均エピポーラ距離: {total_dist / len(pts1):.4f} pixels\")\n",
    "\n",
    "visualize_correspondences_and_epipolar_lines(pts1, pts2, F_estimated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. RANSACによるロバスト推定\n",
    "\n",
    "### 6.1 なぜRANSACが必要か\n",
    "\n",
    "実際のデータには**外れ値（outliers）**が含まれます：\n",
    "- 誤対応（特徴点マッチングのエラー）\n",
    "- 動く物体\n",
    "- 反射や遮蔽\n",
    "\n",
    "8点アルゴリズムは最小二乗法ベースのため、外れ値に弱いです。\n",
    "\n",
    "### 6.2 RANSACアルゴリズム\n",
    "\n",
    "```\n",
    "for i = 1 to max_iterations:\n",
    "    1. ランダムに8点を選択\n",
    "    2. 8点アルゴリズムでFを計算\n",
    "    3. 全点に対してエピポーラ距離を計算\n",
    "    4. 閾値以下の点をインライアとしてカウント\n",
    "    5. インライア数が最大なら、このFを保持\n",
    "\n",
    "最終的に、全インライアでFを再計算\n",
    "```\n",
    "\n",
    "### 6.3 必要な反復回数\n",
    "\n",
    "$$k = \\frac{\\log(1 - p)}{\\log(1 - w^n)}$$\n",
    "\n",
    "ここで：\n",
    "- $p$: 成功確率（通常0.99）\n",
    "- $w$: インライア率\n",
    "- $n$: サンプル数（8点アルゴリズムでは8）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epipolar_distances(F: np.ndarray, pts1: np.ndarray, pts2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"各対応点のエピポーラ距離を計算\n",
    "    \n",
    "    Sampson距離（1次近似）を使用\n",
    "    \"\"\"\n",
    "    n = len(pts1)\n",
    "    distances = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        x1_h = np.array([pts1[i, 0], pts1[i, 1], 1])\n",
    "        x2_h = np.array([pts2[i, 0], pts2[i, 1], 1])\n",
    "        \n",
    "        # Sampson距離\n",
    "        Fx1 = F @ x1_h\n",
    "        Ftx2 = F.T @ x2_h\n",
    "        \n",
    "        numerator = (x2_h @ F @ x1_h) ** 2\n",
    "        denominator = Fx1[0]**2 + Fx1[1]**2 + Ftx2[0]**2 + Ftx2[1]**2\n",
    "        \n",
    "        distances[i] = numerator / denominator if denominator > 1e-10 else 0\n",
    "    \n",
    "    return np.sqrt(distances)\n",
    "\n",
    "def ransac_fundamental_matrix(pts1: np.ndarray, pts2: np.ndarray,\n",
    "                               threshold: float = 3.0,\n",
    "                               max_iterations: int = 1000,\n",
    "                               confidence: float = 0.99) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"RANSACによる基礎行列のロバスト推定\n",
    "    \n",
    "    Returns:\n",
    "        F: 基礎行列\n",
    "        inlier_mask: インライアのマスク\n",
    "    \"\"\"\n",
    "    n_points = len(pts1)\n",
    "    best_F = None\n",
    "    best_inliers = np.zeros(n_points, dtype=bool)\n",
    "    best_n_inliers = 0\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # 1. ランダムに8点選択\n",
    "        indices = np.random.choice(n_points, 8, replace=False)\n",
    "        \n",
    "        # 2. 8点アルゴリズム\n",
    "        try:\n",
    "            F = eight_point_algorithm(pts1[indices], pts2[indices], normalize=True)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # 3. エピポーラ距離の計算\n",
    "        distances = compute_epipolar_distances(F, pts1, pts2)\n",
    "        \n",
    "        # 4. インライアの判定\n",
    "        inliers = distances < threshold\n",
    "        n_inliers = np.sum(inliers)\n",
    "        \n",
    "        # 5. 最良モデルの更新\n",
    "        if n_inliers > best_n_inliers:\n",
    "            best_n_inliers = n_inliers\n",
    "            best_F = F\n",
    "            best_inliers = inliers\n",
    "            \n",
    "            # 早期終了の判定\n",
    "            inlier_ratio = n_inliers / n_points\n",
    "            if inlier_ratio > 0.9:  # 90%以上がインライア\n",
    "                break\n",
    "    \n",
    "    # 6. 全インライアでFを再計算\n",
    "    if np.sum(best_inliers) >= 8:\n",
    "        best_F = eight_point_algorithm(pts1[best_inliers], pts2[best_inliers], normalize=True)\n",
    "    \n",
    "    return best_F, best_inliers\n",
    "\n",
    "print(\"RANSAC実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outliers(pts1: np.ndarray, pts2: np.ndarray, \n",
    "                 outlier_ratio: float = 0.3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"外れ値を追加\"\"\"\n",
    "    n = len(pts1)\n",
    "    n_outliers = int(n * outlier_ratio)\n",
    "    \n",
    "    # 外れ値のインデックス\n",
    "    outlier_indices = np.random.choice(n, n_outliers, replace=False)\n",
    "    \n",
    "    # コピー\n",
    "    pts1_out = pts1.copy()\n",
    "    pts2_out = pts2.copy()\n",
    "    \n",
    "    # 外れ値：ランダムな位置に変更\n",
    "    pts2_out[outlier_indices] = np.random.rand(n_outliers, 2) * [640, 480]\n",
    "    \n",
    "    # インライアマスク（真の値）\n",
    "    inlier_mask_true = np.ones(n, dtype=bool)\n",
    "    inlier_mask_true[outlier_indices] = False\n",
    "    \n",
    "    return pts1_out, pts2_out, inlier_mask_true\n",
    "\n",
    "# 外れ値を追加したデータ\n",
    "pts1_noisy, pts2_noisy, true_inliers = add_outliers(pts1, pts2, outlier_ratio=0.3)\n",
    "\n",
    "print(f\"全点数: {len(pts1_noisy)}\")\n",
    "print(f\"真のインライア数: {np.sum(true_inliers)}\")\n",
    "print(f\"外れ値数: {np.sum(~true_inliers)}\")\n",
    "\n",
    "# 通常の8点アルゴリズム（外れ値に弱い）\n",
    "F_8point = eight_point_algorithm(pts1_noisy, pts2_noisy, normalize=True)\n",
    "dist_8point = compute_epipolar_distances(F_8point, pts1_noisy, pts2_noisy)\n",
    "\n",
    "# RANSAC\n",
    "F_ransac, inlier_mask = ransac_fundamental_matrix(pts1_noisy, pts2_noisy, \n",
    "                                                   threshold=3.0, max_iterations=1000)\n",
    "dist_ransac = compute_epipolar_distances(F_ransac, pts1_noisy, pts2_noisy)\n",
    "\n",
    "print(f\"\\n=== 結果比較 ===\")\n",
    "print(f\"8点アルゴリズム:\")\n",
    "print(f\"  平均エピポーラ距離: {np.mean(dist_8point):.2f} pixels\")\n",
    "print(f\"  中央値: {np.median(dist_8point):.2f} pixels\")\n",
    "\n",
    "print(f\"\\nRANSAC:\")\n",
    "print(f\"  検出インライア数: {np.sum(inlier_mask)}\")\n",
    "print(f\"  平均エピポーラ距離（インライアのみ）: {np.mean(dist_ransac[inlier_mask]):.2f} pixels\")\n",
    "print(f\"  インライア検出精度: {np.sum(inlier_mask & true_inliers) / np.sum(true_inliers) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ransac_result(pts1, pts2, F, inlier_mask, true_inliers):\n",
    "    \"\"\"RANSACの結果を可視化\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    img_size = (640, 480)\n",
    "    \n",
    "    # 1. 全対応点\n",
    "    ax = axes[0]\n",
    "    ax.set_xlim(0, img_size[0])\n",
    "    ax.set_ylim(img_size[1], 0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='#f0f0f0', edgecolor='black'))\n",
    "    \n",
    "    # 真のインライア/アウトライア\n",
    "    ax.scatter(pts2[true_inliers, 0], pts2[true_inliers, 1], \n",
    "               c='blue', s=30, alpha=0.5, label='True Inliers')\n",
    "    ax.scatter(pts2[~true_inliers, 0], pts2[~true_inliers, 1], \n",
    "               c='red', s=30, alpha=0.5, label='True Outliers')\n",
    "    ax.set_title('Ground Truth', fontsize=12)\n",
    "    ax.legend()\n",
    "    \n",
    "    # 2. RANSAC検出結果\n",
    "    ax = axes[1]\n",
    "    ax.set_xlim(0, img_size[0])\n",
    "    ax.set_ylim(img_size[1], 0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                 fill=True, facecolor='#f0f0f0', edgecolor='black'))\n",
    "    \n",
    "    ax.scatter(pts2[inlier_mask, 0], pts2[inlier_mask, 1], \n",
    "               c='green', s=30, alpha=0.5, label='Detected Inliers')\n",
    "    ax.scatter(pts2[~inlier_mask, 0], pts2[~inlier_mask, 1], \n",
    "               c='orange', s=30, alpha=0.5, label='Detected Outliers')\n",
    "    ax.set_title('RANSAC Detection', fontsize=12)\n",
    "    ax.legend()\n",
    "    \n",
    "    # 3. エピポーラ距離の分布\n",
    "    ax = axes[2]\n",
    "    distances = compute_epipolar_distances(F, pts1, pts2)\n",
    "    \n",
    "    ax.hist(distances[true_inliers], bins=30, alpha=0.5, label='True Inliers', color='blue')\n",
    "    ax.hist(distances[~true_inliers], bins=30, alpha=0.5, label='True Outliers', color='red')\n",
    "    ax.axvline(x=3.0, color='black', linestyle='--', label='Threshold (3px)')\n",
    "    ax.set_xlabel('Epipolar Distance (pixels)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Epipolar Distance Distribution', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 50)\n",
    "    \n",
    "    plt.suptitle('RANSAC Robust Estimation Results', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_ransac_result(pts1_noisy, pts2_noisy, F_ransac, inlier_mask, true_inliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 本質行列の分解（R, tの復元）\n",
    "\n",
    "### 7.1 理論\n",
    "\n",
    "本質行列 $\\mathbf{E}$ から回転 $\\mathbf{R}$ と並進 $\\mathbf{t}$ を復元できます。\n",
    "\n",
    "#### SVD分解\n",
    "\n",
    "$$\\mathbf{E} = \\mathbf{U} \\text{diag}(\\sigma, \\sigma, 0) \\mathbf{V}^\\top$$\n",
    "\n",
    "#### 4つの解候補\n",
    "\n",
    "$$\\mathbf{W} = \\begin{pmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$$\n",
    "\n",
    "| 解 | 回転 | 並進 |\n",
    "|---|------|------|\n",
    "| 1 | $\\mathbf{R} = \\mathbf{U} \\mathbf{W} \\mathbf{V}^\\top$ | $\\mathbf{t} = \\mathbf{u}_3$ |\n",
    "| 2 | $\\mathbf{R} = \\mathbf{U} \\mathbf{W} \\mathbf{V}^\\top$ | $\\mathbf{t} = -\\mathbf{u}_3$ |\n",
    "| 3 | $\\mathbf{R} = \\mathbf{U} \\mathbf{W}^\\top \\mathbf{V}^\\top$ | $\\mathbf{t} = \\mathbf{u}_3$ |\n",
    "| 4 | $\\mathbf{R} = \\mathbf{U} \\mathbf{W}^\\top \\mathbf{V}^\\top$ | $\\mathbf{t} = -\\mathbf{u}_3$ |\n",
    "\n",
    "ここで $\\mathbf{u}_3$ は $\\mathbf{U}$ の3列目。\n",
    "\n",
    "### 7.2 正しい解の選択\n",
    "\n",
    "4つの解のうち、**両方のカメラの前方に3D点が復元される**解が正しい解です。\n",
    "\n",
    "チェック方法：\n",
    "1. 対応点から3D点を三角測量で復元\n",
    "2. 復元された点のZ座標（深度）が両カメラで正であることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_essential_matrix(E: np.ndarray) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"本質行列を分解して4つのR, t候補を返す\n",
    "    \n",
    "    Returns:\n",
    "        List of (R, t) tuples, 4 solutions\n",
    "    \"\"\"\n",
    "    U, S, Vt = np.linalg.svd(E)\n",
    "    \n",
    "    # detが正になるように調整\n",
    "    if np.linalg.det(U) < 0:\n",
    "        U = -U\n",
    "    if np.linalg.det(Vt) < 0:\n",
    "        Vt = -Vt\n",
    "    \n",
    "    # W行列\n",
    "    W = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # 4つの解候補\n",
    "    R1 = U @ W @ Vt\n",
    "    R2 = U @ W.T @ Vt\n",
    "    t = U[:, 2]  # Uの3列目\n",
    "    \n",
    "    # det(R) = 1 を保証\n",
    "    if np.linalg.det(R1) < 0:\n",
    "        R1 = -R1\n",
    "    if np.linalg.det(R2) < 0:\n",
    "        R2 = -R2\n",
    "    \n",
    "    solutions = [\n",
    "        (R1, t),\n",
    "        (R1, -t),\n",
    "        (R2, t),\n",
    "        (R2, -t)\n",
    "    ]\n",
    "    \n",
    "    return solutions\n",
    "\n",
    "def triangulate_point(K: np.ndarray, R1: np.ndarray, t1: np.ndarray,\n",
    "                      R2: np.ndarray, t2: np.ndarray,\n",
    "                      x1: np.ndarray, x2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"DLT法による三角測量\n",
    "    \n",
    "    Args:\n",
    "        K: カメラ内部パラメータ\n",
    "        R1, t1: カメラ1の姿勢\n",
    "        R2, t2: カメラ2の姿勢\n",
    "        x1, x2: 対応する画像点\n",
    "    \n",
    "    Returns:\n",
    "        X: 3D点の座標\n",
    "    \"\"\"\n",
    "    # 投影行列\n",
    "    P1 = K @ np.hstack([R1, t1.reshape(-1, 1)])\n",
    "    P2 = K @ np.hstack([R2, t2.reshape(-1, 1)])\n",
    "    \n",
    "    # DLT\n",
    "    A = np.array([\n",
    "        x1[0] * P1[2] - P1[0],\n",
    "        x1[1] * P1[2] - P1[1],\n",
    "        x2[0] * P2[2] - P2[0],\n",
    "        x2[1] * P2[2] - P2[1]\n",
    "    ])\n",
    "    \n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    X_h = Vt[-1]\n",
    "    X = X_h[:3] / X_h[3]\n",
    "    \n",
    "    return X\n",
    "\n",
    "def check_cheirality(K: np.ndarray, R: np.ndarray, t: np.ndarray,\n",
    "                     pts1: np.ndarray, pts2: np.ndarray) -> int:\n",
    "    \"\"\"チェイラリティ条件（カメラ前方）を満たす点の数を数える\"\"\"\n",
    "    # カメラ1は原点\n",
    "    R1, t1 = np.eye(3), np.zeros(3)\n",
    "    R2, t2 = R, t\n",
    "    \n",
    "    n_valid = 0\n",
    "    for i in range(min(len(pts1), 50)):  # 50点でチェック\n",
    "        X = triangulate_point(K, R1, t1, R2, t2, pts1[i], pts2[i])\n",
    "        \n",
    "        # カメラ1座標でのZ（深度）\n",
    "        z1 = X[2]\n",
    "        \n",
    "        # カメラ2座標での位置\n",
    "        X_cam2 = R @ X + t\n",
    "        z2 = X_cam2[2]\n",
    "        \n",
    "        if z1 > 0 and z2 > 0:\n",
    "            n_valid += 1\n",
    "    \n",
    "    return n_valid\n",
    "\n",
    "def recover_pose_from_essential(E: np.ndarray, K: np.ndarray,\n",
    "                                 pts1: np.ndarray, pts2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"本質行列からカメラ姿勢を復元（正しい解を選択）\"\"\"\n",
    "    solutions = decompose_essential_matrix(E)\n",
    "    \n",
    "    best_R, best_t = None, None\n",
    "    best_count = 0\n",
    "    \n",
    "    print(\"=== 4つの解候補の評価 ===\")\n",
    "    for i, (R, t) in enumerate(solutions):\n",
    "        count = check_cheirality(K, R, t, pts1, pts2)\n",
    "        print(f\"解{i+1}: 有効点数 = {count}\")\n",
    "        \n",
    "        if count > best_count:\n",
    "            best_count = count\n",
    "            best_R, best_t = R, t\n",
    "    \n",
    "    print(f\"\\n選択された解: 有効点数 = {best_count}\")\n",
    "    \n",
    "    return best_R, best_t\n",
    "\n",
    "print(\"本質行列分解の実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本質行列の計算（Fから）\n",
    "E_estimated = K.T @ F_ransac @ K\n",
    "\n",
    "# 特異値の正規化（σ, σ, 0の形式に）\n",
    "U, S, Vt = np.linalg.svd(E_estimated)\n",
    "S_corrected = np.array([(S[0] + S[1]) / 2, (S[0] + S[1]) / 2, 0])\n",
    "E_corrected = U @ np.diag(S_corrected) @ Vt\n",
    "\n",
    "print(\"推定された本質行列 E:\")\n",
    "print(E_corrected)\n",
    "\n",
    "# 姿勢の復元\n",
    "R_recovered, t_recovered = recover_pose_from_essential(E_corrected, K, pts1_noisy[inlier_mask], pts2_noisy[inlier_mask])\n",
    "\n",
    "print(\"\\n=== 復元された姿勢 ===\")\n",
    "print(\"回転行列 R:\")\n",
    "print(R_recovered)\n",
    "print(f\"\\n並進ベクトル t: {t_recovered}\")\n",
    "print(f\"並進方向（正規化）: {t_recovered / np.linalg.norm(t_recovered)}\")\n",
    "\n",
    "# 真の値との比較\n",
    "print(\"\\n=== 真の値との比較 ===\")\n",
    "print(\"真の回転行列 R:\")\n",
    "print(R)\n",
    "print(f\"\\n真の並進方向（正規化）: {t / np.linalg.norm(t)}\")\n",
    "\n",
    "# 回転の誤差（角度）\n",
    "R_error = R_recovered @ R.T\n",
    "angle_error = np.arccos(np.clip((np.trace(R_error) - 1) / 2, -1, 1))\n",
    "print(f\"\\n回転誤差: {np.degrees(angle_error):.2f}度\")\n",
    "\n",
    "# 並進方向の誤差（角度）\n",
    "t_true_norm = t / np.linalg.norm(t)\n",
    "t_recovered_norm = t_recovered / np.linalg.norm(t_recovered)\n",
    "# 符号の不定性を考慮\n",
    "cos_angle = np.abs(np.dot(t_true_norm, t_recovered_norm))\n",
    "translation_angle_error = np.arccos(np.clip(cos_angle, -1, 1))\n",
    "print(f\"並進方向誤差: {np.degrees(translation_angle_error):.2f}度\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pose_recovery():\n",
    "    \"\"\"復元されたカメラ姿勢の可視化\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # カメラ1（原点）\n",
    "    C1 = np.array([0, 0, 0])\n",
    "    \n",
    "    # 真のカメラ2位置（並進ベクトルはカメラ座標での相対位置）\n",
    "    # C2 = -R^T @ t\n",
    "    C2_true = -R.T @ t\n",
    "    \n",
    "    # 復元されたカメラ2位置\n",
    "    C2_recovered = -R_recovered.T @ t_recovered\n",
    "    # スケール調整（真の並進距離に合わせる）\n",
    "    scale = np.linalg.norm(C2_true) / np.linalg.norm(C2_recovered)\n",
    "    C2_recovered_scaled = C2_recovered * scale\n",
    "    \n",
    "    # カメラの描画\n",
    "    def draw_camera(ax, C, R, color, label, scale=0.3):\n",
    "        # カメラの向き（Z軸方向）\n",
    "        z_dir = R.T @ np.array([0, 0, 1])\n",
    "        x_dir = R.T @ np.array([1, 0, 0])\n",
    "        y_dir = R.T @ np.array([0, 1, 0])\n",
    "        \n",
    "        ax.scatter(*C, color=color, s=200, label=label)\n",
    "        ax.quiver(*C, *z_dir * scale, color=color, arrow_length_ratio=0.2, linewidth=2)\n",
    "        ax.quiver(*C, *x_dir * scale * 0.5, color=color, alpha=0.5, arrow_length_ratio=0.2)\n",
    "        ax.quiver(*C, *y_dir * scale * 0.5, color=color, alpha=0.5, arrow_length_ratio=0.2)\n",
    "    \n",
    "    # カメラ1\n",
    "    draw_camera(ax, C1, np.eye(3), 'blue', 'Camera 1')\n",
    "    \n",
    "    # 真のカメラ2\n",
    "    draw_camera(ax, C2_true, R, 'green', 'Camera 2 (True)')\n",
    "    \n",
    "    # 復元されたカメラ2\n",
    "    draw_camera(ax, C2_recovered_scaled, R_recovered, 'red', 'Camera 2 (Recovered)')\n",
    "    \n",
    "    # 3D点（一部）\n",
    "    if len(X_3d) > 0:\n",
    "        ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], \n",
    "                   c='gray', s=20, alpha=0.3, label='3D Points')\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Camera Pose Recovery from Essential Matrix', fontsize=14)\n",
    "    ax.legend()\n",
    "    \n",
    "    # 等軸スケール\n",
    "    max_range = np.array([X_3d[:, 0].max() - X_3d[:, 0].min(),\n",
    "                          X_3d[:, 1].max() - X_3d[:, 1].min(),\n",
    "                          X_3d[:, 2].max() - X_3d[:, 2].min()]).max() / 2.0\n",
    "    mid_x = (X_3d[:, 0].max() + X_3d[:, 0].min()) * 0.5\n",
    "    mid_y = (X_3d[:, 1].max() + X_3d[:, 1].min()) * 0.5\n",
    "    mid_z = (X_3d[:, 2].max() + X_3d[:, 2].min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    ax.view_init(elev=20, azim=-60)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_pose_recovery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. 実践的な注意点\n",
    "\n",
    "### 8.1 退化条件（Degenerate Cases）\n",
    "\n",
    "エピポーラ幾何が決定できない状況：\n",
    "\n",
    "| 条件 | 説明 | 対処法 |\n",
    "|------|------|--------|\n",
    "| **純回転** | カメラが回転のみで移動なし（$\\mathbf{t} = \\mathbf{0}$） | ホモグラフィを使用 |\n",
    "| **平面シーン** | 全点が同一平面上 | ホモグラフィを使用 |\n",
    "| **共線点** | 全点が一直線上 | 避ける |\n",
    "\n",
    "### 8.2 数値安定性\n",
    "\n",
    "1. **点の正規化**: 8点アルゴリズム前に必須\n",
    "2. **RANSAC**: 外れ値に対するロバスト性\n",
    "3. **非線形最適化**: 初期値を線形解で与え、再投影誤差を最小化\n",
    "\n",
    "### 8.3 スケールの不定性\n",
    "\n",
    "単眼カメラからは**絶対スケール**を復元できません。\n",
    "\n",
    "解決方法：\n",
    "- 既知の距離（オブジェクトサイズ、ベースライン長）\n",
    "- IMU との融合\n",
    "- ステレオカメラの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_degenerate_case():\n",
    "    \"\"\"退化条件のデモ: 純回転ケース\"\"\"\n",
    "    print(\"=== 退化条件: 純回転（t = 0）===\")\n",
    "    \n",
    "    # 純回転（並進なし）\n",
    "    theta = np.radians(15)\n",
    "    R_pure = np.array([\n",
    "        [np.cos(theta), 0, np.sin(theta)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(theta), 0, np.cos(theta)]\n",
    "    ])\n",
    "    t_zero = np.array([0, 0, 0])\n",
    "    \n",
    "    # 本質行列\n",
    "    E_pure = compute_essential_matrix(R_pure, t_zero)\n",
    "    \n",
    "    print(\"本質行列 E (純回転):\")\n",
    "    print(E_pure)\n",
    "    print(f\"\\n||E|| = {np.linalg.norm(E_pure):.6f}\")\n",
    "    print(\"→ E ≈ 0 となり、エピポーラ幾何が退化します\")\n",
    "    \n",
    "    print(\"\\n解決策: ホモグラフィ行列 H を使用\")\n",
    "    print(\"平面上の点に対して: x2 = H @ x1\")\n",
    "\n",
    "demonstrate_degenerate_case()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. まとめと次のステップ\n",
    "\n",
    "### 学んだこと\n",
    "\n",
    "1. **エピポーラ幾何の基本**: エピポール、エピポーラ線、エピポーラ面\n",
    "2. **基礎行列 F**: 画像座標間のエピポーラ拘束 $\\mathbf{x}_2^\\top \\mathbf{F} \\mathbf{x}_1 = 0$\n",
    "3. **本質行列 E**: 正規化座標間の拘束、$\\mathbf{E} = [\\mathbf{t}]_\\times \\mathbf{R}$\n",
    "4. **8点アルゴリズム**: 対応点からFを推定\n",
    "5. **RANSAC**: 外れ値に対するロバスト推定\n",
    "6. **Eの分解**: カメラの相対姿勢（R, t）の復元\n",
    "\n",
    "### 重要な数式\n",
    "\n",
    "| 概念 | 数式 |\n",
    "|------|------|\n",
    "| エピポーラ拘束（F） | $\\mathbf{x}_2^\\top \\mathbf{F} \\mathbf{x}_1 = 0$ |\n",
    "| エピポーラ拘束（E） | $\\hat{\\mathbf{x}}_2^\\top \\mathbf{E} \\hat{\\mathbf{x}}_1 = 0$ |\n",
    "| F と E の関係 | $\\mathbf{F} = \\mathbf{K}_2^{-\\top} \\mathbf{E} \\mathbf{K}_1^{-1}$ |\n",
    "| E の構造 | $\\mathbf{E} = [\\mathbf{t}]_\\times \\mathbf{R}$ |\n",
    "| エピポーラ線 | $\\mathbf{l}_2 = \\mathbf{F} \\mathbf{x}_1$ |\n",
    "\n",
    "### 次のノートブック\n",
    "\n",
    "**56. ステレオ視と視差**では：\n",
    "- ステレオ画像ペアの整列（Rectification）\n",
    "- 視差（Disparity）マップの計算\n",
    "- ブロックマッチングアルゴリズム\n",
    "- 深度マップの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. 自己評価クイズ\n",
    "\n",
    "以下の質問に答えて理解度を確認しましょう：\n",
    "\n",
    "1. **エピポール** $\\mathbf{e}_1$ は何を表しますか？\n",
    "\n",
    "2. エピポーラ拘束 $\\mathbf{x}_2^\\top \\mathbf{F} \\mathbf{x}_1 = 0$ の幾何学的な意味は？\n",
    "\n",
    "3. 基礎行列 $\\mathbf{F}$ のランクが2である理由は？\n",
    "\n",
    "4. 本質行列 $\\mathbf{E}$ と基礎行列 $\\mathbf{F}$ の違いは何ですか？\n",
    "\n",
    "5. 8点アルゴリズムで「正規化」が重要な理由は？\n",
    "\n",
    "6. RANSACが必要な理由は何ですか？\n",
    "\n",
    "7. 本質行列の分解で4つの解候補が出る理由と、正しい解を選ぶ方法は？\n",
    "\n",
    "8. 純回転（$\\mathbf{t} = \\mathbf{0}$）の場合、なぜエピポーラ幾何が退化するのですか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クイズの解答（隠し）\n",
    "def show_quiz_answers():\n",
    "    answers = \"\"\"\n",
    "    === 自己評価クイズ解答 ===\n",
    "    \n",
    "    1. エピポール e₁ は、カメラ2の光学中心をカメラ1の画像面に投影した点です。\n",
    "       ベースラインと画像面の交点とも言えます。\n",
    "    \n",
    "    2. 画像1の点x₁と対応する点x₂は、画像2上のエピポーラ線l₂ = Fx₁上に\n",
    "       必ず存在するという拘束条件を表します。\n",
    "    \n",
    "    3. rank(F) = 2 である理由：\n",
    "       - Fはエピポールを零空間に持つ（Fe₁ = 0, F^Te₂ = 0）\n",
    "       - これにより1つの特異値が0になり、ランクが2に制限される\n",
    "    \n",
    "    4. 違い：\n",
    "       - F: ピクセル座標で定義、カメラ内部パラメータに依存\n",
    "       - E: 正規化座標で定義、幾何学的情報（R, t）のみを含む\n",
    "       - 関係: E = K₂ᵀFK₁\n",
    "    \n",
    "    5. 正規化の重要性：\n",
    "       - ピクセル座標の値の範囲が大きく、行列Aの条件数が悪化する\n",
    "       - 正規化により数値的に安定した解が得られる\n",
    "    \n",
    "    6. RANSAC が必要な理由：\n",
    "       - 実データには外れ値（誤対応）が含まれる\n",
    "       - 8点アルゴリズムは最小二乗法ベースで外れ値に敏感\n",
    "       - RANSACはロバストに正しい解を見つけられる\n",
    "    \n",
    "    7. 4つの解候補：\n",
    "       - SVD分解の符号の不定性から4通りの(R, t)組み合わせが生じる\n",
    "       - 正しい解の選択：三角測量で3D点を復元し、両カメラの前方（Z > 0）\n",
    "         にある点が最も多い解を選ぶ（チェイラリティ条件）\n",
    "    \n",
    "    8. 純回転での退化：\n",
    "       - t = 0 のとき、E = [t]×R = 0 となる\n",
    "       - ベースラインが存在しないため、エピポーラ幾何が定義できない\n",
    "       - 全ての点が同じ光線上に投影され、深度情報が失われる\n",
    "    \"\"\"\n",
    "    print(answers)\n",
    "\n",
    "# 解答を見るには以下のコメントを外して実行\n",
    "# show_quiz_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ナビゲーション\n",
    "\n",
    "- **前のノートブック**: [54. カメラキャリブレーション](54_camera_calibration_v1.ipynb)\n",
    "- **次のノートブック**: [56. ステレオ視と視差](56_stereo_vision_disparity_v1.ipynb)\n",
    "- **カリキュラム**: [CURRICULUM_UNIT_0.3.md](CURRICULUM_UNIT_0.3.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

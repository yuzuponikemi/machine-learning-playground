# Unit 0.3: 知覚と空間 - 3D Computer Vision 基礎

## カリキュラム概要

このユニットは、統計・MLの「平面的なデータ処理」から「物理的な3D空間」へ認識を拡張するためのゲートウェイです。
NeoVerseのような最新4D技術のコード（camera_intrinsics, extrinsics, pose）を読み解くための「空間の文法」を習得します。

**このユニットの特徴:**
- 光学・物理学の原理から出発し、数学的モデルへ接続
- 「なぜそうなるのか」を重視した深い理解
- 最新技術（NeRF/3DGS/Gaussian Splatting）への明確な橋渡し

---

## 学習ロードマップ

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     Unit 0.3 学習ロードマップ                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [Phase 1: 光と画像形成の物理]                                            │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │ Notebook 50 │───→│ Notebook 51 │───→│ Notebook 52 │                  │
│  │ 光学基礎    │    │ カメラ射影  │    │ レンズ・歪み │                  │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
│         │                                    │                          │
│         └────────────────┬───────────────────┘                          │
│                          ▼                                              │
│  [Phase 2: 座標系と変換]                                                  │
│  ┌─────────────┐    ┌─────────────┐                                     │
│  │ Notebook 53 │───→│ Notebook 54 │                                     │
│  │ 座標変換    │    │ キャリブレ  │                                     │
│  └─────────────┘    └─────────────┘                                     │
│                          │                                              │
│                          ▼                                              │
│  [Phase 3: 多視点幾何]                                                    │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │ Notebook 55 │───→│ Notebook 56 │───→│ Notebook 57 │                  │
│  │ エピポーラ  │    │ ステレオ視  │    │ 三角測量    │                  │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
│                                              │                          │
│                          ┌───────────────────┘                          │
│                          ▼                                              │
│  [Phase 4: 3D復元]                                                       │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │ Notebook 58 │───→│ Notebook 59 │───→│ Notebook 60 │                  │
│  │ 特徴点      │    │ SfM基礎     │    │ バンドル調整│                  │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
│                                              │                          │
│                          ┌───────────────────┘                          │
│                          ▼                                              │
│  [Phase 5: Neural Rendering への橋渡し]                                   │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │ Notebook 61 │───→│ Notebook 62 │───→│ Notebook 63 │                  │
│  │ Ray Casting │    │ Volume Rend │    │ NeRF入門    │                  │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Phase 1: 光と画像形成の物理

### Notebook 50: 光学の基礎 (`50_optics_fundamentals_v1.ipynb`)

**学習目標**:
- [ ] 光の性質（波動性・粒子性）と画像形成の関係を理解する
- [ ] 幾何光学の基本法則（反射・屈折）を説明できる
- [ ] レンズの結像原理と薄レンズの式を導出できる
- [ ] 焦点距離・F値・被写界深度の関係を理解する

**前提知識**:
- ✅ 高校物理（波動、光学）
- ✅ 基礎的な微積分

**難易度**: ★★☆☆☆（初級〜中級）
**推定学習時間**: 120-150分

**主要内容**:

1. **光の性質**
   - 電磁波としての光（波長と色）
   - 可視光スペクトル (380-780nm)
   - 光の速度と屈折率
   - 回折と干渉（なぜレンズが必要か）

2. **幾何光学の基本法則**
   - **反射の法則**: 入射角 = 反射角
   - **スネルの法則**: $n_1 \sin\theta_1 = n_2 \sin\theta_2$
   - 全反射と臨界角
   - プリズムによる分散

3. **レンズの結像**
   - 凸レンズ・凹レンズの原理
   - **薄レンズの式**: $\frac{1}{f} = \frac{1}{d_o} + \frac{1}{d_i}$
   - 倍率: $M = -\frac{d_i}{d_o}$
   - 実像と虚像

4. **カメラ光学パラメータ**
   - **焦点距離 (f)**: 結像特性の決定
   - **F値 (絞り)**: $F = \frac{f}{D}$ (Dは開口径)
   - **被写界深度 (DoF)**: ピントが合う範囲
   - Circle of Confusion（錯乱円）

5. **露出の三角形**
   ```
        シャッタースピード
              △
             / \
            /   \
           /     \
          /       \
         /_________\
     ISO感度      絞り(F値)
   ```
   - 各パラメータのトレードオフ
   - 明るさとノイズ、ボケの関係

**実践演習**:
- 薄レンズシミュレータの実装
- 被写界深度計算器
- 露出パラメータの視覚化

---

### Notebook 51: ピンホールカメラと射影モデル (`51_pinhole_projection_model_v1.ipynb`)

**学習目標**:
- [ ] ピンホールカメラモデルの幾何学的意味を理解する
- [ ] 内部パラメータ行列 K を構成・操作できる
- [ ] 3D点から2D画像座標への射影を実装できる
- [ ] 同次座標と射影幾何の基礎を理解する

**前提知識**:
- ✅ Notebook 50（光学基礎）
- ✅ 線形代数（行列演算）

**難易度**: ★★★☆☆（中級）
**推定学習時間**: 120-150分

**主要内容**:

1. **なぜピンホールモデルか**
   - レンズモデルの簡略化
   - 「理想的なカメラ」としてのピンホール
   - ピンホール → 実レンズへの拡張

2. **ピンホールカメラの幾何学**
   - 光学中心（カメラ中心）
   - 撮像面と焦点距離
   - 類似三角形による像の形成
   - **基本射影式**:
     ```
     x = f * X / Z
     y = f * Y / Z
     ```

3. **座標系の定義**
   - ワールド座標系
   - カメラ座標系
   - 画像座標系（正規化座標、ピクセル座標）
   - 各座標系間の関係

4. **内部パラメータ行列 K**
   ```
   K = | f_x  γ   c_x |
       |  0  f_y  c_y |
       |  0   0    1  |
   ```
   - 焦点距離 (f_x, f_y): センサーサイズとの関係
   - 主点 (c_x, c_y): 光軸と撮像面の交点
   - スキュー γ: 通常は0（非直交ピクセル）
   - アスペクト比

5. **同次座標と射影**
   - なぜ同次座標を使うのか
   - 射影変換の行列表現
   - 無限遠点の扱い
   - **完全な射影式**:
     ```
     s * [u, v, 1]^T = K @ [X, Y, Z]^T
     ```

6. **画角（Field of View）**
   - 水平・垂直・対角FOV
   - 焦点距離との関係: $\text{FOV} = 2 \arctan\left(\frac{W}{2f}\right)$
   - センサーサイズの影響（クロップファクター）

**実践演習**:
- 3D立方体の2D射影
- 焦点距離変化による画角の可視化
- 「ズーム」vs「接近」の違い

---

### Notebook 52: レンズ歪みと補正 (`52_lens_distortion_correction_v1.ipynb`)

**学習目標**:
- [ ] レンズ歪みの物理的原因を理解する
- [ ] 放射歪み・接線歪みの数学モデルを実装できる
- [ ] Brown-Conradyモデルを説明できる
- [ ] 歪み補正アルゴリズムを実装できる

**前提知識**:
- ✅ Notebook 50-51（光学、射影モデル）

**難易度**: ★★★☆☆（中級）
**推定学習時間**: 90-120分

**主要内容**:

1. **レンズ歪みの原因**
   - 理想レンズ vs 実際のレンズ
   - 収差（Aberration）の種類
     - 球面収差
     - コマ収差
     - 非点収差
     - 像面湾曲
     - 歪曲収差 ← 主な対象

2. **放射歪み（Radial Distortion）**
   - **樽型歪み（Barrel）**: 広角レンズで顕著
   - **糸巻き型歪み（Pincushion）**: 望遠レンズで顕著
   - **口髭型歪み（Mustache）**: 複合型

   ```
   樽型        糸巻き型      口髭型
   ┌───┐      ┌───┐       ┌───┐
   │) (│      │( )│       │)(│
   │) (│      │( )│       │()│
   │) (│      │( )│       │)(│
   └───┘      └───┘       └───┘
   ```

3. **数学モデル**
   - **放射歪み**:
     ```
     x_d = x(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)
     y_d = y(1 + k_1 r^2 + k_2 r^4 + k_3 r^6)
     ```
   - **接線歪み（Tangential Distortion）**:
     ```
     x_d = x + [2p_1 xy + p_2(r^2 + 2x^2)]
     y_d = y + [p_1(r^2 + 2y^2) + 2p_2 xy]
     ```

4. **Brown-Conradyモデル**
   - 歪み係数: [k_1, k_2, p_1, p_2, k_3, ...]
   - OpenCVでの表現
   - 高次項の必要性

5. **魚眼レンズモデル**
   - 等距離射影（Equidistant）
   - 等立体角射影（Equisolid）
   - 正射影（Orthographic）
   - 立体射影（Stereographic）

6. **歪み補正アルゴリズム**
   - 前方マッピング vs 逆マッピング
   - バイリニア補間
   - `cv2.undistort()` の内部動作
   - リマッピングテーブル

**実践演習**:
- 歪み画像の生成
- 歪み補正の実装
- 魚眼レンズシミュレーション

---

## Phase 2: 座標系と変換

### Notebook 53: 3D座標変換と剛体運動 (`53_coordinate_transforms_rigid_motion_v1.ipynb`)

**学習目標**:
- [ ] 剛体変換（回転・並進）を理解し実装できる
- [ ] 回転の複数の表現方法を相互変換できる
- [ ] SE(3)群の基本的な性質を理解する
- [ ] 座標系間の変換を正しく適用できる

**前提知識**:
- ✅ 線形代数（行列、固有値）
- ✅ Notebook 51（座標系の定義）

**難易度**: ★★★★☆（上級）
**推定学習時間**: 150-180分

**主要内容**:

1. **剛体運動の数学**
   - 剛体変換とは（距離・角度を保存）
   - 自由度: 6 DoF（3回転 + 3並進）
   - 変換の合成

2. **回転の表現方法**

   | 表現 | パラメータ数 | 特徴 |
   |-----|------------|------|
   | 回転行列 | 9 (実質3) | 直感的、冗長 |
   | オイラー角 | 3 | ジンバルロック問題 |
   | 軸角度 | 4 (軸3+角度1) | 幾何学的に明確 |
   | ロドリゲス | 3 | コンパクト |
   | クォータニオン | 4 | 補間に最適、特異点なし |

3. **回転行列**
   - SO(3)群: $R^T R = I$, $\det(R) = 1$
   - 基本回転行列 $R_x, R_y, R_z$
   - 内在的 vs 外在的回転

4. **オイラー角とジンバルロック**
   - Roll-Pitch-Yaw vs Yaw-Pitch-Roll
   - 12通りの回転順序
   - ジンバルロック: なぜ起こるか、どう避けるか

5. **ロドリゲスの公式**
   ```
   R = I + sin(θ)[k]× + (1-cos(θ))[k]×²
   ```
   - 歪対称行列 [k]×
   - 指数写像: so(3) → SO(3)

6. **クォータニオン**
   - 定義: $q = w + xi + yj + zk$
   - 回転の表現: $q = \cos(\theta/2) + \sin(\theta/2)(u_x i + u_y j + u_z k)$
   - SLERP補間
   - 回転行列との相互変換

7. **同次変換行列**
   ```
   T = | R  t |    ∈ SE(3)
       | 0  1 |
   ```
   - 逆変換: $T^{-1}$
   - 変換の合成: $T_1 \cdot T_2$

8. **座標系間の変換**
   - ワールド → カメラ
   - カメラ → 画像
   - フレーム間変換

**実践演習**:
- 回転表現の相互変換
- ジンバルロックの可視化
- クォータニオン補間

---

### Notebook 54: カメラキャリブレーション (`54_camera_calibration_v1.ipynb`)

**学習目標**:
- [ ] カメラキャリブレーションの目的と手法を理解する
- [ ] Zhang法（平面パターン法）を説明できる
- [ ] OpenCVでキャリブレーションを実行できる
- [ ] キャリブレーション精度の評価方法を理解する

**前提知識**:
- ✅ Notebook 51-53（射影モデル、歪み、座標変換）

**難易度**: ★★★★☆（上級）
**推定学習時間**: 150-180分

**主要内容**:

1. **キャリブレーションの目的**
   - 内部パラメータの推定
   - 歪み係数の推定
   - 外部パラメータの推定（オプション）

2. **キャリブレーションターゲット**
   - チェッカーボード（最も一般的）
   - 円グリッド（ChArUco）
   - AprilTag / ArUco マーカー
   - ターゲットの設計考慮点

3. **Zhang法（平面パターン法）**
   - ホモグラフィの推定
   - 内部パラメータの初期推定
   - 非線形最適化による精緻化

   **手順**:
   ```
   1. 複数の角度から平面パターンを撮影
   2. 各画像でコーナー検出
   3. ホモグラフィ H を推定
   4. H から K の制約を導出
   5. K を閉形式で解く
   6. 歪み係数を含めた非線形最適化
   ```

4. **ホモグラフィと内部パラメータ**
   - 平面とその像の関係
   - $H = K[r_1 | r_2 | t]$
   - 制約条件: $h_1^T K^{-T} K^{-1} h_2 = 0$

5. **実装詳細**
   - `cv2.findChessboardCorners()`
   - `cv2.cornerSubPix()`（サブピクセル精度）
   - `cv2.calibrateCamera()`
   - フラグオプション（固定主点、ゼロスキューなど）

6. **キャリブレーション精度の評価**
   - 再投影誤差（RMS）
   - 残差の分布
   - パラメータの信頼区間
   - 画像数と精度の関係

7. **ステレオキャリブレーション**
   - 2台のカメラの相対姿勢
   - 平行化（Rectification）

8. **実用的な考慮事項**
   - 照明条件
   - パターンのサイズと配置
   - 画像数の目安（15-25枚）
   - オンラインキャリブレーション

**実践演習**:
- チェッカーボード画像でのキャリブレーション
- 再投影誤差の可視化
- パラメータの感度分析

---

## Phase 3: 多視点幾何

### Notebook 55: エピポーラ幾何の理論 (`55_epipolar_geometry_theory_v1.ipynb`)

**学習目標**:
- [ ] エピポーラ幾何の基本概念を説明できる
- [ ] 基礎行列 F と本質行列 E の違いを理解する
- [ ] エピポーラ拘束を導出できる
- [ ] 8点アルゴリズムを実装できる

**前提知識**:
- ✅ Notebook 51-54（射影モデル、座標変換）
- ✅ 特異値分解（SVD）の基礎

**難易度**: ★★★★★（上級）
**推定学習時間**: 180-210分

**主要内容**:

1. **2視点幾何の基本概念**

   ```
   カメラ1        エピポーラ平面       カメラ2
      O₁ ←────────────────────────→ O₂
       \           ／|\              /
        \         / | \            /
         \       /  |  \          /
          \     /   |   \        /
           \   /    |    \      /
            \ /     |     \    /
             X ─────+───── X'
           3D点   エピポーラ線
   ```

   - **エピポール (e, e')**: 一方のカメラ中心の他方への投影
   - **エピポーラ平面**: 2つのカメラ中心と3D点を含む平面
   - **エピポーラ線**: エピポーラ平面と撮像面の交線

2. **エピポーラ拘束**
   - 対応点の探索空間を1次元に削減
   - **拘束式**: $\mathbf{x'}^T F \mathbf{x} = 0$
   - 幾何学的意味の理解

3. **本質行列 E (Essential Matrix)**
   - 正規化座標系での関係
   - $E = [t]_\times R$
   - 性質: $\text{rank}(E) = 2$, 2つの等しい特異値

4. **基礎行列 F (Fundamental Matrix)**
   - ピクセル座標系での関係
   - $F = K'^{-T} E K^{-1}$
   - 性質: $\text{rank}(F) = 2$

5. **8点アルゴリズム**
   - 線形方程式系の構築
   - SVDによる解法
   - ランク2制約の強制
   - 正規化の重要性（Hartley正規化）

6. **ロバスト推定**
   - RANSAC
   - MLESAC, PROSAC
   - 外れ値の影響

7. **本質行列の分解**
   - $E \rightarrow R, t$ の抽出
   - 4つの解候補
   - Cheirality条件による選択

**実践演習**:
- エピポーラ線の可視化
- 8点アルゴリズムの実装
- RANSAC-based推定

---

### Notebook 56: ステレオ視と視差 (`56_stereo_vision_disparity_v1.ipynb`)

**学習目標**:
- [ ] ステレオ視の原理を理解する
- [ ] ステレオ平行化（Rectification）を実装できる
- [ ] 視差マップの計算方法を理解する
- [ ] 視差から深度への変換ができる

**前提知識**:
- ✅ Notebook 55（エピポーラ幾何）

**難易度**: ★★★★☆（上級）
**推定学習時間**: 150-180分

**主要内容**:

1. **ステレオ視の原理**
   - 人間の両眼視と深度知覚
   - 視差（Parallax）の概念
   - ベースラインと深度分解能

2. **ステレオ平行化（Rectification）**
   - 目的: エピポーラ線を水平に揃える
   - 平行化後: 対応点探索が1次元に

   ```
   平行化前:              平行化後:
   ╱─────╲   ╱─────╲     ┌─────┐  ┌─────┐
   │  /   │  │   \  │     │ ─── │  │ ─── │
   │ /    │  │    \ │  →  │ ─── │  │ ─── │
   │/     │  │     \│     │ ─── │  │ ─── │
   └─────┘  └─────┘      └─────┘  └─────┘
   ```

3. **視差（Disparity）**
   - 定義: $d = x_L - x_R$
   - **視差と深度の関係**:
     ```
     Z = f * B / d
     ```
     - f: 焦点距離
     - B: ベースライン（カメラ間距離）
     - d: 視差

4. **ステレオマッチング**

   | 手法 | 特徴 | 速度 |
   |-----|------|------|
   | ブロックマッチング | シンプル、局所的 | 高速 |
   | SGM | 複数方向のコスト集約 | 中程度 |
   | Graph Cut | グローバル最適化 | 低速 |
   | 深層学習 | 高精度、訓練データ必要 | GPU依存 |

5. **SGM (Semi-Global Matching)**
   - マッチングコスト計算（SAD, Census等）
   - 複数方向からのコスト集約
   - 視差選択（WTA, サブピクセル精度）
   - 後処理（メディアンフィルタ、左右整合性チェック）

6. **視差マップの品質評価**
   - 遮蔽領域の扱い
   - テクスチャレス領域
   - 反復パターン問題

**実践演習**:
- ステレオ平行化の実装
- SGMによる視差計算
- 視差 → 深度変換

---

### Notebook 57: 三角測量と3D復元 (`57_triangulation_3d_reconstruction_v1.ipynb`)

**学習目標**:
- [ ] 三角測量の原理を理解し実装できる
- [ ] 線形・非線形三角測量の違いを説明できる
- [ ] 復元の精度に影響する要因を理解する
- [ ] 点群を生成・可視化できる

**前提知識**:
- ✅ Notebook 55-56（エピポーラ幾何、ステレオ視）

**難易度**: ★★★★☆（上級）
**推定学習時間**: 120-150分

**主要内容**:

1. **三角測量の原理**
   - 2視点からの光線交差
   - 理想的なケース vs 実際のケース
   - ノイズの影響

2. **線形三角測量（DLT法）**
   - 同次座標での定式化
   - $A\mathbf{X} = 0$ の構築
   - SVDによる解法

   ```
   A = | x₁(P₁[2,:]) - P₁[0,:] |
       | y₁(P₁[2,:]) - P₁[1,:] |
       | x₂(P₂[2,:]) - P₂[0,:] |
       | y₂(P₂[2,:]) - P₂[1,:] |
   ```

3. **最小二乗法による三角測量**
   - 中点法（Midpoint method）
   - 幾何学的誤差の最小化
   - 各手法の比較

4. **非線形最適化**
   - 再投影誤差の最小化
   - Levenberg-Marquardt法
   - 初期値の重要性

5. **多視点三角測量**
   - 3視点以上からの復元
   - 重み付け最小二乗
   - ロバスト推定

6. **精度に影響する要因**
   - ベースライン / 距離 比
   - 角度分解能
   - 画像ノイズ
   - キャリブレーション精度

7. **密な点群の生成**
   - 視差マップからの変換
   - 点群のフィルタリング
   - 法線推定

**実践演習**:
- DLT三角測量の実装
- 非線形最適化との比較
- 点群の可視化

---

## Phase 4: 3D復元

### Notebook 58: 特徴点検出とマッチング (`58_feature_detection_matching_v1.ipynb`)

**学習目標**:
- [ ] 特徴点検出器の原理を理解する
- [ ] 特徴量記述子の役割を説明できる
- [ ] SIFT/ORB/SuperPointを使い分けられる
- [ ] ロバストなマッチングを実装できる

**前提知識**:
- ✅ 画像処理の基礎（フィルタ、エッジ検出）

**難易度**: ★★★☆☆（中級）
**推定学習時間**: 120-150分

**主要内容**:

1. **特徴点とは何か**
   - 「良い特徴点」の条件
     - 再現性（Repeatability）
     - 識別性（Distinctiveness）
     - 局所性（Locality）
     - 効率性（Efficiency）

2. **コーナー検出**
   - Harris Corner Detector
   - Shi-Tomasi (Good Features to Track)
   - 数学的背景: 構造テンソル

3. **スケール不変特徴**
   - **SIFT (Scale-Invariant Feature Transform)**
     - DoG (Difference of Gaussians)
     - キーポイントの局所化
     - 向きの割り当て
     - 128次元記述子

   - **SURF (Speeded Up Robust Features)**
     - Hessian行列近似
     - 積分画像による高速化

4. **バイナリ特徴**
   - **ORB (Oriented FAST and Rotated BRIEF)**
     - FASTコーナー検出
     - rBRIEF記述子
     - リアルタイム性能

   - **AKAZE**
     - 非線形スケール空間

5. **深層学習ベース特徴**
   - **SuperPoint**
   - **D2-Net**
   - **DISK**
   - 訓練 vs 推論

6. **特徴量マッチング**
   - 最近傍探索
   - Lowe's ratio test
   - 相互最近傍（Cross-check）
   - FLANN vs Brute-force

7. **外れ値除去**
   - RANSAC
   - 幾何学的検証
   - GMS (Grid-based Motion Statistics)

**実践演習**:
- 各検出器の比較実験
- ロバストマッチングの実装
- 計算時間とのトレードオフ

---

### Notebook 59: Structure from Motion 基礎 (`59_sfm_pipeline_basics_v1.ipynb`)

**学習目標**:
- [ ] SfMの全体的な流れを説明できる
- [ ] 2視点復元を実装できる
- [ ] 増分SfMの原理を理解する
- [ ] PnP問題を解ける

**前提知識**:
- ✅ Notebook 55-58（エピポーラ幾何、特徴点マッチング）

**難易度**: ★★★★★（上級）
**推定学習時間**: 180-240分

**主要内容**:

1. **SfMの概要**
   ```
   入力: N枚の画像
         ↓
   ┌─────────────────────┐
   │  特徴点検出・マッチング │
   └─────────────────────┘
         ↓
   ┌─────────────────────┐
   │    初期ペアの復元     │
   └─────────────────────┘
         ↓
   ┌─────────────────────┐
   │  画像の逐次追加 (PnP) │
   │  + 新規3D点の追加     │
   │  + バンドル調整       │
   └─────────────────────┘
         ↓
   出力: カメラポーズ + 疎点群
   ```

2. **2視点復元（初期化）**
   - 初期ペアの選択基準
   - 本質行列の推定
   - ポーズ分解
   - 三角測量

3. **PnP (Perspective-n-Point)**
   - 既知の3D点から新規カメラポーズを推定
   - P3P, EPnP, DLT
   - RANSAC-based PnP

4. **増分SfM**
   - 新規画像の登録
   - 2D-3D対応の確立
   - 新規3D点の三角測量
   - トラックの管理

5. **グローバルSfM**
   - 回転の平均化
   - 並進の平均化
   - 増分SfMとの比較

6. **スケールの曖昧性**
   - 単眼SfMの本質的限界
   - スケール復元の方法
     - 既知の物体
     - IMU
     - GPS

**実践演習**:
- ミニSfMパイプラインの実装
- COLMAPの使用
- 結果の評価

---

### Notebook 60: バンドル調整 (`60_bundle_adjustment_v1.ipynb`)

**学習目標**:
- [ ] バンドル調整の目的を説明できる
- [ ] 再投影誤差を定義・計算できる
- [ ] 非線形最小二乗問題としての定式化を理解する
- [ ] 疎なヤコビ行列の構造を理解する

**前提知識**:
- ✅ Notebook 59（SfMパイプライン）
- ✅ 最適化の基礎（勾配降下法）

**難易度**: ★★★★★（上級）
**推定学習時間**: 180-210分

**主要内容**:

1. **バンドル調整とは**
   - 「光線の束（bundle）を調整」
   - カメラポーズと3D点を同時最適化
   - SfMパイプラインの中核

2. **問題の定式化**
   ```
   min_{θ_i, X_j} Σ_{i,j} ρ( ||x_ij - π(θ_i, X_j)||² )
   ```
   - $\theta_i$: カメラiのパラメータ（ポーズ、内部パラメータ）
   - $X_j$: 3D点jの座標
   - $x_{ij}$: 画像iでの点jの観測
   - $\pi$: 射影関数
   - $\rho$: ロバストカーネル

3. **再投影誤差**
   - 幾何学的意味
   - 計算方法
   - 可視化

4. **ヤコビ行列の構造**
   ```
   J = | ∂r/∂θ₁  ...  ∂r/∂θₘ | ∂r/∂X₁  ...  ∂r/∂Xₙ |

       カメラパラメータ部分    3D点パラメータ部分
   ```
   - 疎性（Sparsity）
   - ブロック構造

5. **Schur補完**
   - 3D点の消去
   - 縮小カメラ系の解法
   - 計算量の削減

6. **最適化アルゴリズム**
   - Gauss-Newton法
   - **Levenberg-Marquardt法**
   - 減衰パラメータの調整

7. **パラメータ化**
   - 回転の表現（クォータニオン vs ロドリゲス）
   - ゲージ自由度の固定
   - 正則化

8. **ロバスト推定**
   - Huberカーネル
   - Cauchyカーネル
   - Tukey's biweight

9. **実装ツール**
   - Ceres Solver
   - g2o
   - GTSAM

**実践演習**:
- 再投影誤差の計算と可視化
- SciPyによる簡易バンドル調整
- 最適化前後の比較

---

## Phase 5: Neural Renderingへの橋渡し

### Notebook 61: Ray Castingと座標系 (`61_ray_casting_coordinates_v1.ipynb`)

**学習目標**:
- [ ] カメラからの光線（ray）を数学的に表現できる
- [ ] 画像ピクセルから3D光線を生成できる
- [ ] 光線上の点をサンプリングできる
- [ ] NDC（Normalized Device Coordinates）を理解する

**前提知識**:
- ✅ Notebook 51-53（カメラモデル、座標変換）

**難易度**: ★★★★☆（上級）
**推定学習時間**: 120-150分

**主要内容**:

1. **光線の表現**
   ```
   r(t) = o + t * d
   ```
   - o: 光線の原点（カメラ中心）
   - d: 光線の方向（正規化）
   - t: 光線パラメータ (t > 0 で前方)

2. **ピクセル→光線の変換**
   ```python
   def get_ray(u, v, K, c2w):
       # ピクセル → カメラ座標系の方向
       d_cam = K_inv @ [u, v, 1]
       # カメラ → ワールド座標系
       d_world = c2w[:3, :3] @ d_cam
       d_world = d_world / norm(d_world)
       # 原点
       o_world = c2w[:3, 3]
       return o_world, d_world
   ```

3. **画像全体の光線生成**
   - メッシュグリッドの活用
   - バッチ処理
   - GPUフレンドリーな実装

4. **光線上のサンプリング**
   - **均一サンプリング**
   - **階層的サンプリング（NeRF）**
   - **重要度サンプリング**
   - near/far平面の設定

5. **座標系の正規化**
   - シーンのバウンディングボックス
   - 正規化の方法
   - なぜ正規化が重要か

6. **NDC (Normalized Device Coordinates)**
   - 無限遠シーンの扱い
   - 射影変換
   - NeRFでの使用

7. **カメラポーズの慣例**
   - c2w (camera-to-world) vs w2c (world-to-camera)
   - OpenGL vs OpenCV慣例
   - 変換の確認方法

**実践演習**:
- 光線の3D可視化
- サンプル点の可視化
- カメラの視錐台描画

---

### Notebook 62: ボリュームレンダリング (`62_volume_rendering_v1.ipynb`)

**学習目標**:
- [ ] ボリュームレンダリングの原理を理解する
- [ ] レンダリング方程式を導出・実装できる
- [ ] 離散化と数値積分を実装できる
- [ ] 透過率と不透明度の関係を理解する

**前提知識**:
- ✅ Notebook 61（Ray Casting）
- ✅ 微積分（積分）

**難易度**: ★★★★★（上級）
**推定学習時間**: 150-180分

**主要内容**:

1. **ボリュームレンダリングとは**
   - ボクセル表現 vs 暗黙的表現
   - 医療画像、科学可視化での応用
   - NeRFとの関連

2. **物理モデル**
   - 吸収（Absorption）
   - 放射（Emission）
   - 散乱（Scattering）- 簡略化して無視

3. **レンダリング方程式**
   - **連続形式**:
     ```
     C(r) = ∫_{t_n}^{t_f} T(t) σ(r(t)) c(r(t)) dt

     T(t) = exp(-∫_{t_n}^{t} σ(r(s)) ds)
     ```
   - T(t): 透過率（transmittance）
   - σ: 密度（density）
   - c: 色（color/radiance）

4. **離散化**
   ```
   C = Σ_{i=1}^{N} T_i α_i c_i

   T_i = Π_{j=1}^{i-1} (1 - α_j)
   α_i = 1 - exp(-σ_i δ_i)
   ```
   - $\delta_i$: サンプル間隔
   - アルファ合成との関係

5. **数値積分の実装**
   - 前方から後方へ（Front-to-back）
   - 後方から前方へ（Back-to-front）
   - 早期終了（Early termination）

6. **深度の推定**
   ```
   D = Σ_{i=1}^{N} T_i α_i t_i
   ```

7. **勾配の計算**
   - 自動微分
   - 手動導出
   - メモリ効率

**実践演習**:
- ボリュームレンダリングの実装
- 簡単な3Dシーンのレンダリング
- 深度マップの生成

---

### Notebook 63: NeRF入門 (`63_nerf_introduction_v1.ipynb`)

**学習目標**:
- [ ] NeRFの基本アーキテクチャを説明できる
- [ ] 位置エンコーディングの役割を理解する
- [ ] 訓練パイプラインを実装できる
- [ ] NeRFの限界と発展を理解する

**前提知識**:
- ✅ Notebook 61-62（Ray Casting、ボリュームレンダリング）
- ✅ PyTorchの基礎
- ✅ 深層学習の基礎（MLP、バックプロパゲーション）

**難易度**: ★★★★★（上級）
**推定学習時間**: 240-300分

**主要内容**:

1. **NeRFの概要**
   - Neural Radiance Field
   - 入力: 位置 (x,y,z) + 視線方向 (θ,φ)
   - 出力: 密度 σ + 色 (r,g,b)
   - 暗黙的な3D表現

2. **ネットワークアーキテクチャ**
   ```
   (x,y,z) → γ(x,y,z) → MLP → σ
                         ↓
               + γ(θ,φ) → MLP → (r,g,b)
   ```
   - 密度は位置のみに依存
   - 色は位置と視線方向に依存
   - スキップ接続

3. **位置エンコーディング**
   ```
   γ(p) = [sin(2^0 π p), cos(2^0 π p), ...,
           sin(2^{L-1} π p), cos(2^{L-1} π p)]
   ```
   - なぜ必要か（スペクトラルバイアス）
   - 周波数の選択
   - 学習可能なエンコーディング

4. **訓練パイプライン**
   ```
   1. 画像からランダムに光線をサンプル
   2. 光線上の点をサンプル
   3. MLPで密度・色を予測
   4. ボリュームレンダリングで色を計算
   5. 実際のピクセル値との損失
   6. バックプロパゲーション
   ```

5. **階層的サンプリング**
   - Coarse network + Fine network
   - 重要度サンプリング
   - 効率化

6. **実装の詳細**
   - バッチ処理
   - メモリ管理
   - 訓練の安定化

7. **評価指標**
   - PSNR
   - SSIM
   - LPIPS

8. **NeRFの限界と発展**
   - 訓練時間
   - 動的シーン
   - 大規模シーン

   **発展技術**:
   - Instant-NGP（ハッシュエンコーディング）
   - Mip-NeRF（アンチエイリアシング）
   - NeRF in the Wild（外乱対応）
   - 3D Gaussian Splatting

**実践演習**:
- 簡易NeRFの実装（2D → 3D）
- Tiny NeRFでの訓練
- 新規視点合成

---

## プロジェクト構成

```
notebooks/3d-vision/
├── CURRICULUM_UNIT_0.3.md              # このファイル
│
├── # Phase 1: 光と画像形成の物理
├── 50_optics_fundamentals_v1.ipynb
├── 51_pinhole_projection_model_v1.ipynb
├── 52_lens_distortion_correction_v1.ipynb
│
├── # Phase 2: 座標系と変換
├── 53_coordinate_transforms_rigid_motion_v1.ipynb
├── 54_camera_calibration_v1.ipynb
│
├── # Phase 3: 多視点幾何
├── 55_epipolar_geometry_theory_v1.ipynb
├── 56_stereo_vision_disparity_v1.ipynb
├── 57_triangulation_3d_reconstruction_v1.ipynb
│
├── # Phase 4: 3D復元
├── 58_feature_detection_matching_v1.ipynb
├── 59_sfm_pipeline_basics_v1.ipynb
├── 60_bundle_adjustment_v1.ipynb
│
├── # Phase 5: Neural Renderingへの橋渡し
├── 61_ray_casting_coordinates_v1.ipynb
├── 62_volume_rendering_v1.ipynb
├── 63_nerf_introduction_v1.ipynb
│
└── utils/
    ├── __init__.py
    ├── geometry_tools.py       # 回転行列、座標変換
    ├── camera_utils.py         # カメラ関連ユーティリティ
    ├── feature_utils.py        # 特徴点関連
    ├── sfm_utils.py            # SfM関連
    ├── rendering_utils.py      # レンダリング関連
    └── visualizer.py           # 3D可視化ヘルパー
```

---

## 重要な数式まとめ

### 光学

| 数式 | 意味 |
|------|------|
| $n_1 \sin\theta_1 = n_2 \sin\theta_2$ | スネルの法則 |
| $\frac{1}{f} = \frac{1}{d_o} + \frac{1}{d_i}$ | 薄レンズの式 |
| $F = \frac{f}{D}$ | F値の定義 |
| $\text{DoF} \approx \frac{2u^2 N c}{f^2}$ | 被写界深度の近似 |

### 射影

| 数式 | 意味 |
|------|------|
| $s[u,v,1]^T = K[R\|t]P$ | 完全な射影モデル |
| $\text{FOV} = 2\arctan\left(\frac{W}{2f}\right)$ | 画角 |
| $x_d = x(1 + k_1 r^2 + k_2 r^4)$ | 放射歪み |

### エピポーラ幾何

| 数式 | 意味 |
|------|------|
| $\mathbf{x'}^T F \mathbf{x} = 0$ | エピポーラ拘束 |
| $E = [t]_\times R$ | 本質行列の分解 |
| $F = K'^{-T} E K^{-1}$ | 基礎行列と本質行列の関係 |

### 三角測量と深度

| 数式 | 意味 |
|------|------|
| $Z = \frac{fB}{d}$ | 視差と深度 |
| $A\mathbf{X} = 0$ | DLT三角測量 |

### ボリュームレンダリング

| 数式 | 意味 |
|------|------|
| $\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}$ | 光線の表現 |
| $C = \sum_i T_i \alpha_i c_i$ | 離散ボリュームレンダリング |
| $T_i = \prod_{j<i}(1-\alpha_j)$ | 透過率 |
| $\alpha_i = 1 - e^{-\sigma_i \delta_i}$ | 不透明度 |

---

## 認知の拡張への接続

### 物理から数学へ
このユニットでは、光の物理的性質（波長、屈折、反射）から出発し、それをどのように数学的モデル（行列、最適化）に抽象化するかを学びます。この「物理現象→数学モデル→アルゴリズム」の流れは、あらゆる科学技術の基盤です。

### 視点という主観
カメラパラメータを操作することは、「視点」という主観を数学的に記述し、操作することです：
- 内部パラメータ K: 「目のレンズ」の特性
- 外部パラメータ [R|t]: 「頭の位置と向き」
- 歪み係数: 「目の癖」

### デジタルツインへの応用
SfMとNeRFの知識があれば：
- 「なぜこの角度の映像が足りないのか」→ 特徴点の分布、ベースライン不足
- 「なぜ再現が歪むのか」→ キャリブレーション精度、歪み補正不足
- 「なぜ新規視点がぼやけるのか」→ サンプリング密度、位置エンコーディング

### 問いの種

1. **視点の不在**: NeRFが学習する「3D表現」は、どの視点にも属さない。これは「客観的な形」なのか、それとも「すべての視点の統合」なのか？

2. **情報の補完**: NeRFが訓練画像に写っていない「裏側」を生成するとき、それは「推論」なのか「幻覚」なのか？

3. **スケールの意味**: 単眼SfMで復元された3Dモデルには絶対スケールがない。「大きさ」とは何に対する相対的な概念なのか？

4. **連続と離散**: NeRFは連続的な3D空間を表現するが、訓練データは離散的な画像。この変換で何が失われ、何が生成されるのか？

---

## 推奨ライブラリ

```python
# 必須
numpy                  # 数値計算
matplotlib             # 2D可視化
opencv-python          # 画像処理、キャリブレーション

# 3D可視化
open3d                 # 点群・メッシュ可視化
plotly                 # インタラクティブ3Dプロット
trimesh                # メッシュ処理

# 深層学習
torch                  # PyTorch
torchvision            # 画像処理

# SfM/MVS
pycolmap               # COLMAP Pythonバインディング
kornia                 # 微分可能幾何ライブラリ

# 最適化
scipy                  # 最適化、線形代数
ceres-solver           # 非線形最小二乗（C++、Pythonラッパー）
```

---

## 参考文献・リソース

### 書籍
- **Hartley & Zisserman**, "Multiple View Geometry in Computer Vision" (MVG本) - 多視点幾何のバイブル
- **Szeliski**, "Computer Vision: Algorithms and Applications" (無料PDF公開) - 包括的な教科書
- **Forsyth & Ponce**, "Computer Vision: A Modern Approach" - 良い入門書

### オンラインコース
- **First Principles of Computer Vision** (YouTube) - Shree Nayar教授
- **CS231A: Computer Vision** (Stanford) - 3D CV特化
- **CS231N: Convolutional Neural Networks** (Stanford) - 深層学習CV

### 論文（必読）
- **NeRF**: Mildenhall et al., "NeRF: Representing Scenes as Neural Radiance Fields" (ECCV 2020)
- **3DGS**: Kerbl et al., "3D Gaussian Splatting for Real-Time Radiance Field Rendering" (SIGGRAPH 2023)
- **Instant-NGP**: Muller et al., "Instant Neural Graphics Primitives" (SIGGRAPH 2022)
- **COLMAP**: Schonberger & Frahm, "Structure-from-Motion Revisited" (CVPR 2016)

### 実装リソース
- [COLMAP](https://colmap.github.io/) - 最も信頼性の高いSfM実装
- [Nerfstudio](https://docs.nerf.studio/) - NeRF実装フレームワーク
- [tiny-cuda-nn](https://github.com/NVlabs/tiny-cuda-nn) - 高速ニューラルネットワーク

---

## 学習時間の目安

| Phase | ノートブック数 | 推定時間 |
|-------|-------------|---------|
| Phase 1: 光と画像形成 | 3 | 6-8時間 |
| Phase 2: 座標系と変換 | 2 | 5-6時間 |
| Phase 3: 多視点幾何 | 3 | 8-10時間 |
| Phase 4: 3D復元 | 3 | 9-12時間 |
| Phase 5: Neural Rendering | 3 | 8-11時間 |
| **合計** | **14** | **36-47時間** |

※ 演習時間を含む。個人差あり。

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 56. ステレオ視と視差\n",
    "## Stereo Vision and Disparity\n",
    "\n",
    "---\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このノートブックを完了すると、以下ができるようになります：\n",
    "\n",
    "- [ ] ステレオビジョンの原理と深度推定の仕組みを理解する\n",
    "- [ ] ステレオ画像の平行化（Rectification）の目的と方法を説明できる\n",
    "- [ ] 視差（Disparity）と深度の関係を数学的に記述できる\n",
    "- [ ] ブロックマッチングによる視差計算を実装できる\n",
    "- [ ] SGM（Semi-Global Matching）の概念を理解する\n",
    "- [ ] 視差マップから深度マップを生成できる\n",
    "\n",
    "---\n",
    "\n",
    "## 前提知識\n",
    "\n",
    "- 51: ピンホールカメラモデルと射影変換\n",
    "- 55: エピポーラ幾何の理論\n",
    "- 線形代数：ホモグラフィ、行列演算\n",
    "\n",
    "**難易度**: ★★★★☆（上級）  \n",
    "**推定学習時間**: 90-120分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ステレオビジョンとは\n",
    "\n",
    "**ステレオビジョン**は、2台のカメラ（または1台のカメラの2つの位置）から撮影した画像を使って、シーンの3D構造（深度情報）を復元する技術です。\n",
    "\n",
    "### 人間の両眼立体視との類似\n",
    "\n",
    "人間の目は約6.5cm離れており、この差（両眼視差）から脳が深度を知覚します。ステレオビジョンは同じ原理をコンピュータで実現します。\n",
    "\n",
    "### ステレオビジョンのワークフロー\n",
    "\n",
    "```\n",
    "1. カメラキャリブレーション\n",
    "       ↓\n",
    "2. ステレオ平行化（Rectification）\n",
    "       ↓\n",
    "3. 対応点探索（視差計算）\n",
    "       ↓\n",
    "4. 深度マップ生成\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from typing import Tuple, Optional\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ステレオ幾何学の基礎\n",
    "\n",
    "### 2.1 標準ステレオ配置\n",
    "\n",
    "最も単純なステレオ配置は、2台のカメラが**平行**に配置され、**同一平面上**にある場合です。\n",
    "\n",
    "- **ベースライン** $b$: 2つのカメラ中心間の距離\n",
    "- **焦点距離** $f$: カメラの焦点距離（ピクセル単位）\n",
    "- **画像面**: 平行かつ同一平面上\n",
    "\n",
    "### 2.2 視差（Disparity）の定義\n",
    "\n",
    "3D点 $\\mathbf{X} = (X, Y, Z)$ が左画像で $(x_L, y_L)$、右画像で $(x_R, y_R)$ に投影されるとき：\n",
    "\n",
    "$$d = x_L - x_R$$\n",
    "\n",
    "これが**視差（Disparity）**です。\n",
    "\n",
    "### 2.3 深度と視差の関係\n",
    "\n",
    "標準ステレオ配置では：\n",
    "\n",
    "$$Z = \\frac{f \\cdot b}{d}$$\n",
    "\n",
    "ここで：\n",
    "- $Z$: 深度（カメラからの距離）\n",
    "- $f$: 焦点距離（ピクセル）\n",
    "- $b$: ベースライン（実世界の単位、例：メートル）\n",
    "- $d$: 視差（ピクセル）\n",
    "\n",
    "**重要な洞察**: 視差は深度に**反比例**します。近いものほど視差が大きく、遠いものほど視差が小さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stereo_geometry():\n",
    "    \"\"\"ステレオ幾何学の可視化\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # 3Dビュー\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    \n",
    "    # カメラパラメータ\n",
    "    baseline = 0.1  # 10cm\n",
    "    f = 500  # ピクセル\n",
    "    \n",
    "    # カメラ中心\n",
    "    C_L = np.array([-baseline/2, 0, 0])\n",
    "    C_R = np.array([baseline/2, 0, 0])\n",
    "    \n",
    "    # 3D点（異なる深度）\n",
    "    points_3d = np.array([\n",
    "        [0, 0, 1.0],    # 近い点\n",
    "        [0.05, 0, 2.0], # 中距離\n",
    "        [-0.05, 0, 4.0] # 遠い点\n",
    "    ])\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    \n",
    "    # カメラをプロット\n",
    "    ax1.scatter(*C_L, color='purple', s=200, marker='o', label='Left Camera')\n",
    "    ax1.scatter(*C_R, color='orange', s=200, marker='o', label='Right Camera')\n",
    "    \n",
    "    # ベースライン\n",
    "    ax1.plot([C_L[0], C_R[0]], [C_L[1], C_R[1]], [C_L[2], C_R[2]], \n",
    "             'k-', linewidth=2, label=f'Baseline = {baseline*100:.0f}cm')\n",
    "    \n",
    "    # 3D点と光線\n",
    "    for i, (pt, color) in enumerate(zip(points_3d, colors)):\n",
    "        ax1.scatter(*pt, color=color, s=150, marker='*', label=f'Point at Z={pt[2]:.1f}m')\n",
    "        ax1.plot([C_L[0], pt[0]], [C_L[1], pt[1]], [C_L[2], pt[2]], \n",
    "                 color=color, linestyle='--', alpha=0.5)\n",
    "        ax1.plot([C_R[0], pt[0]], [C_R[1], pt[1]], [C_R[2], pt[2]], \n",
    "                 color=color, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_zlabel('Z (Depth)')\n",
    "    ax1.set_title('Stereo Geometry (Top-Down View)', fontsize=12)\n",
    "    ax1.legend(loc='upper left', fontsize=8)\n",
    "    ax1.view_init(elev=30, azim=-60)\n",
    "    \n",
    "    # 視差と深度の関係\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    \n",
    "    depths = np.linspace(0.5, 10, 100)\n",
    "    disparities = f * baseline / depths\n",
    "    \n",
    "    ax2.plot(depths, disparities, 'b-', linewidth=2)\n",
    "    ax2.set_xlabel('Depth Z (m)', fontsize=12)\n",
    "    ax2.set_ylabel('Disparity d (pixels)', fontsize=12)\n",
    "    ax2.set_title('Disparity vs Depth Relationship\\n$d = fb/Z$', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3D点の視差をマーク\n",
    "    for pt, color in zip(points_3d, colors):\n",
    "        d = f * baseline / pt[2]\n",
    "        ax2.scatter(pt[2], d, color=color, s=100, zorder=5)\n",
    "        ax2.annotate(f'Z={pt[2]:.1f}m\\nd={d:.1f}px', \n",
    "                     xy=(pt[2], d), xytext=(pt[2]+0.5, d+5),\n",
    "                     fontsize=9, color=color)\n",
    "    \n",
    "    ax2.set_xlim(0, 10)\n",
    "    ax2.set_ylim(0, max(disparities) * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"パラメータ: f = {f} pixels, baseline = {baseline*100:.0f} cm\")\n",
    "    print(\"\\n視差と深度:\")\n",
    "    for pt in points_3d:\n",
    "        d = f * baseline / pt[2]\n",
    "        print(f\"  Z = {pt[2]:.1f}m → d = {d:.1f} pixels\")\n",
    "\n",
    "visualize_stereo_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ステレオ平行化（Rectification）\n",
    "\n",
    "### 3.1 なぜ平行化が必要か？\n",
    "\n",
    "一般的なステレオ配置では、カメラは完全に平行ではありません。この場合：\n",
    "\n",
    "- エピポーラ線が水平ではない\n",
    "- 対応点探索が2次元探索になる（非効率）\n",
    "\n",
    "**平行化**により：\n",
    "- エピポーラ線を**水平**かつ**同じ行**に揃える\n",
    "- 対応点探索が**1次元の水平探索**に簡略化される\n",
    "\n",
    "### 3.2 平行化の幾何学\n",
    "\n",
    "平行化は、両画像にホモグラフィ変換 $\\mathbf{H}_L$ と $\\mathbf{H}_R$ を適用して、仮想的な平行ステレオ配置を作り出します。\n",
    "\n",
    "$$\\mathbf{x}'_L = \\mathbf{H}_L \\mathbf{x}_L$$\n",
    "$$\\mathbf{x}'_R = \\mathbf{H}_R \\mathbf{x}_R$$\n",
    "\n",
    "変換後：\n",
    "- 対応点は同じ行（同じy座標）に存在\n",
    "- $y'_L = y'_R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rectification_homographies(K: np.ndarray, R: np.ndarray, t: np.ndarray\n",
    "                                       ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"ステレオ平行化のホモグラフィを計算\n",
    "    \n",
    "    Bouguet's algorithmの簡略版\n",
    "    \n",
    "    Args:\n",
    "        K: カメラ内部パラメータ（両カメラ共通と仮定）\n",
    "        R: 右カメラの左カメラに対する回転\n",
    "        t: 右カメラの左カメラに対する並進\n",
    "    \n",
    "    Returns:\n",
    "        H_L, H_R: 左右画像のホモグラフィ\n",
    "    \"\"\"\n",
    "    # 新しいX軸: ベースライン方向（左から右へ）\n",
    "    e1 = t / np.linalg.norm(t)\n",
    "    \n",
    "    # 新しいY軸: 元のZ軸との外積\n",
    "    e2 = np.array([-t[1], t[0], 0])\n",
    "    e2 = e2 / np.linalg.norm(e2) if np.linalg.norm(e2) > 1e-6 else np.array([0, 1, 0])\n",
    "    \n",
    "    # 新しいZ軸: X × Y\n",
    "    e3 = np.cross(e1, e2)\n",
    "    \n",
    "    # 新しい回転行列（世界座標から平行化座標へ）\n",
    "    R_rect = np.vstack([e1, e2, e3])\n",
    "    \n",
    "    # 左カメラの回転（補正なし→平行化）\n",
    "    R_L = R_rect\n",
    "    \n",
    "    # 右カメラの回転（R→平行化）\n",
    "    R_R = R_rect @ R.T\n",
    "    \n",
    "    # ホモグラフィ\n",
    "    H_L = K @ R_L @ np.linalg.inv(K)\n",
    "    H_R = K @ R_R @ np.linalg.inv(K)\n",
    "    \n",
    "    return H_L, H_R\n",
    "\n",
    "def visualize_rectification_effect():\n",
    "    \"\"\"平行化の効果を可視化\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # カメラパラメータ\n",
    "    K = np.array([\n",
    "        [500, 0, 320],\n",
    "        [0, 500, 240],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # 非平行なステレオ配置\n",
    "    theta = np.radians(10)  # 10度回転\n",
    "    R = np.array([\n",
    "        [np.cos(theta), 0, np.sin(theta)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(theta), 0, np.cos(theta)]\n",
    "    ])\n",
    "    t = np.array([0.1, 0.02, 0.01])  # 非理想的な並進\n",
    "    \n",
    "    # 基礎行列\n",
    "    def skew(v):\n",
    "        return np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
    "    \n",
    "    E = skew(t) @ R\n",
    "    F = np.linalg.inv(K).T @ E @ np.linalg.inv(K)\n",
    "    \n",
    "    # テスト点\n",
    "    test_points_L = np.array([\n",
    "        [100, 200], [200, 150], [300, 250], [400, 300], [500, 200]\n",
    "    ])\n",
    "    \n",
    "    img_size = (640, 480)\n",
    "    \n",
    "    # 平行化前：エピポーラ線を描画\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_xlim(0, img_size[0])\n",
    "    ax.set_ylim(img_size[1], 0)\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                fill=True, facecolor='#f0f0f0', edgecolor='black'))\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(test_points_L)))\n",
    "    \n",
    "    for pt, color in zip(test_points_L, colors):\n",
    "        ax.scatter(*pt, color=color, s=100, zorder=5)\n",
    "    \n",
    "    ax.set_title('Left Image (Before Rectification)', fontsize=12)\n",
    "    ax.set_xlabel('u')\n",
    "    ax.set_ylabel('v')\n",
    "    \n",
    "    # 右画像：エピポーラ線\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_xlim(0, img_size[0])\n",
    "    ax.set_ylim(img_size[1], 0)\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                fill=True, facecolor='#f0f0f0', edgecolor='black'))\n",
    "    \n",
    "    for pt, color in zip(test_points_L, colors):\n",
    "        x_h = np.array([pt[0], pt[1], 1])\n",
    "        l = F @ x_h\n",
    "        a, b, c = l\n",
    "        \n",
    "        if abs(b) > 1e-6:\n",
    "            x_vals = np.array([0, img_size[0]])\n",
    "            y_vals = -(a * x_vals + c) / b\n",
    "            ax.plot(x_vals, y_vals, color=color, linewidth=2)\n",
    "    \n",
    "    ax.set_title('Right Image: Epipolar Lines (Non-horizontal)', fontsize=12)\n",
    "    ax.set_xlabel('u')\n",
    "    ax.set_ylabel('v')\n",
    "    \n",
    "    # 平行化後\n",
    "    H_L, H_R = compute_rectification_homographies(K, R, t)\n",
    "    \n",
    "    # 左画像（平行化後）\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_xlim(0, img_size[0])\n",
    "    ax.set_ylim(img_size[1], 0)\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                fill=True, facecolor='#e8f4e8', edgecolor='black'))\n",
    "    \n",
    "    transformed_points = []\n",
    "    for pt, color in zip(test_points_L, colors):\n",
    "        x_h = np.array([pt[0], pt[1], 1])\n",
    "        x_rect = H_L @ x_h\n",
    "        x_rect = x_rect[:2] / x_rect[2]\n",
    "        transformed_points.append(x_rect)\n",
    "        \n",
    "        if 0 <= x_rect[0] <= img_size[0] and 0 <= x_rect[1] <= img_size[1]:\n",
    "            ax.scatter(*x_rect, color=color, s=100, zorder=5)\n",
    "            # 水平線を描画\n",
    "            ax.axhline(y=x_rect[1], color=color, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    ax.set_title('Left Image (After Rectification)', fontsize=12)\n",
    "    ax.set_xlabel('u')\n",
    "    ax.set_ylabel('v')\n",
    "    \n",
    "    # 右画像（平行化後）：水平エピポーラ線\n",
    "    ax = axes[1, 1]\n",
    "    ax.set_xlim(0, img_size[0])\n",
    "    ax.set_ylim(img_size[1], 0)\n",
    "    ax.add_patch(plt.Rectangle((0, 0), img_size[0], img_size[1], \n",
    "                                fill=True, facecolor='#e8f4e8', edgecolor='black'))\n",
    "    \n",
    "    for pt_rect, color in zip(transformed_points, colors):\n",
    "        if 0 <= pt_rect[1] <= img_size[1]:\n",
    "            ax.axhline(y=pt_rect[1], color=color, linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax.set_title('Right Image: Epipolar Lines (Horizontal)', fontsize=12)\n",
    "    ax.set_xlabel('u')\n",
    "    ax.set_ylabel('v')\n",
    "    \n",
    "    plt.suptitle('Effect of Stereo Rectification', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"平行化後、全てのエピポーラ線が水平になります。\")\n",
    "    print(\"これにより、対応点探索が1次元の水平探索に簡略化されます。\")\n",
    "\n",
    "visualize_rectification_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ステレオマッチング\n",
    "\n",
    "### 4.1 問題設定\n",
    "\n",
    "平行化されたステレオ画像ペアに対して、左画像の各ピクセル $(x_L, y)$ に対応する右画像のピクセル $(x_R, y)$ を見つけます。\n",
    "\n",
    "視差: $d = x_L - x_R$\n",
    "\n",
    "### 4.2 マッチングコスト\n",
    "\n",
    "対応点を見つけるため、ピクセル間の類似度（またはコスト）を計算します：\n",
    "\n",
    "| コスト関数 | 式 | 特徴 |\n",
    "|-----------|-----|------|\n",
    "| **SAD** (Sum of Absolute Differences) | $\\sum |I_L - I_R|$ | シンプル、高速 |\n",
    "| **SSD** (Sum of Squared Differences) | $\\sum (I_L - I_R)^2$ | 外れ値に敏感 |\n",
    "| **NCC** (Normalized Cross-Correlation) | $\\frac{\\sum (I_L - \\bar{I}_L)(I_R - \\bar{I}_R)}{\\sigma_L \\sigma_R}$ | 照明変化に強い |\n",
    "| **Census** | ハミング距離 | エッジに強い |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sad(patch1: np.ndarray, patch2: np.ndarray) -> float:\n",
    "    \"\"\"SAD (Sum of Absolute Differences)\"\"\"\n",
    "    return np.sum(np.abs(patch1.astype(float) - patch2.astype(float)))\n",
    "\n",
    "def compute_ssd(patch1: np.ndarray, patch2: np.ndarray) -> float:\n",
    "    \"\"\"SSD (Sum of Squared Differences)\"\"\"\n",
    "    diff = patch1.astype(float) - patch2.astype(float)\n",
    "    return np.sum(diff ** 2)\n",
    "\n",
    "def compute_ncc(patch1: np.ndarray, patch2: np.ndarray) -> float:\n",
    "    \"\"\"NCC (Normalized Cross-Correlation)\n",
    "    \n",
    "    Returns: 1 - NCC (コストとして使うため、小さいほど良い)\n",
    "    \"\"\"\n",
    "    p1 = patch1.astype(float).flatten()\n",
    "    p2 = patch2.astype(float).flatten()\n",
    "    \n",
    "    p1_mean = p1 - np.mean(p1)\n",
    "    p2_mean = p2 - np.mean(p2)\n",
    "    \n",
    "    numerator = np.sum(p1_mean * p2_mean)\n",
    "    denominator = np.sqrt(np.sum(p1_mean**2) * np.sum(p2_mean**2))\n",
    "    \n",
    "    if denominator < 1e-6:\n",
    "        return 1.0\n",
    "    \n",
    "    ncc = numerator / denominator\n",
    "    return 1 - ncc  # コストに変換\n",
    "\n",
    "def census_transform(image: np.ndarray, window_size: int = 7) -> np.ndarray:\n",
    "    \"\"\"Census Transform\n",
    "    \n",
    "    各ピクセルを周囲との比較結果のビット列に変換\n",
    "    \"\"\"\n",
    "    h, w = image.shape\n",
    "    half = window_size // 2\n",
    "    census = np.zeros((h, w), dtype=np.uint64)\n",
    "    \n",
    "    for y in range(half, h - half):\n",
    "        for x in range(half, w - half):\n",
    "            center = image[y, x]\n",
    "            bit_string = 0\n",
    "            \n",
    "            for dy in range(-half, half + 1):\n",
    "                for dx in range(-half, half + 1):\n",
    "                    if dy == 0 and dx == 0:\n",
    "                        continue\n",
    "                    bit_string <<= 1\n",
    "                    if image[y + dy, x + dx] < center:\n",
    "                        bit_string |= 1\n",
    "            \n",
    "            census[y, x] = bit_string\n",
    "    \n",
    "    return census\n",
    "\n",
    "def hamming_distance(a: int, b: int) -> int:\n",
    "    \"\"\"ハミング距離（異なるビットの数）\"\"\"\n",
    "    xor = a ^ b\n",
    "    count = 0\n",
    "    while xor:\n",
    "        count += xor & 1\n",
    "        xor >>= 1\n",
    "    return count\n",
    "\n",
    "print(\"マッチングコスト関数の実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matching_costs():\n",
    "    \"\"\"マッチングコストの可視化\"\"\"\n",
    "    # サンプルパッチの作成\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 基準パッチ（グラデーション + ノイズ）\n",
    "    x, y = np.meshgrid(np.linspace(0, 1, 9), np.linspace(0, 1, 9))\n",
    "    base_patch = (x * 200 + np.random.randn(9, 9) * 10).astype(np.uint8)\n",
    "    \n",
    "    # 類似パッチ（少しずれた）\n",
    "    similar_patch = np.roll(base_patch, 1, axis=1)\n",
    "    \n",
    "    # 異なるパッチ\n",
    "    different_patch = (255 - base_patch).astype(np.uint8)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    \n",
    "    patches = [base_patch, similar_patch, different_patch]\n",
    "    titles = ['Reference Patch', 'Similar Patch', 'Different Patch']\n",
    "    \n",
    "    for ax, patch, title in zip(axes[0], patches, titles):\n",
    "        ax.imshow(patch, cmap='gray', vmin=0, vmax=255)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # コスト比較\n",
    "    costs = {\n",
    "        'SAD': [],\n",
    "        'SSD': [],\n",
    "        'NCC': []\n",
    "    }\n",
    "    \n",
    "    for patch in [similar_patch, different_patch]:\n",
    "        costs['SAD'].append(compute_sad(base_patch, patch))\n",
    "        costs['SSD'].append(compute_ssd(base_patch, patch))\n",
    "        costs['NCC'].append(compute_ncc(base_patch, patch))\n",
    "    \n",
    "    # 棒グラフ\n",
    "    x_pos = np.arange(2)\n",
    "    width = 0.25\n",
    "    \n",
    "    ax = axes[1, 0]\n",
    "    ax.bar(x_pos - width, costs['SAD'], width, label='SAD', alpha=0.8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Similar', 'Different'])\n",
    "    ax.set_ylabel('Cost')\n",
    "    ax.set_title('SAD Cost')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[1, 1]\n",
    "    ax.bar(x_pos, costs['SSD'], width, label='SSD', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Similar', 'Different'])\n",
    "    ax.set_title('SSD Cost')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[1, 2]\n",
    "    ax.bar(x_pos + width, costs['NCC'], width, label='NCC', alpha=0.8, color='green')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Similar', 'Different'])\n",
    "    ax.set_title('NCC Cost (1 - correlation)')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.suptitle('Comparison of Matching Cost Functions', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nコスト値:\")\n",
    "    print(f\"Similar patch - SAD: {costs['SAD'][0]:.1f}, SSD: {costs['SSD'][0]:.1f}, NCC: {costs['NCC'][0]:.3f}\")\n",
    "    print(f\"Different patch - SAD: {costs['SAD'][1]:.1f}, SSD: {costs['SSD'][1]:.1f}, NCC: {costs['NCC'][1]:.3f}\")\n",
    "\n",
    "visualize_matching_costs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ブロックマッチング\n",
    "\n",
    "### 5.1 アルゴリズム\n",
    "\n",
    "```\n",
    "for each pixel (x, y) in left image:\n",
    "    extract patch around (x, y)\n",
    "    \n",
    "    for each disparity d in [0, max_disparity]:\n",
    "        extract patch around (x - d, y) in right image\n",
    "        compute matching cost\n",
    "    \n",
    "    disparity[x, y] = argmin(cost)\n",
    "```\n",
    "\n",
    "### 5.2 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_matching(left: np.ndarray, right: np.ndarray,\n",
    "                   block_size: int = 9,\n",
    "                   max_disparity: int = 64,\n",
    "                   cost_function: str = 'sad') -> np.ndarray:\n",
    "    \"\"\"ブロックマッチングによる視差計算\n",
    "    \n",
    "    Args:\n",
    "        left: 左画像 (grayscale)\n",
    "        right: 右画像 (grayscale)\n",
    "        block_size: ブロックサイズ（奇数）\n",
    "        max_disparity: 最大視差\n",
    "        cost_function: 'sad', 'ssd', または 'ncc'\n",
    "    \n",
    "    Returns:\n",
    "        disparity: 視差マップ\n",
    "    \"\"\"\n",
    "    assert left.shape == right.shape, \"画像サイズが一致しません\"\n",
    "    assert block_size % 2 == 1, \"ブロックサイズは奇数である必要があります\"\n",
    "    \n",
    "    h, w = left.shape\n",
    "    half = block_size // 2\n",
    "    \n",
    "    # コスト関数の選択\n",
    "    if cost_function == 'sad':\n",
    "        cost_func = compute_sad\n",
    "    elif cost_function == 'ssd':\n",
    "        cost_func = compute_ssd\n",
    "    elif cost_function == 'ncc':\n",
    "        cost_func = compute_ncc\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown cost function: {cost_function}\")\n",
    "    \n",
    "    disparity = np.zeros((h, w), dtype=np.float32)\n",
    "    \n",
    "    for y in range(half, h - half):\n",
    "        for x in range(half + max_disparity, w - half):\n",
    "            # 左画像のパッチ\n",
    "            patch_L = left[y-half:y+half+1, x-half:x+half+1]\n",
    "            \n",
    "            min_cost = float('inf')\n",
    "            best_d = 0\n",
    "            \n",
    "            for d in range(max_disparity + 1):\n",
    "                # 右画像のパッチ（左へシフト）\n",
    "                x_R = x - d\n",
    "                if x_R - half < 0:\n",
    "                    continue\n",
    "                \n",
    "                patch_R = right[y-half:y+half+1, x_R-half:x_R+half+1]\n",
    "                \n",
    "                cost = cost_func(patch_L, patch_R)\n",
    "                \n",
    "                if cost < min_cost:\n",
    "                    min_cost = cost\n",
    "                    best_d = d\n",
    "            \n",
    "            disparity[y, x] = best_d\n",
    "    \n",
    "    return disparity\n",
    "\n",
    "print(\"ブロックマッチングの実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_stereo_pair(width: int = 320, height: int = 240,\n",
    "                                  max_disparity: int = 32) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"合成ステレオ画像ペアを生成\n",
    "    \n",
    "    Returns:\n",
    "        left: 左画像\n",
    "        right: 右画像\n",
    "        gt_disparity: 真の視差マップ\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 背景（テクスチャ付き）\n",
    "    background = np.random.randint(100, 200, (height, width), dtype=np.uint8)\n",
    "    background = ndimage.gaussian_filter(background.astype(float), sigma=2).astype(np.uint8)\n",
    "    \n",
    "    # 深度マップ（複数の長方形オブジェクト）\n",
    "    gt_disparity = np.ones((height, width), dtype=np.float32) * 5  # 背景視差\n",
    "    \n",
    "    # オブジェクトを配置\n",
    "    objects = [\n",
    "        {'x': 50, 'y': 50, 'w': 80, 'h': 100, 'disp': 25},   # 近いオブジェクト\n",
    "        {'x': 180, 'y': 80, 'w': 60, 'h': 80, 'disp': 15},   # 中距離\n",
    "        {'x': 100, 'y': 150, 'w': 100, 'h': 50, 'disp': 20}, # 手前の棚\n",
    "    ]\n",
    "    \n",
    "    left = background.copy()\n",
    "    \n",
    "    for obj in objects:\n",
    "        x, y, w, h, d = obj['x'], obj['y'], obj['w'], obj['h'], obj['disp']\n",
    "        \n",
    "        # オブジェクトのテクスチャ\n",
    "        texture = np.random.randint(50, 150, (h, w), dtype=np.uint8)\n",
    "        # チェッカーパターンを追加\n",
    "        checker = np.indices((h, w)).sum(axis=0) % 20 < 10\n",
    "        texture[checker] += 30\n",
    "        \n",
    "        left[y:y+h, x:x+w] = texture\n",
    "        gt_disparity[y:y+h, x:x+w] = d\n",
    "    \n",
    "    # 右画像を視差に基づいてシフト\n",
    "    right = np.zeros_like(left)\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            d = int(gt_disparity[y, x])\n",
    "            x_R = x - d\n",
    "            if 0 <= x_R < width:\n",
    "                right[y, x_R] = left[y, x]\n",
    "    \n",
    "    # 穴埋め（簡易的）\n",
    "    right = ndimage.grey_dilation(right, size=3)\n",
    "    right = ndimage.gaussian_filter(right.astype(float), sigma=0.5).astype(np.uint8)\n",
    "    \n",
    "    return left, right, gt_disparity\n",
    "\n",
    "# 合成データの生成\n",
    "left_img, right_img, gt_disp = create_synthetic_stereo_pair()\n",
    "\n",
    "# 可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "axes[0].imshow(left_img, cmap='gray')\n",
    "axes[0].set_title('Left Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(right_img, cmap='gray')\n",
    "axes[1].set_title('Right Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "im = axes[2].imshow(gt_disp, cmap='jet')\n",
    "axes[2].set_title('Ground Truth Disparity')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im, ax=axes[2], label='Disparity (pixels)')\n",
    "\n",
    "plt.suptitle('Synthetic Stereo Pair', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブロックマッチングの実行\n",
    "print(\"ブロックマッチングを実行中...\")\n",
    "\n",
    "disparity_sad = block_matching(left_img, right_img, \n",
    "                                block_size=9, max_disparity=32, \n",
    "                                cost_function='sad')\n",
    "\n",
    "print(\"完了!\")\n",
    "\n",
    "# 結果の可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "axes[0].imshow(gt_disp, cmap='jet', vmin=0, vmax=32)\n",
    "axes[0].set_title('Ground Truth Disparity')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(disparity_sad, cmap='jet', vmin=0, vmax=32)\n",
    "axes[1].set_title('Estimated Disparity (Block Matching)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 誤差マップ\n",
    "error = np.abs(disparity_sad - gt_disp)\n",
    "im = axes[2].imshow(error, cmap='hot', vmin=0, vmax=10)\n",
    "axes[2].set_title('Absolute Error')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im, ax=axes[2], label='Error (pixels)')\n",
    "\n",
    "plt.suptitle('Block Matching Results', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 精度評価\n",
    "valid_mask = gt_disp > 0\n",
    "mae = np.mean(error[valid_mask])\n",
    "bad_pixels = np.sum(error[valid_mask] > 3) / np.sum(valid_mask) * 100\n",
    "\n",
    "print(f\"\\n精度評価:\")\n",
    "print(f\"  MAE (Mean Absolute Error): {mae:.2f} pixels\")\n",
    "print(f\"  Bad pixels (error > 3px): {bad_pixels:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Semi-Global Matching (SGM)\n",
    "\n",
    "### 6.1 ブロックマッチングの問題点\n",
    "\n",
    "- テクスチャレス領域で不安定\n",
    "- オクルージョン境界でノイジー\n",
    "- 局所的な最適化のみ（グローバルな整合性なし）\n",
    "\n",
    "### 6.2 SGMの考え方\n",
    "\n",
    "**Semi-Global Matching (SGM)** は、複数の方向からのコスト集約により、グローバルな整合性を考慮します。\n",
    "\n",
    "#### コスト集約\n",
    "\n",
    "方向 $\\mathbf{r}$ に沿った累積コスト：\n",
    "\n",
    "$$L_\\mathbf{r}(\\mathbf{p}, d) = C(\\mathbf{p}, d) + \\min \\begin{cases}\n",
    "L_\\mathbf{r}(\\mathbf{p}-\\mathbf{r}, d) \\\\\n",
    "L_\\mathbf{r}(\\mathbf{p}-\\mathbf{r}, d-1) + P_1 \\\\\n",
    "L_\\mathbf{r}(\\mathbf{p}-\\mathbf{r}, d+1) + P_1 \\\\\n",
    "\\min_i L_\\mathbf{r}(\\mathbf{p}-\\mathbf{r}, i) + P_2\n",
    "\\end{cases}$$\n",
    "\n",
    "ここで：\n",
    "- $P_1$: 小さな視差変化へのペナルティ\n",
    "- $P_2$: 大きな視差変化へのペナルティ（$P_2 > P_1$）\n",
    "\n",
    "#### 全方向からの集約\n",
    "\n",
    "$$S(\\mathbf{p}, d) = \\sum_\\mathbf{r} L_\\mathbf{r}(\\mathbf{p}, d)$$\n",
    "\n",
    "最終視差：\n",
    "\n",
    "$$d(\\mathbf{p}) = \\arg\\min_d S(\\mathbf{p}, d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_volume(left: np.ndarray, right: np.ndarray,\n",
    "                        max_disparity: int, block_size: int = 5) -> np.ndarray:\n",
    "    \"\"\"コストボリュームを計算（SAD）\n",
    "    \n",
    "    Returns:\n",
    "        cost_volume: shape (H, W, max_disparity+1)\n",
    "    \"\"\"\n",
    "    h, w = left.shape\n",
    "    half = block_size // 2\n",
    "    cost_volume = np.full((h, w, max_disparity + 1), np.inf, dtype=np.float32)\n",
    "    \n",
    "    for d in range(max_disparity + 1):\n",
    "        for y in range(half, h - half):\n",
    "            for x in range(half + d, w - half):\n",
    "                patch_L = left[y-half:y+half+1, x-half:x+half+1]\n",
    "                patch_R = right[y-half:y+half+1, x-d-half:x-d+half+1]\n",
    "                cost_volume[y, x, d] = compute_sad(patch_L, patch_R)\n",
    "    \n",
    "    return cost_volume\n",
    "\n",
    "def sgm_aggregate_direction(cost_volume: np.ndarray, \n",
    "                             direction: Tuple[int, int],\n",
    "                             P1: float = 10, P2: float = 150) -> np.ndarray:\n",
    "    \"\"\"1方向のSGMコスト集約\n",
    "    \n",
    "    Args:\n",
    "        cost_volume: (H, W, D)\n",
    "        direction: (dy, dx)\n",
    "        P1: 小さな視差変化のペナルティ\n",
    "        P2: 大きな視差変化のペナルティ\n",
    "    \"\"\"\n",
    "    h, w, d_max = cost_volume.shape\n",
    "    dy, dx = direction\n",
    "    \n",
    "    L = np.zeros_like(cost_volume)\n",
    "    \n",
    "    # 開始位置の決定\n",
    "    if dy > 0:\n",
    "        y_range = range(h)\n",
    "    else:\n",
    "        y_range = range(h - 1, -1, -1)\n",
    "    \n",
    "    if dx > 0:\n",
    "        x_range = range(w)\n",
    "    else:\n",
    "        x_range = range(w - 1, -1, -1)\n",
    "    \n",
    "    for y in y_range:\n",
    "        for x in x_range:\n",
    "            py, px = y - dy, x - dx\n",
    "            \n",
    "            if 0 <= py < h and 0 <= px < w:\n",
    "                L_prev = L[py, px]\n",
    "                \n",
    "                for d in range(d_max):\n",
    "                    # 4つの候補からの最小コスト\n",
    "                    costs = [L_prev[d]]  # 同じ視差\n",
    "                    \n",
    "                    if d > 0:\n",
    "                        costs.append(L_prev[d-1] + P1)  # 視差-1\n",
    "                    \n",
    "                    if d < d_max - 1:\n",
    "                        costs.append(L_prev[d+1] + P1)  # 視差+1\n",
    "                    \n",
    "                    costs.append(np.min(L_prev) + P2)  # 大きなジャンプ\n",
    "                    \n",
    "                    L[y, x, d] = cost_volume[y, x, d] + min(costs) - np.min(L_prev)\n",
    "            else:\n",
    "                L[y, x] = cost_volume[y, x]\n",
    "    \n",
    "    return L\n",
    "\n",
    "def semi_global_matching(left: np.ndarray, right: np.ndarray,\n",
    "                          max_disparity: int = 32,\n",
    "                          block_size: int = 5,\n",
    "                          P1: float = 10, P2: float = 150) -> np.ndarray:\n",
    "    \"\"\"Semi-Global Matching (SGM)\n",
    "    \n",
    "    8方向からのコスト集約\n",
    "    \"\"\"\n",
    "    # コストボリュームの計算\n",
    "    print(\"  コストボリューム計算中...\")\n",
    "    cost_volume = compute_cost_volume(left, right, max_disparity, block_size)\n",
    "    \n",
    "    # 8方向\n",
    "    directions = [\n",
    "        (0, 1),   # 右\n",
    "        (0, -1),  # 左\n",
    "        (1, 0),   # 下\n",
    "        (-1, 0),  # 上\n",
    "        (1, 1),   # 右下\n",
    "        (1, -1),  # 左下\n",
    "        (-1, 1),  # 右上\n",
    "        (-1, -1)  # 左上\n",
    "    ]\n",
    "    \n",
    "    # 各方向からの集約\n",
    "    print(\"  8方向からのコスト集約中...\")\n",
    "    S = np.zeros_like(cost_volume)\n",
    "    \n",
    "    for i, direction in enumerate(directions):\n",
    "        L = sgm_aggregate_direction(cost_volume, direction, P1, P2)\n",
    "        S += L\n",
    "    \n",
    "    # 視差の決定（WTA: Winner-Take-All）\n",
    "    disparity = np.argmin(S, axis=2).astype(np.float32)\n",
    "    \n",
    "    return disparity\n",
    "\n",
    "print(\"SGMの実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGMの実行\n",
    "print(\"Semi-Global Matching を実行中...\")\n",
    "\n",
    "disparity_sgm = semi_global_matching(left_img, right_img, \n",
    "                                      max_disparity=32, block_size=5,\n",
    "                                      P1=10, P2=150)\n",
    "\n",
    "print(\"完了!\")\n",
    "\n",
    "# 結果の比較\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(gt_disp, cmap='jet', vmin=0, vmax=32)\n",
    "axes[0, 0].set_title('Ground Truth', fontsize=12)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(disparity_sad, cmap='jet', vmin=0, vmax=32)\n",
    "axes[0, 1].set_title('Block Matching (SAD)', fontsize=12)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(disparity_sgm, cmap='jet', vmin=0, vmax=32)\n",
    "axes[1, 0].set_title('Semi-Global Matching', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# 誤差比較\n",
    "error_sad = np.abs(disparity_sad - gt_disp)\n",
    "error_sgm = np.abs(disparity_sgm - gt_disp)\n",
    "\n",
    "valid_mask = gt_disp > 0\n",
    "mae_sad = np.mean(error_sad[valid_mask])\n",
    "mae_sgm = np.mean(error_sgm[valid_mask])\n",
    "\n",
    "methods = ['Block Matching', 'SGM']\n",
    "maes = [mae_sad, mae_sgm]\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "axes[1, 1].bar(methods, maes, color=colors, alpha=0.7)\n",
    "axes[1, 1].set_ylabel('MAE (pixels)', fontsize=12)\n",
    "axes[1, 1].set_title('Error Comparison', fontsize=12)\n",
    "for i, (method, mae) in enumerate(zip(methods, maes)):\n",
    "    axes[1, 1].text(i, mae + 0.1, f'{mae:.2f}', ha='center', fontsize=11)\n",
    "\n",
    "plt.suptitle('Comparison: Block Matching vs SGM', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n精度比較:\")\n",
    "print(f\"  Block Matching MAE: {mae_sad:.2f} pixels\")\n",
    "print(f\"  SGM MAE: {mae_sgm:.2f} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 視差から深度への変換\n",
    "\n",
    "### 7.1 深度マップの生成\n",
    "\n",
    "$$Z = \\frac{f \\cdot b}{d}$$\n",
    "\n",
    "### 7.2 3D点群の生成\n",
    "\n",
    "各ピクセル $(u, v)$ に対して、深度 $Z$ から3D座標を復元：\n",
    "\n",
    "$$X = \\frac{(u - c_x) \\cdot Z}{f}$$\n",
    "$$Y = \\frac{(v - c_y) \\cdot Z}{f}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_to_depth(disparity: np.ndarray, \n",
    "                       focal_length: float, \n",
    "                       baseline: float) -> np.ndarray:\n",
    "    \"\"\"視差マップから深度マップへの変換\n",
    "    \n",
    "    Args:\n",
    "        disparity: 視差マップ（ピクセル）\n",
    "        focal_length: 焦点距離（ピクセル）\n",
    "        baseline: ベースライン（メートル）\n",
    "    \n",
    "    Returns:\n",
    "        depth: 深度マップ（メートル）\n",
    "    \"\"\"\n",
    "    # ゼロ除算を避ける\n",
    "    disparity_safe = np.maximum(disparity, 0.1)\n",
    "    depth = (focal_length * baseline) / disparity_safe\n",
    "    \n",
    "    # 無効な視差（0以下）をマスク\n",
    "    depth[disparity <= 0] = 0\n",
    "    \n",
    "    return depth\n",
    "\n",
    "def depth_to_pointcloud(depth: np.ndarray, K: np.ndarray,\n",
    "                        image: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"深度マップから3D点群を生成\n",
    "    \n",
    "    Args:\n",
    "        depth: 深度マップ（メートル）\n",
    "        K: カメラ内部パラメータ\n",
    "        image: 色情報（オプション）\n",
    "    \n",
    "    Returns:\n",
    "        points: 3D点群 (N, 3)\n",
    "        colors: 色情報 (N, 3) or None\n",
    "    \"\"\"\n",
    "    h, w = depth.shape\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    \n",
    "    # ピクセル座標のグリッド\n",
    "    u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # 有効な深度のマスク\n",
    "    valid = depth > 0\n",
    "    \n",
    "    # 3D座標の計算\n",
    "    Z = depth[valid]\n",
    "    X = (u[valid] - cx) * Z / fx\n",
    "    Y = (v[valid] - cy) * Z / fy\n",
    "    \n",
    "    points = np.vstack([X, Y, Z]).T\n",
    "    \n",
    "    # 色情報\n",
    "    if image is not None:\n",
    "        if len(image.shape) == 2:\n",
    "            colors = np.stack([image[valid]] * 3, axis=1) / 255.0\n",
    "        else:\n",
    "            colors = image[valid] / 255.0\n",
    "    else:\n",
    "        colors = None\n",
    "    \n",
    "    return points, colors\n",
    "\n",
    "# カメラパラメータ（仮定）\n",
    "focal_length = 500  # pixels\n",
    "baseline = 0.1      # 10cm\n",
    "\n",
    "K = np.array([\n",
    "    [focal_length, 0, left_img.shape[1] / 2],\n",
    "    [0, focal_length, left_img.shape[0] / 2],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# 深度マップの計算\n",
    "depth_map = disparity_to_depth(disparity_sgm, focal_length, baseline)\n",
    "\n",
    "# 可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "axes[0].imshow(disparity_sgm, cmap='jet')\n",
    "axes[0].set_title('Disparity Map')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(axes[0].images[0], ax=axes[0], label='Disparity (px)')\n",
    "\n",
    "# 深度の可視化（適切な範囲にクリップ）\n",
    "depth_display = np.clip(depth_map, 0, 5)  # 0-5m\n",
    "im = axes[1].imshow(depth_display, cmap='viridis_r')\n",
    "axes[1].set_title('Depth Map')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im, ax=axes[1], label='Depth (m)')\n",
    "\n",
    "# 深度のヒストグラム\n",
    "valid_depths = depth_map[(depth_map > 0) & (depth_map < 5)]\n",
    "axes[2].hist(valid_depths, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[2].set_xlabel('Depth (m)')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Depth Distribution')\n",
    "\n",
    "plt.suptitle('Disparity to Depth Conversion', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"深度範囲: {valid_depths.min():.2f}m - {valid_depths.max():.2f}m\")\n",
    "print(f\"平均深度: {valid_depths.mean():.2f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_3d_reconstruction(depth: np.ndarray, K: np.ndarray, \n",
    "                                 image: np.ndarray, max_points: int = 5000):\n",
    "    \"\"\"3D点群の可視化\"\"\"\n",
    "    points, colors = depth_to_pointcloud(depth, K, image)\n",
    "    \n",
    "    # ダウンサンプリング\n",
    "    if len(points) > max_points:\n",
    "        indices = np.random.choice(len(points), max_points, replace=False)\n",
    "        points = points[indices]\n",
    "        if colors is not None:\n",
    "            colors = colors[indices]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # 深度で色付け\n",
    "    scatter = ax.scatter(points[:, 0], points[:, 2], -points[:, 1], \n",
    "                         c=points[:, 2], cmap='viridis_r', s=1, alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel('X (m)')\n",
    "    ax.set_ylabel('Z (Depth, m)')\n",
    "    ax.set_zlabel('Y (m)')\n",
    "    ax.set_title('3D Point Cloud from Stereo', fontsize=14)\n",
    "    \n",
    "    plt.colorbar(scatter, label='Depth (m)', shrink=0.5)\n",
    "    \n",
    "    # 視点調整\n",
    "    ax.view_init(elev=20, azim=-60)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"点群サイズ: {len(points)} 点\")\n",
    "\n",
    "visualize_3d_reconstruction(depth_map, K, left_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. 実践的な考慮事項\n",
    "\n",
    "### 8.1 ステレオマッチングの課題\n",
    "\n",
    "| 課題 | 説明 | 対処法 |\n",
    "|------|------|--------|\n",
    "| **オクルージョン** | 片方の画像でのみ見える領域 | Left-Right Consistency Check |\n",
    "| **テクスチャレス領域** | マッチングが曖昧 | 大きなウィンドウ、SGM |\n",
    "| **反復パターン** | 複数の候補が存在 | グローバル最適化 |\n",
    "| **照明変化** | 左右画像の輝度差 | Census Transform, NCC |\n",
    "\n",
    "### 8.2 Left-Right Consistency Check\n",
    "\n",
    "1. 左画像から右画像への視差 $d_L$ を計算\n",
    "2. 右画像から左画像への視差 $d_R$ を計算\n",
    "3. 一致しない点を除外: $|d_L(x) - d_R(x - d_L(x))| > \\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_consistency_check(disp_L: np.ndarray, disp_R: np.ndarray,\n",
    "                                  threshold: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Left-Right Consistency Check\n",
    "    \n",
    "    Args:\n",
    "        disp_L: 左→右の視差マップ\n",
    "        disp_R: 右→左の視差マップ\n",
    "        threshold: 許容誤差（ピクセル）\n",
    "    \n",
    "    Returns:\n",
    "        valid_mask: 有効なピクセルのマスク\n",
    "    \"\"\"\n",
    "    h, w = disp_L.shape\n",
    "    valid_mask = np.zeros((h, w), dtype=bool)\n",
    "    \n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            d = int(round(disp_L[y, x]))\n",
    "            x_R = x - d\n",
    "            \n",
    "            if 0 <= x_R < w:\n",
    "                d_R = disp_R[y, x_R]\n",
    "                \n",
    "                if abs(d - d_R) <= threshold:\n",
    "                    valid_mask[y, x] = True\n",
    "    \n",
    "    return valid_mask\n",
    "\n",
    "# 右→左の視差も計算（簡略版：左右を入れ替え）\n",
    "print(\"右→左の視差マップを計算中...\")\n",
    "disparity_RL = block_matching(right_img, left_img, \n",
    "                               block_size=9, max_disparity=32, \n",
    "                               cost_function='sad')\n",
    "print(\"完了!\")\n",
    "\n",
    "# Consistency Check\n",
    "valid_mask = left_right_consistency_check(disparity_sad, disparity_RL, threshold=1.0)\n",
    "\n",
    "# 結果の可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "axes[0].imshow(disparity_sad, cmap='jet', vmin=0, vmax=32)\n",
    "axes[0].set_title('Original Disparity')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(valid_mask, cmap='gray')\n",
    "axes[1].set_title(f'Valid Pixels ({np.sum(valid_mask) / valid_mask.size * 100:.1f}%)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# フィルタリング後\n",
    "disparity_filtered = disparity_sad.copy()\n",
    "disparity_filtered[~valid_mask] = 0\n",
    "axes[2].imshow(disparity_filtered, cmap='jet', vmin=0, vmax=32)\n",
    "axes[2].set_title('After L-R Check')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Left-Right Consistency Check', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n有効ピクセル率: {np.sum(valid_mask) / valid_mask.size * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. まとめと次のステップ\n",
    "\n",
    "### 学んだこと\n",
    "\n",
    "1. **ステレオビジョンの原理**: ベースライン、視差、深度の関係\n",
    "2. **ステレオ平行化**: エピポーラ線を水平に揃え、1D探索に簡略化\n",
    "3. **マッチングコスト**: SAD, SSD, NCC, Census\n",
    "4. **ブロックマッチング**: 局所的な視差計算\n",
    "5. **SGM**: グローバルな整合性を考慮した視差計算\n",
    "6. **深度復元**: 視差から深度へ、3D点群の生成\n",
    "\n",
    "### 重要な数式\n",
    "\n",
    "| 概念 | 数式 |\n",
    "|------|------|\n",
    "| 視差 | $d = x_L - x_R$ |\n",
    "| 深度 | $Z = \\frac{f \\cdot b}{d}$ |\n",
    "| 3D座標 | $X = \\frac{(u - c_x) \\cdot Z}{f}$ |\n",
    "\n",
    "### 次のノートブック\n",
    "\n",
    "**57. 三角測量と3D復元**では：\n",
    "- DLT（Direct Linear Transform）による三角測量\n",
    "- 最小二乗法による最適化\n",
    "- 誤差解析と精度向上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. 自己評価クイズ\n",
    "\n",
    "以下の質問に答えて理解度を確認しましょう：\n",
    "\n",
    "1. 視差と深度の関係式 $Z = fb/d$ を導出してください。\n",
    "\n",
    "2. ステレオ平行化（Rectification）の目的は何ですか？\n",
    "\n",
    "3. SAD と NCC のマッチングコストの違いは？どのような状況でNCCが有利ですか？\n",
    "\n",
    "4. SGMがブロックマッチングより優れている点は何ですか？\n",
    "\n",
    "5. オクルージョン領域で視差推定が困難な理由は？\n",
    "\n",
    "6. Left-Right Consistency Check の原理と目的を説明してください。\n",
    "\n",
    "7. 視差が0の場合、深度はどうなりますか？これは物理的に何を意味しますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クイズの解答（隠し）\n",
    "def show_quiz_answers():\n",
    "    answers = \"\"\"\n",
    "    === 自己評価クイズ解答 ===\n",
    "    \n",
    "    1. Z = fb/d の導出:\n",
    "       - 三角形の相似より: x_L/f = X/Z, x_R/f = (X-b)/Z\n",
    "       - 視差: d = x_L - x_R = f(X/Z) - f(X-b)/Z = fb/Z\n",
    "       - よって: Z = fb/d\n",
    "    \n",
    "    2. 平行化の目的:\n",
    "       - エピポーラ線を水平かつ同じ行に揃える\n",
    "       - 対応点探索を2D探索から1D水平探索に簡略化\n",
    "       - 計算効率の大幅な向上\n",
    "    \n",
    "    3. SAD vs NCC:\n",
    "       - SAD: 絶対差の和、高速だが照明変化に敏感\n",
    "       - NCC: 正規化相互相関、照明変化に強いが計算コスト高い\n",
    "       - NCCが有利: 左右カメラの露出が異なる場合、影がある場合\n",
    "    \n",
    "    4. SGMの利点:\n",
    "       - 複数方向からのコスト集約でグローバルな整合性を考慮\n",
    "       - テクスチャレス領域でより安定\n",
    "       - 視差の滑らかさを保ちつつエッジを保存\n",
    "    \n",
    "    5. オクルージョンの問題:\n",
    "       - オクルージョン領域は一方の画像でのみ見える\n",
    "       - 対応点が存在しないため、マッチングが不可能\n",
    "       - 誤った対応を見つけてしまう可能性\n",
    "    \n",
    "    6. L-R Consistency Check:\n",
    "       - 原理: 左→右と右→左の視差が一致するか確認\n",
    "       - 目的: オクルージョンや誤マッチングの検出・除去\n",
    "       - 一致しない点は信頼性が低いと判断\n",
    "    \n",
    "    7. 視差が0の場合:\n",
    "       - Z = fb/0 = ∞（無限遠）\n",
    "       - 物理的意味: 非常に遠い物体（または平行移動がない場合の全点）\n",
    "       - 実際には数値的に扱えないため、最小視差を設定することが多い\n",
    "    \"\"\"\n",
    "    print(answers)\n",
    "\n",
    "# 解答を見るには以下のコメントを外して実行\n",
    "# show_quiz_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ナビゲーション\n",
    "\n",
    "- **前のノートブック**: [55. エピポーラ幾何の理論](55_epipolar_geometry_theory_v1.ipynb)\n",
    "- **次のノートブック**: [57. 三角測量と3D復元](57_triangulation_3d_reconstruction_v1.ipynb)\n",
    "- **カリキュラム**: [CURRICULUM_UNIT_0.3.md](CURRICULUM_UNIT_0.3.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

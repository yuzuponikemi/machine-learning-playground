# 3D Computer Vision å®Ÿè£…ã‚¬ã‚¤ãƒ‰

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€3D Computer Visionã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã®å®Ÿè£…ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

---

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«ç§»å‹•
cd /path/to/machine-learning-playground

# 3D Visionç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements-3dvision.txt

# ã¾ãŸã¯ã€uvã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆ
uv pip install -r requirements-3dvision.txt
```

### 2. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ãƒ†ã‚¹ãƒˆ

```bash
# 3d-visionãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd notebooks/3d-vision

# geometry_tools.pyã®ãƒ†ã‚¹ãƒˆ
python utils/geometry_tools.py

# camera.pyã®ãƒ†ã‚¹ãƒˆ
python utils/camera.py

# visualizer.pyã®ãƒ†ã‚¹ãƒˆ
python utils/visualizer.py

# matching.pyã®ãƒ†ã‚¹ãƒˆ
python utils/matching.py
```

ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã™ã‚Œã°ã€ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¯å®Œäº†ã§ã™ï¼

---

## ğŸ“š å­¦ç¿’ã®é€²ã‚æ–¹

### Phase 1: ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ‡ãƒ«ã¨å°„å½±å¹¾ä½•

#### Notebook 50: ãƒ”ãƒ³ãƒ›ãƒ¼ãƒ«ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ‡ãƒ«ã®åŸºç¤

**ç›®æ¨™**: ã‚«ãƒ¡ãƒ©ã®åŸºæœ¬åŸç†ã‚’ç†è§£ã—ã€3Dâ†’2Då°„å½±ã‚’å®Ÿè£…ã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- ç„¦ç‚¹è·é›¢ï¼ˆfocal lengthï¼‰
- ä¸»ç‚¹ï¼ˆprincipal pointï¼‰
- å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡Œåˆ— K

**å®Ÿè£…ã®æµã‚Œ**:
1. ã‚«ãƒ¡ãƒ©å†…éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡Œåˆ— K ã®æ§‹ç¯‰
2. 3Dç‚¹ã‹ã‚‰2Dç”»åƒåº§æ¨™ã¸ã®å°„å½±
3. ç„¦ç‚¹è·é›¢ã®å½±éŸ¿ã®å¯è¦–åŒ–
4. ãƒ¬ãƒ³ã‚ºæ­ªã¿ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
import numpy as np
from utils.camera import PinholeCamera
from utils.visualizer import setup_3d_plot, plot_points_3d
import matplotlib.pyplot as plt

# ã‚«ãƒ¡ãƒ©ã®ä½œæˆ
camera = PinholeCamera(fx=500, fy=500, cx=320, cy=240)

# 3Dç‚¹ï¼ˆã‚«ãƒ¡ãƒ©å‰æ–¹5mï¼‰
points_3d = np.array([
    [0, 0, 5],
    [1, 0, 5],
    [0, 1, 5]
])

# 2DæŠ•å½±
points_2d = camera.project(points_3d)
print("2DæŠ•å½±:")
print(points_2d)
```

---

#### Notebook 51: ã‚«ãƒ¡ãƒ©å¤–éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨åº§æ¨™å¤‰æ›

**ç›®æ¨™**: å›è»¢ãƒ»ä¸¦é€²å¤‰æ›ã‚’ç†è§£ã—ã€ç•°ãªã‚‹åº§æ¨™ç³»é–“ã®å¤‰æ›ã‚’å®Ÿè£…ã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- å›è»¢è¡Œåˆ— R
- ä¸¦é€²ãƒ™ã‚¯ãƒˆãƒ« t
- ãƒ­ãƒ‰ãƒªã‚²ã‚¹ã®å…¬å¼

**å®Ÿè£…ã®æµã‚Œ**:
1. å›è»¢è¡Œåˆ—ã®ç”Ÿæˆï¼ˆX, Y, Zè»¸å‘¨ã‚Šï¼‰
2. ãƒ­ãƒ‰ãƒªã‚²ã‚¹å¤‰æ›ã®å®Ÿè£…
3. åº§æ¨™å¤‰æ›ã®å¯è¦–åŒ–
4. è¤‡æ•°ã‚«ãƒ¡ãƒ©ã®ç›¸å¯¾å§¿å‹¢

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
from utils.geometry_tools import (
    rotation_matrix_z,
    rodrigues_to_rotation_matrix,
    homogeneous_transform
)

# Zè»¸å‘¨ã‚Š90åº¦å›è»¢
R = rotation_matrix_z(np.pi / 2)
t = np.array([1, 2, 3])

# 3Dç‚¹ã®å¤‰æ›
points = np.array([[1, 0, 0], [0, 1, 0]])
transformed = homogeneous_transform(points, R, t)
print("å¤‰æ›å¾Œã®ç‚¹:")
print(transformed)
```

---

#### Notebook 52: ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**ç›®æ¨™**: å®Ÿã‚«ãƒ¡ãƒ©ã®å†…éƒ¨ãƒ»å¤–éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- Zhang's method
- ãƒã‚§ã‚¹ãƒœãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
- å†æŠ•å½±èª¤å·®

**å®Ÿè£…ã®æµã‚Œ**:
1. ãƒã‚§ã‚¹ãƒœãƒ¼ãƒ‰ç”»åƒã®æº–å‚™
2. ã‚³ãƒ¼ãƒŠãƒ¼æ¤œå‡º
3. ã‚«ãƒ¡ãƒ©è¡Œåˆ—ã¨æ­ªã¿ä¿‚æ•°ã®æ¨å®š
4. æ­ªã¿è£œæ­£ã®é©ç”¨

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
import cv2

# ãƒã‚§ã‚¹ãƒœãƒ¼ãƒ‰ã®ã‚µã‚¤ã‚º
pattern_size = (9, 6)  # å†…éƒ¨ã‚³ãƒ¼ãƒŠãƒ¼ã®æ•°

# è¤‡æ•°ã®ç”»åƒã‹ã‚‰ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
objpoints = []  # 3Dç‚¹
imgpoints = []  # 2Dç‚¹

for image_path in image_paths:
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ã‚³ãƒ¼ãƒŠãƒ¼æ¤œå‡º
    ret, corners = cv2.findChessboardCorners(gray, pattern_size)

    if ret:
        objpoints.append(objp)
        imgpoints.append(corners)

# ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(
    objpoints, imgpoints, gray.shape[::-1], None, None
)

print("ã‚«ãƒ¡ãƒ©è¡Œåˆ— K:")
print(K)
```

---

### Phase 2: ã‚¨ãƒ”ãƒãƒ¼ãƒ©å¹¾ä½•ã¨ã‚¹ãƒ†ãƒ¬ã‚ªè¦–

#### Notebook 53: ã‚¨ãƒ”ãƒãƒ¼ãƒ©å¹¾ä½•ã®åŸºç¤

**ç›®æ¨™**: 2è¦–ç‚¹å¹¾ä½•å­¦ã‚’ç†è§£ã—ã€åŸºç¤è¡Œåˆ—ãƒ»æœ¬è³ªè¡Œåˆ—ã‚’æ¨å®šã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- ã‚¨ãƒ”ãƒãƒ¼ãƒ©ç·šã€ã‚¨ãƒ”ãƒãƒ¼ãƒ«
- åŸºç¤è¡Œåˆ— F
- æœ¬è³ªè¡Œåˆ— E
- 8ç‚¹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

**å®Ÿè£…ã®æµã‚Œ**:
1. å¯¾å¿œç‚¹ã®æ¤œå‡º
2. åŸºç¤è¡Œåˆ— F ã®æ¨å®šï¼ˆ8ç‚¹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
3. ã‚¨ãƒ”ãƒãƒ¼ãƒ©ç·šã®æç”»
4. æœ¬è³ªè¡Œåˆ— E ã®è¨ˆç®—

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
from utils.matching import detect_and_compute, match_features, extract_matched_points
from utils.visualizer import plot_epipolar_lines

# ç‰¹å¾´ç‚¹æ¤œå‡ºã¨ãƒãƒƒãƒãƒ³ã‚°
kp1, desc1 = detect_and_compute(img1, method='sift')
kp2, desc2 = detect_and_compute(img2, method='sift')
matches = match_features(desc1, desc2, ratio_test=0.75)

# å¯¾å¿œç‚¹ã®æŠ½å‡º
pts1, pts2 = extract_matched_points(kp1, kp2, matches)

# åŸºç¤è¡Œåˆ—ã®æ¨å®šï¼ˆRANSACï¼‰
F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, 3.0, 0.99)

# ã‚¨ãƒ”ãƒãƒ¼ãƒ©ç·šã®æç”»
fig, axes = plot_epipolar_lines(img1, img2, pts1, pts2, F, n_lines=10)
plt.show()
```

---

#### Notebook 54: ã‚¹ãƒ†ãƒ¬ã‚ªãƒ“ã‚¸ãƒ§ãƒ³ã¨æ·±åº¦æ¨å®š

**ç›®æ¨™**: ã‚¹ãƒ†ãƒ¬ã‚ªç”»åƒãƒšã‚¢ã‹ã‚‰æ·±åº¦ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- è¦–å·®ï¼ˆdisparityï¼‰
- ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒƒãƒãƒ³ã‚°
- Semi-Global Matchingï¼ˆSGMï¼‰
- æ·±åº¦ã¨è¦–å·®ã®é–¢ä¿‚

**å®Ÿè£…ã®æµã‚Œ**:
1. ã‚¹ãƒ†ãƒ¬ã‚ªç”»åƒã®å¹³è¡ŒåŒ–
2. ãƒ–ãƒ­ãƒƒã‚¯ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹è¦–å·®è¨ˆç®—
3. æ·±åº¦ãƒãƒƒãƒ—ã®ç”Ÿæˆ
4. 3Dç‚¹ç¾¤ã¸ã®å¤‰æ›

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
# ã‚¹ãƒ†ãƒ¬ã‚ªãƒãƒƒãƒãƒ³ã‚°
stereo = cv2.StereoBM_create(numDisparities=16*5, blockSize=15)
disparity = stereo.compute(img_left_gray, img_right_gray)

# è¦–å·®ã‹ã‚‰æ·±åº¦ã¸ã®å¤‰æ›
# Z = (f * B) / d
# f: ç„¦ç‚¹è·é›¢, B: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³, d: è¦–å·®
baseline = 0.1  # ãƒ¡ãƒ¼ãƒˆãƒ«
focal_length = K[0, 0]  # ãƒ”ã‚¯ã‚»ãƒ«
depth = (focal_length * baseline) / (disparity + 1e-10)

# æ·±åº¦ãƒãƒƒãƒ—ã®å¯è¦–åŒ–
plt.imshow(depth, cmap='viridis')
plt.colorbar(label='Depth (m)')
plt.show()
```

---

### Phase 3: Structure from Motion

#### Notebook 55: ç‰¹å¾´ç‚¹æ¤œå‡ºã¨ãƒãƒƒãƒãƒ³ã‚°

**ç›®æ¨™**: SIFT/ORBãªã©ã®ç‰¹å¾´é‡ã‚’ä½¿ã„ã“ãªã™

**é‡è¦ãªæ¦‚å¿µ**:
- SIFT, ORB, AKAZE
- ç‰¹å¾´é‡è¨˜è¿°å­
- Lowe's ratio test
- RANSAC

**å®Ÿè£…ã®æµã‚Œ**:
1. ç•°ãªã‚‹ç‰¹å¾´é‡æ¤œå‡ºå™¨ã®æ¯”è¼ƒ
2. ãƒãƒƒãƒãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ
3. RANSACã«ã‚ˆã‚‹å¤–ã‚Œå€¤é™¤å»
4. ãƒãƒƒãƒãƒ³ã‚°çµæœã®å¯è¦–åŒ–

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
from utils.matching import (
    detect_and_compute,
    match_features,
    extract_matched_points,
    ransac_homography,
    draw_matches
)

# SIFTç‰¹å¾´é‡
kp_sift, desc_sift = detect_and_compute(img1, method='sift')

# ORBç‰¹å¾´é‡
kp_orb, desc_orb = detect_and_compute(img1, method='orb', nfeatures=1000)

# ãƒãƒƒãƒãƒ³ã‚°
matches_sift = match_features(desc_sift1, desc_sift2, ratio_test=0.75)
matches_orb = match_features(desc_orb1, desc_orb2, ratio_test=0.75)

print(f"SIFT matches: {len(matches_sift)}")
print(f"ORB matches: {len(matches_orb)}")

# RANSAC
pts1, pts2 = extract_matched_points(kp1, kp2, matches)
H, mask = ransac_homography(pts1, pts2, threshold=5.0)
print(f"Inliers: {mask.sum()} / {len(pts1)}")
```

---

#### Notebook 56: ä¸‰è§’æ¸¬é‡ã¨ç‚¹ç¾¤å†æ§‹æˆ

**ç›®æ¨™**: 2è¦–ç‚¹ã‹ã‚‰3Dç‚¹ã‚’å¾©å…ƒã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- ä¸‰è§’æ¸¬é‡ï¼ˆTriangulationï¼‰
- DLTï¼ˆDirect Linear Transformï¼‰
- å†æŠ•å½±èª¤å·®

**å®Ÿè£…ã®æµã‚Œ**:
1. 2ã¤ã®ã‚«ãƒ¡ãƒ©ã®ç›¸å¯¾å§¿å‹¢ã‚’æ¨å®š
2. å¯¾å¿œç‚¹ã‹ã‚‰3Dç‚¹ã‚’ä¸‰è§’æ¸¬é‡
3. ç–ãªç‚¹ç¾¤ã®ç”Ÿæˆ
4. Open3Dã§ã®3Då¯è¦–åŒ–

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
# ã‚«ãƒ¡ãƒ©è¡Œåˆ—
P1 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])  # ã‚«ãƒ¡ãƒ©1
P2 = K @ np.hstack([R, t.reshape(3, 1)])           # ã‚«ãƒ¡ãƒ©2

# ä¸‰è§’æ¸¬é‡
points_4d_homogeneous = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)

# åŒæ¬¡åº§æ¨™ã‹ã‚‰3Dåº§æ¨™ã¸
points_3d = points_4d_homogeneous[:3, :] / points_4d_homogeneous[3, :]
points_3d = points_3d.T

# Open3Dã§å¯è¦–åŒ–
import open3d as o3d

pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(points_3d)

o3d.visualization.draw_geometries([pcd])
```

---

#### Notebook 57: Structure from Motion ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ç›®æ¨™**: è¤‡æ•°ç”»åƒã‹ã‚‰ã‚«ãƒ¡ãƒ©è»Œè·¡ã¨3Dæ§‹é€ ã‚’åŒæ™‚å¾©å…ƒã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«SfM
- PnPå•é¡Œ
- ãƒãƒ³ãƒ‰ãƒ«èª¿æ•´ï¼ˆBundle Adjustmentï¼‰

**å®Ÿè£…ã®æµã‚Œ**:
1. ç”»åƒã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®èª­ã¿è¾¼ã¿
2. å…¨ãƒšã‚¢ç”»åƒã®ãƒãƒƒãƒãƒ³ã‚°
3. åˆæœŸ2è¦–ç‚¹ã®é¸æŠã¨å¾©å…ƒ
4. æ–°è¦ã‚«ãƒ¡ãƒ©ã®è¿½åŠ ï¼ˆPnPï¼‰
5. ãƒãƒ³ãƒ‰ãƒ«èª¿æ•´

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
# ç°¡æ˜“çš„ãªã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«SfMã®ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰

# 1. åˆæœŸ2è¦–ç‚¹ã®é¸æŠ
img1, img2 = select_initial_pair(images)

# 2. ç‰¹å¾´ç‚¹ãƒãƒƒãƒãƒ³ã‚°
kp1, desc1 = detect_and_compute(img1)
kp2, desc2 = detect_and_compute(img2)
matches = match_features(desc1, desc2)
pts1, pts2 = extract_matched_points(kp1, kp2, matches)

# 3. æœ¬è³ªè¡Œåˆ—ã®æ¨å®šã¨R, tã®å¾©å…ƒ
E, mask = cv2.findEssentialMat(pts1, pts2, K)
_, R, t, mask = cv2.recoverPose(E, pts1, pts2, K)

# 4. åˆæœŸç‚¹ç¾¤ã®ç”Ÿæˆ
P1 = K @ np.hstack([np.eye(3), np.zeros((3, 1))])
P2 = K @ np.hstack([R, t.reshape(3, 1)])
points_4d = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)
points_3d = (points_4d[:3, :] / points_4d[3, :]).T

# 5. æ–°è¦ç”»åƒã®è¿½åŠ ï¼ˆPnPã§å§¿å‹¢æ¨å®šï¼‰
for img_new in remaining_images:
    # æ–°è¦ç”»åƒã¨æ—¢å­˜3Dç‚¹ã®å¯¾å¿œã‚’è¦‹ã¤ã‘ã‚‹
    # ...

    # PnPã§æ–°è¦ã‚«ãƒ¡ãƒ©ã®å§¿å‹¢ã‚’æ¨å®š
    success, rvec, tvec = cv2.solvePnP(
        points_3d, points_2d_new, K, None, flags=cv2.SOLVEPNP_ITERATIVE
    )

    # æ–°è¦3Dç‚¹ã‚’è¿½åŠ 
    # ...

    # ãƒãƒ³ãƒ‰ãƒ«èª¿æ•´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    # ...
```

---

### Phase 4: NeRF/3DGSã¸ã®æ©‹æ¸¡ã—

#### Notebook 58: Ray Castingã¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

**ç›®æ¨™**: ã‚«ãƒ¡ãƒ©ã‹ã‚‰3Dç©ºé–“ã¸ã®å…‰ç·šã‚’ç”Ÿæˆã—ã€ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- Ray Castingï¼ˆå…‰ç·šæŠ•å°„ï¼‰
- ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
- ã‚¢ãƒ«ãƒ•ã‚¡åˆæˆ

**å®Ÿè£…ã®æµã‚Œ**:
1. ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å…‰ç·šã®ç”Ÿæˆ
2. å…‰ç·šä¸Šã®ç‚¹ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
3. ãƒœã‚¯ã‚»ãƒ«ã‚°ãƒªãƒƒãƒ‰ã®ä½œæˆ
4. ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®å®Ÿè£…

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
def generate_rays(H, W, K, R, t):
    """
    ã‚«ãƒ¡ãƒ©ã‹ã‚‰å…‰ç·šã‚’ç”Ÿæˆ

    Returns
    -------
    rays_o : np.ndarray, shape (H*W, 3)
        å…‰ç·šã®åŸç‚¹ï¼ˆã‚«ãƒ¡ãƒ©ä¸­å¿ƒï¼‰
    rays_d : np.ndarray, shape (H*W, 3)
        å…‰ç·šã®æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
    """
    # ç”»åƒåº§æ¨™ã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚°ãƒªãƒƒãƒ‰
    i, j = np.meshgrid(
        np.arange(W, dtype=np.float32),
        np.arange(H, dtype=np.float32),
        indexing='xy'
    )

    # ã‚«ãƒ¡ãƒ©åº§æ¨™ç³»ã§ã®æ–¹å‘
    dirs = np.stack([
        (i - K[0, 2]) / K[0, 0],
        (j - K[1, 2]) / K[1, 1],
        np.ones_like(i)
    ], axis=-1)

    # ä¸–ç•Œåº§æ¨™ç³»ã§ã®æ–¹å‘
    rays_d = np.sum(dirs[..., None, :] * R.T, axis=-1)

    # ã‚«ãƒ¡ãƒ©ä¸­å¿ƒï¼ˆä¸–ç•Œåº§æ¨™ç³»ï¼‰
    rays_o = -R.T @ t
    rays_o = np.broadcast_to(rays_o, rays_d.shape)

    rays_o = rays_o.reshape(-1, 3)
    rays_d = rays_d.reshape(-1, 3)

    return rays_o, rays_d


# ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
def volume_rendering(rays_o, rays_d, density_fn, color_fn, t_near, t_far, n_samples):
    """
    ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ–¹ç¨‹å¼

    C(r) = Î£ T_i * (1 - exp(-Ïƒ_i * Î´_i)) * c_i
    T_i = exp(-Î£_{j<i} Ïƒ_j * Î´_j)
    """
    # å…‰ç·šä¸Šã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹
    t = np.linspace(t_near, t_far, n_samples)
    points = rays_o[:, None, :] + rays_d[:, None, :] * t[None, :, None]

    # å„ç‚¹ã§ã®å¯†åº¦ã¨è‰²ã‚’å–å¾—
    density = density_fn(points)  # (n_rays, n_samples)
    colors = color_fn(points)     # (n_rays, n_samples, 3)

    # è·é›¢
    delta = t[1:] - t[:-1]
    delta = np.concatenate([delta, np.array([1e10])])

    # ã‚¢ãƒ«ãƒ•ã‚¡å€¤ï¼ˆä¸é€æ˜åº¦ï¼‰
    alpha = 1.0 - np.exp(-density * delta)

    # é€éç‡
    transmittance = np.cumprod(1.0 - alpha + 1e-10, axis=-1)
    transmittance = np.concatenate([
        np.ones_like(transmittance[:, :1]),
        transmittance[:, :-1]
    ], axis=-1)

    # æœ€çµ‚çš„ãªè‰²
    weights = alpha * transmittance
    rgb = np.sum(weights[..., None] * colors, axis=1)

    return rgb
```

---

#### Notebook 59: 3D Vision ã‹ã‚‰ NeRF/3DGS ã¸ã®æ©‹æ¸¡ã—

**ç›®æ¨™**: å¤å…¸çš„3D CVã¨æœ€æ–°ã®3Dç”ŸæˆæŠ€è¡“ã®é–¢ä¿‚ã‚’ç†è§£ã™ã‚‹

**é‡è¦ãªæ¦‚å¿µ**:
- COLMAPã¨NeRFã®é–¢ä¿‚
- ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
- transforms.jsonãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

**å®Ÿè£…ã®æµã‚Œ**:
1. SfMã§å¾—ã‚‰ã‚ŒãŸã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚ºã®èª­ã¿è¾¼ã¿
2. NeRFç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®å¤‰æ›
3. transforms.jsonã®ç”Ÿæˆ
4. ã‚«ãƒ¡ãƒ©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¤å·®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**ã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
def create_nerf_transforms(images, cameras, points_3d, output_path):
    """
    NeRFç”¨ã®transforms.jsonã‚’ç”Ÿæˆ
    """
    transforms = {
        "camera_angle_x": 2 * np.arctan(cameras[0].width / (2 * cameras[0].fx)),
        "frames": []
    }

    for i, (img_path, camera) in enumerate(zip(images, cameras)):
        # ã‚«ãƒ¡ãƒ©ãƒãƒ¼ã‚ºï¼ˆOpenGLåº§æ¨™ç³»ã¸ã®å¤‰æ›ãŒå¿…è¦ï¼‰
        R = camera.R
        t = camera.t

        # å¤‰æ›è¡Œåˆ—ï¼ˆ4x4ï¼‰
        transform_matrix = np.eye(4)
        transform_matrix[:3, :3] = R.T
        transform_matrix[:3, 3] = -R.T @ t

        frame = {
            "file_path": img_path,
            "transform_matrix": transform_matrix.tolist()
        }

        transforms["frames"].append(frame)

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    import json
    with open(output_path, 'w') as f:
        json.dump(transforms, f, indent=2)

    print(f"âœ… transforms.json ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")


# ä½¿ç”¨ä¾‹
create_nerf_transforms(
    images=image_paths,
    cameras=camera_list,
    points_3d=reconstructed_points,
    output_path="transforms.json"
)
```

---

## ğŸ”§ ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ³•

### 1. OpenCVã®SIFTãŒä½¿ãˆãªã„

**å•é¡Œ**:
```python
AttributeError: module 'cv2' has no attribute 'SIFT_create'
```

**è§£æ±ºæ³•**:
```bash
# opencv-contrib-pythonã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install opencv-contrib-python
```

### 2. Open3Dã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼

**å•é¡Œ**:
```python
ImportError: No module named 'open3d'
```

**è§£æ±ºæ³•**:
```bash
pip install open3d
```

### 3. ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚³ãƒ¼ãƒŠãƒ¼ãŒæ¤œå‡ºã•ã‚Œãªã„

**å•é¡Œ**: `cv2.findChessboardCorners` ãŒ False ã‚’è¿”ã™

**è§£æ±ºæ³•**:
- ãƒã‚§ã‚¹ãƒœãƒ¼ãƒ‰ãŒç”»åƒå…¨ä½“ã«æ˜ç­ã«å†™ã£ã¦ã„ã‚‹ã‹ç¢ºèª
- ç…§æ˜æ¡ä»¶ã‚’æ”¹å–„
- `cv2.CALIB_CB_ADAPTIVE_THRESH` ãƒ•ãƒ©ã‚°ã‚’è©¦ã™

```python
ret, corners = cv2.findChessboardCorners(
    gray, pattern_size,
    cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE
)
```

### 4. ãƒãƒƒãƒãƒ³ã‚°æ•°ãŒå°‘ãªã„

**å•é¡Œ**: ç‰¹å¾´ç‚¹ãƒãƒƒãƒãƒ³ã‚°ã§ååˆ†ãªãƒãƒƒãƒãŒå¾—ã‚‰ã‚Œãªã„

**è§£æ±ºæ³•**:
- ç‰¹å¾´ç‚¹ã®æ¤œå‡ºæ•°ã‚’å¢—ã‚„ã™: `nfeatures=2000`
- ratio testã®é–¾å€¤ã‚’ç·©ã‚ã‚‹: `ratio_test=0.8`
- ç•°ãªã‚‹ç‰¹å¾´é‡æ¤œå‡ºå™¨ã‚’è©¦ã™ï¼ˆSIFT, ORB, AKAZEï¼‰

---

## ğŸ“Š ãƒ‡ãƒãƒƒã‚°ã®ã‚³ãƒ„

### 1. å°„å½±ã®ç¢ºèª

```python
# æ—¢çŸ¥ã®3Dç‚¹ã‚’å°„å½±ã—ã¦ã€æœŸå¾…é€šã‚Šã®2Dåº§æ¨™ã«ãªã‚‹ã‹ç¢ºèª
points_3d = np.array([[0, 0, 5]])  # ã‚«ãƒ¡ãƒ©å‰æ–¹5m
points_2d = camera.project(points_3d)
print(f"å°„å½±çµæœ: {points_2d}")
print(f"æœŸå¾…å€¤: [cx, cy] = [{camera.cx}, {camera.cy}]")
```

### 2. å›è»¢è¡Œåˆ—ã®ç¢ºèª

```python
# å›è»¢è¡Œåˆ—ã¯ç›´äº¤è¡Œåˆ—ï¼ˆR @ R.T = Iï¼‰
R = rotation_matrix_z(np.pi / 2)
print(f"R @ R.T =\n{R @ R.T}")
print(f"det(R) = {np.linalg.det(R)}")  # det(R) = 1 ã®ã¯ãš
```

### 3. ã‚¨ãƒ”ãƒãƒ¼ãƒ©åˆ¶ç´„ã®ç¢ºèª

```python
# ã‚¨ãƒ”ãƒãƒ¼ãƒ©åˆ¶ç´„: x'^T F x = 0
for i in range(len(pts1)):
    pt1_homogeneous = np.array([pts1[i, 0], pts1[i, 1], 1])
    pt2_homogeneous = np.array([pts2[i, 0], pts2[i, 1], 1])

    error = pt2_homogeneous.T @ F @ pt1_homogeneous
    print(f"Point {i}: error = {error:.6f}")  # â‰ˆ 0 ã®ã¯ãš
```

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ã“ã®ã‚¬ã‚¤ãƒ‰ã‚’å®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã«æŒ‘æˆ¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

1. **COLMAPã®ä½¿ç”¨**: å®Ÿç”¨çš„ãªSfMãƒ„ãƒ¼ãƒ«ã‚’è©¦ã™
2. **Nerfstudio**: NeRFã®å­¦ç¿’ã¨æ–°è¦è¦–ç‚¹åˆæˆ
3. **è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: éƒ¨å±‹ã‚„ç‰©ä½“ã®3Då†æ§‹æˆ
4. **è«–æ–‡ã®å®Ÿè£…**: æœ€æ–°ã®3DæŠ€è¡“ã‚’è‡ªåˆ†ã§å®Ÿè£…

---

**Happy Coding! ğŸš€**

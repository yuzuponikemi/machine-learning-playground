{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 57. 三角測量と3D復元\n",
    "## Triangulation and 3D Reconstruction\n",
    "\n",
    "---\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このノートブックを完了すると、以下ができるようになります：\n",
    "\n",
    "- [ ] 三角測量の原理と幾何学的背景を理解する\n",
    "- [ ] DLT（Direct Linear Transform）による三角測量を実装できる\n",
    "- [ ] 中点法による三角測量を理解する\n",
    "- [ ] 最適三角測量（Optimal Triangulation）の概念を理解する\n",
    "- [ ] 多視点からの3D復元を実装できる\n",
    "- [ ] 三角測量の誤差要因と精度向上の方法を理解する\n",
    "\n",
    "---\n",
    "\n",
    "## 前提知識\n",
    "\n",
    "- 51: ピンホールカメラモデルと射影変換\n",
    "- 53: 3D座標変換と剛体運動\n",
    "- 55: エピポーラ幾何の理論\n",
    "- 線形代数：SVD分解、最小二乗法\n",
    "\n",
    "**難易度**: ★★★★☆（上級）  \n",
    "**推定学習時間**: 90-120分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. 三角測量とは\n",
    "\n",
    "**三角測量（Triangulation）**は、複数の視点から観測した2D画像点の対応から、3D空間上の点の位置を復元する技術です。\n",
    "\n",
    "### 基本原理\n",
    "\n",
    "- 各画像点は、カメラ中心から3D点を通る**光線（ray）**に対応\n",
    "- 2つの視点からの光線の**交点**が3D点の位置\n",
    "- 理想的には2つの光線は1点で交わる\n",
    "- 実際にはノイズにより交わらないため、**最良近似**を求める\n",
    "\n",
    "### 応用\n",
    "\n",
    "- ステレオビジョン\n",
    "- Structure from Motion (SfM)\n",
    "- SLAM\n",
    "- モーションキャプチャ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from typing import Tuple, List, Optional\n",
    "from scipy.optimize import least_squares\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 三角測量の幾何学\n",
    "\n",
    "### 2.1 問題設定\n",
    "\n",
    "- **入力**:\n",
    "  - 2つ以上のカメラの投影行列 $\\mathbf{P}_i = \\mathbf{K}_i [\\mathbf{R}_i | \\mathbf{t}_i]$\n",
    "  - 各カメラでの画像点 $\\mathbf{x}_i = (u_i, v_i)$\n",
    "\n",
    "- **出力**:\n",
    "  - 3D点 $\\mathbf{X} = (X, Y, Z)$\n",
    "\n",
    "### 2.2 投影方程式\n",
    "\n",
    "$$\\lambda_i \\begin{pmatrix} u_i \\\\ v_i \\\\ 1 \\end{pmatrix} = \\mathbf{P}_i \\begin{pmatrix} X \\\\ Y \\\\ Z \\\\ 1 \\end{pmatrix}$$\n",
    "\n",
    "### 2.3 理想と現実\n",
    "\n",
    "- **理想**: 2つの光線が1点で交わる\n",
    "- **現実**: ノイズにより光線は交わらない（ねじれの位置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_triangulation_geometry():\n",
    "    \"\"\"三角測量の幾何学を可視化\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # 理想的なケース\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    \n",
    "    # カメラ中心\n",
    "    C1 = np.array([0, 0, 0])\n",
    "    C2 = np.array([1, 0, 0])\n",
    "    \n",
    "    # 3D点\n",
    "    X_true = np.array([0.5, 0, 3])\n",
    "    \n",
    "    # 光線\n",
    "    ax1.plot([C1[0], X_true[0]], [C1[1], X_true[1]], [C1[2], X_true[2]], \n",
    "             'b-', linewidth=2, label='Ray from Camera 1')\n",
    "    ax1.plot([C2[0], X_true[0]], [C2[1], X_true[1]], [C2[2], X_true[2]], \n",
    "             'g-', linewidth=2, label='Ray from Camera 2')\n",
    "    \n",
    "    # カメラと点\n",
    "    ax1.scatter(*C1, color='blue', s=200, marker='o', label='Camera 1')\n",
    "    ax1.scatter(*C2, color='green', s=200, marker='o', label='Camera 2')\n",
    "    ax1.scatter(*X_true, color='red', s=200, marker='*', label='3D Point')\n",
    "    \n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_zlabel('Z')\n",
    "    ax1.set_title('Ideal Case: Rays Intersect', fontsize=12)\n",
    "    ax1.legend()\n",
    "    ax1.view_init(elev=20, azim=-60)\n",
    "    \n",
    "    # ノイズありのケース\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    \n",
    "    # ノイズを加えた方向\n",
    "    noise = 0.05\n",
    "    dir1 = X_true - C1\n",
    "    dir1_noisy = dir1 + np.array([noise, -noise, 0])\n",
    "    dir1_noisy = dir1_noisy / np.linalg.norm(dir1_noisy)\n",
    "    \n",
    "    dir2 = X_true - C2\n",
    "    dir2_noisy = dir2 + np.array([-noise, noise, 0])\n",
    "    dir2_noisy = dir2_noisy / np.linalg.norm(dir2_noisy)\n",
    "    \n",
    "    # 延長した光線\n",
    "    t_range = 5\n",
    "    ray1_end = C1 + t_range * dir1_noisy\n",
    "    ray2_end = C2 + t_range * dir2_noisy\n",
    "    \n",
    "    ax2.plot([C1[0], ray1_end[0]], [C1[1], ray1_end[1]], [C1[2], ray1_end[2]], \n",
    "             'b-', linewidth=2, label='Noisy Ray 1')\n",
    "    ax2.plot([C2[0], ray2_end[0]], [C2[1], ray2_end[1]], [C2[2], ray2_end[2]], \n",
    "             'g-', linewidth=2, label='Noisy Ray 2')\n",
    "    \n",
    "    # 最近点（中点法で推定）\n",
    "    # 簡略化のため、光線間の最短距離の中点を計算\n",
    "    def closest_points_on_rays(o1, d1, o2, d2):\n",
    "        w0 = o1 - o2\n",
    "        a = np.dot(d1, d1)\n",
    "        b = np.dot(d1, d2)\n",
    "        c = np.dot(d2, d2)\n",
    "        d = np.dot(d1, w0)\n",
    "        e = np.dot(d2, w0)\n",
    "        \n",
    "        denom = a * c - b * b\n",
    "        if abs(denom) < 1e-10:\n",
    "            return o1, o2\n",
    "        \n",
    "        s = (b * e - c * d) / denom\n",
    "        t = (a * e - b * d) / denom\n",
    "        \n",
    "        p1 = o1 + s * d1\n",
    "        p2 = o2 + t * d2\n",
    "        \n",
    "        return p1, p2\n",
    "    \n",
    "    p1, p2 = closest_points_on_rays(C1, dir1_noisy, C2, dir2_noisy)\n",
    "    X_estimated = (p1 + p2) / 2\n",
    "    \n",
    "    # 最短距離を示す線分\n",
    "    ax2.plot([p1[0], p2[0]], [p1[1], p2[1]], [p1[2], p2[2]], \n",
    "             'r-', linewidth=2, linestyle='--', label='Shortest distance')\n",
    "    \n",
    "    # カメラと点\n",
    "    ax2.scatter(*C1, color='blue', s=200, marker='o')\n",
    "    ax2.scatter(*C2, color='green', s=200, marker='o')\n",
    "    ax2.scatter(*X_true, color='red', s=200, marker='*', label='True 3D Point')\n",
    "    ax2.scatter(*X_estimated, color='orange', s=200, marker='x', label='Estimated Point')\n",
    "    \n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Y')\n",
    "    ax2.set_zlabel('Z')\n",
    "    ax2.set_title('Real Case: Rays Do Not Intersect', fontsize=12)\n",
    "    ax2.legend()\n",
    "    ax2.view_init(elev=20, azim=-60)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    error = np.linalg.norm(X_estimated - X_true)\n",
    "    print(f\"真の3D点: {X_true}\")\n",
    "    print(f\"推定された3D点: {X_estimated}\")\n",
    "    print(f\"誤差: {error:.4f}\")\n",
    "\n",
    "visualize_triangulation_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. DLT（Direct Linear Transform）による三角測量\n",
    "\n",
    "### 3.1 基本原理\n",
    "\n",
    "投影方程式から同次線形方程式系を導出し、SVDで解きます。\n",
    "\n",
    "投影方程式：\n",
    "$$\\lambda \\mathbf{x} = \\mathbf{P} \\mathbf{X}$$\n",
    "\n",
    "展開すると：\n",
    "$$\\lambda u = \\mathbf{p}_1^\\top \\mathbf{X}, \\quad \\lambda v = \\mathbf{p}_2^\\top \\mathbf{X}, \\quad \\lambda = \\mathbf{p}_3^\\top \\mathbf{X}$$\n",
    "\n",
    "ここで $\\mathbf{p}_i^\\top$ は $\\mathbf{P}$ の $i$ 行目。\n",
    "\n",
    "### 3.2 拘束式の導出\n",
    "\n",
    "$\\lambda$ を消去：\n",
    "\n",
    "$$u (\\mathbf{p}_3^\\top \\mathbf{X}) - (\\mathbf{p}_1^\\top \\mathbf{X}) = 0$$\n",
    "$$v (\\mathbf{p}_3^\\top \\mathbf{X}) - (\\mathbf{p}_2^\\top \\mathbf{X}) = 0$$\n",
    "\n",
    "### 3.3 線形方程式系\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{X} = \\mathbf{0}$$\n",
    "\n",
    "各カメラから2つの方程式が得られ、$n$ 視点で $2n \\times 4$ の行列 $\\mathbf{A}$ を構築。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate_dlt(points_2d: List[np.ndarray], \n",
    "                    proj_matrices: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"DLT（Direct Linear Transform）による三角測量\n",
    "    \n",
    "    Args:\n",
    "        points_2d: 各カメラでの2D点のリスト [(u1, v1), (u2, v2), ...]\n",
    "        proj_matrices: 各カメラの投影行列のリスト [P1, P2, ...] (3x4)\n",
    "    \n",
    "    Returns:\n",
    "        X: 3D点の座標 (3,)\n",
    "    \"\"\"\n",
    "    n_views = len(points_2d)\n",
    "    assert n_views >= 2, \"少なくとも2視点が必要です\"\n",
    "    assert len(proj_matrices) == n_views\n",
    "    \n",
    "    # 行列Aの構築\n",
    "    A = np.zeros((2 * n_views, 4))\n",
    "    \n",
    "    for i, (pt, P) in enumerate(zip(points_2d, proj_matrices)):\n",
    "        u, v = pt[0], pt[1]\n",
    "        \n",
    "        # u * p3 - p1\n",
    "        A[2*i] = u * P[2] - P[0]\n",
    "        # v * p3 - p2\n",
    "        A[2*i + 1] = v * P[2] - P[1]\n",
    "    \n",
    "    # SVDで解く\n",
    "    U, S, Vt = np.linalg.svd(A)\n",
    "    \n",
    "    # 最小特異値に対応するベクトル\n",
    "    X_homogeneous = Vt[-1]\n",
    "    \n",
    "    # 同次座標から3D座標へ\n",
    "    X = X_homogeneous[:3] / X_homogeneous[3]\n",
    "    \n",
    "    return X\n",
    "\n",
    "def create_projection_matrix(K: np.ndarray, R: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"投影行列 P = K [R | t] を作成\"\"\"\n",
    "    Rt = np.hstack([R, t.reshape(-1, 1)])\n",
    "    P = K @ Rt\n",
    "    return P\n",
    "\n",
    "def project_point(P: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"3D点を2D画像に投影\"\"\"\n",
    "    X_h = np.append(X, 1)\n",
    "    x_h = P @ X_h\n",
    "    x = x_h[:2] / x_h[2]\n",
    "    return x\n",
    "\n",
    "print(\"DLT三角測量の実装完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト：合成データでDLTを検証\n",
    "\n",
    "# カメラ内部パラメータ\n",
    "K = np.array([\n",
    "    [500, 0, 320],\n",
    "    [0, 500, 240],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "# カメラ1：原点、正面を向く\n",
    "R1 = np.eye(3)\n",
    "t1 = np.zeros(3)\n",
    "P1 = create_projection_matrix(K, R1, t1)\n",
    "\n",
    "# カメラ2：右に移動、少し内向き\n",
    "theta = np.radians(10)\n",
    "R2 = np.array([\n",
    "    [np.cos(theta), 0, np.sin(theta)],\n",
    "    [0, 1, 0],\n",
    "    [-np.sin(theta), 0, np.cos(theta)]\n",
    "])\n",
    "t2 = np.array([1, 0, 0])  # 右へ1m移動\n",
    "P2 = create_projection_matrix(K, R2, t2)\n",
    "\n",
    "# 真の3D点\n",
    "X_true = np.array([0.5, 0.3, 3.0])\n",
    "\n",
    "# 各カメラへの投影\n",
    "x1 = project_point(P1, X_true)\n",
    "x2 = project_point(P2, X_true)\n",
    "\n",
    "print(\"=== ノイズなし ===\")\n",
    "print(f\"真の3D点: {X_true}\")\n",
    "print(f\"カメラ1への投影: ({x1[0]:.2f}, {x1[1]:.2f})\")\n",
    "print(f\"カメラ2への投影: ({x2[0]:.2f}, {x2[1]:.2f})\")\n",
    "\n",
    "# DLTによる三角測量\n",
    "X_estimated = triangulate_dlt([x1, x2], [P1, P2])\n",
    "\n",
    "print(f\"\\n推定された3D点: {X_estimated}\")\n",
    "print(f\"誤差: {np.linalg.norm(X_estimated - X_true):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノイズありのテスト\n",
    "def test_triangulation_with_noise(noise_levels: List[float]):\n",
    "    \"\"\"異なるノイズレベルでの三角測量精度を評価\"\"\"\n",
    "    \n",
    "    n_trials = 100\n",
    "    errors = {level: [] for level in noise_levels}\n",
    "    \n",
    "    for level in noise_levels:\n",
    "        for _ in range(n_trials):\n",
    "            # ノイズを加えた観測点\n",
    "            x1_noisy = x1 + np.random.randn(2) * level\n",
    "            x2_noisy = x2 + np.random.randn(2) * level\n",
    "            \n",
    "            # 三角測量\n",
    "            X_est = triangulate_dlt([x1_noisy, x2_noisy], [P1, P2])\n",
    "            \n",
    "            # 誤差\n",
    "            error = np.linalg.norm(X_est - X_true)\n",
    "            errors[level].append(error)\n",
    "    \n",
    "    return errors\n",
    "\n",
    "noise_levels = [0.0, 0.5, 1.0, 2.0, 5.0]\n",
    "errors = test_triangulation_with_noise(noise_levels)\n",
    "\n",
    "# 結果の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 箱ひげ図\n",
    "box_data = [errors[level] for level in noise_levels]\n",
    "ax1.boxplot(box_data, labels=[f'{level}px' for level in noise_levels])\n",
    "ax1.set_xlabel('Noise Level (pixels)', fontsize=12)\n",
    "ax1.set_ylabel('3D Error (meters)', fontsize=12)\n",
    "ax1.set_title('DLT Triangulation Error vs Noise Level', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 平均誤差\n",
    "mean_errors = [np.mean(errors[level]) for level in noise_levels]\n",
    "std_errors = [np.std(errors[level]) for level in noise_levels]\n",
    "\n",
    "ax2.errorbar(noise_levels, mean_errors, yerr=std_errors, \n",
    "             fmt='o-', capsize=5, capthick=2)\n",
    "ax2.set_xlabel('Noise Level (pixels)', fontsize=12)\n",
    "ax2.set_ylabel('Mean 3D Error (meters)', fontsize=12)\n",
    "ax2.set_title('Mean Error with Standard Deviation', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nノイズレベルと平均誤差:\")\n",
    "for level, mean_err, std_err in zip(noise_levels, mean_errors, std_errors):\n",
    "    print(f\"  {level} pixels → {mean_err:.4f} ± {std_err:.4f} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 中点法（Midpoint Method）\n",
    "\n",
    "### 4.1 概要\n",
    "\n",
    "2つの光線間の**最短距離の中点**を3D点の推定値とする幾何学的な手法。\n",
    "\n",
    "### 4.2 アルゴリズム\n",
    "\n",
    "光線1: $\\mathbf{r}_1(s) = \\mathbf{o}_1 + s \\mathbf{d}_1$\n",
    "\n",
    "光線2: $\\mathbf{r}_2(t) = \\mathbf{o}_2 + t \\mathbf{d}_2$\n",
    "\n",
    "最短距離を与える $s^*, t^*$ を求め：\n",
    "\n",
    "$$\\mathbf{X} = \\frac{\\mathbf{r}_1(s^*) + \\mathbf{r}_2(t^*)}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate_midpoint(x1: np.ndarray, x2: np.ndarray,\n",
    "                          P1: np.ndarray, P2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"中点法による三角測量\n",
    "    \n",
    "    Args:\n",
    "        x1, x2: 各カメラでの2D点 (u, v)\n",
    "        P1, P2: 投影行列 (3x4)\n",
    "    \n",
    "    Returns:\n",
    "        X: 3D点の座標\n",
    "    \"\"\"\n",
    "    # カメラ中心を計算\n",
    "    # P = K[R|t] → C = -R^T @ t\n",
    "    # または P の右零空間\n",
    "    def get_camera_center(P):\n",
    "        U, S, Vt = np.linalg.svd(P)\n",
    "        C_h = Vt[-1]\n",
    "        C = C_h[:3] / C_h[3]\n",
    "        return C\n",
    "    \n",
    "    C1 = get_camera_center(P1)\n",
    "    C2 = get_camera_center(P2)\n",
    "    \n",
    "    # 光線の方向を計算\n",
    "    # 正規化座標を使用: K^{-1} @ x\n",
    "    # 簡略化のため、Pの擬似逆行列を使用\n",
    "    x1_h = np.array([x1[0], x1[1], 1])\n",
    "    x2_h = np.array([x2[0], x2[1], 1])\n",
    "    \n",
    "    # Pの3x3部分の逆行列を使用して方向を計算\n",
    "    M1 = P1[:, :3]\n",
    "    M2 = P2[:, :3]\n",
    "    \n",
    "    d1 = np.linalg.inv(M1) @ x1_h\n",
    "    d1 = d1 / np.linalg.norm(d1)\n",
    "    \n",
    "    d2 = np.linalg.inv(M2) @ x2_h\n",
    "    d2 = d2 / np.linalg.norm(d2)\n",
    "    \n",
    "    # 最短距離の計算\n",
    "    w0 = C1 - C2\n",
    "    a = np.dot(d1, d1)\n",
    "    b = np.dot(d1, d2)\n",
    "    c = np.dot(d2, d2)\n",
    "    d = np.dot(d1, w0)\n",
    "    e = np.dot(d2, w0)\n",
    "    \n",
    "    denom = a * c - b * b\n",
    "    \n",
    "    if abs(denom) < 1e-10:\n",
    "        # 光線が平行な場合\n",
    "        return (C1 + C2) / 2\n",
    "    \n",
    "    s = (b * e - c * d) / denom\n",
    "    t = (a * e - b * d) / denom\n",
    "    \n",
    "    # 各光線上の最近点\n",
    "    point1 = C1 + s * d1\n",
    "    point2 = C2 + t * d2\n",
    "    \n",
    "    # 中点\n",
    "    X = (point1 + point2) / 2\n",
    "    \n",
    "    return X\n",
    "\n",
    "# テスト\n",
    "print(\"=== 中点法のテスト ===\")\n",
    "X_midpoint = triangulate_midpoint(x1, x2, P1, P2)\n",
    "print(f\"真の3D点: {X_true}\")\n",
    "print(f\"中点法による推定: {X_midpoint}\")\n",
    "print(f\"誤差: {np.linalg.norm(X_midpoint - X_true):.6f}\")\n",
    "\n",
    "# ノイズあり\n",
    "x1_noisy = x1 + np.random.randn(2) * 1.0\n",
    "x2_noisy = x2 + np.random.randn(2) * 1.0\n",
    "\n",
    "X_midpoint_noisy = triangulate_midpoint(x1_noisy, x2_noisy, P1, P2)\n",
    "X_dlt_noisy = triangulate_dlt([x1_noisy, x2_noisy], [P1, P2])\n",
    "\n",
    "print(f\"\\nノイズあり (1 pixel):\")\n",
    "print(f\"  中点法誤差: {np.linalg.norm(X_midpoint_noisy - X_true):.4f}\")\n",
    "print(f\"  DLT誤差: {np.linalg.norm(X_dlt_noisy - X_true):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 最適三角測量（Optimal Triangulation）\n",
    "\n",
    "### 5.1 問題点\n",
    "\n",
    "DLTや中点法は、観測点のノイズを考慮していません。\n",
    "\n",
    "### 5.2 最適三角測量のアイデア\n",
    "\n",
    "観測点 $\\mathbf{x}_i$ を**エピポーラ線上に補正**し、エピポーラ拘束を満たすようにしてから三角測量を行います。\n",
    "\n",
    "### 5.3 最小化問題\n",
    "\n",
    "$$\\min_{\\hat{\\mathbf{x}}_1, \\hat{\\mathbf{x}}_2} \\|\\mathbf{x}_1 - \\hat{\\mathbf{x}}_1\\|^2 + \\|\\mathbf{x}_2 - \\hat{\\mathbf{x}}_2\\|^2$$\n",
    "\n",
    "subject to: $\\hat{\\mathbf{x}}_2^\\top \\mathbf{F} \\hat{\\mathbf{x}}_1 = 0$\n",
    "\n",
    "### 5.4 非線形最適化によるアプローチ\n",
    "\n",
    "実際には、**再投影誤差の最小化**として定式化することが多いです：\n",
    "\n",
    "$$\\min_{\\mathbf{X}} \\sum_i \\|\\mathbf{x}_i - \\pi(\\mathbf{P}_i, \\mathbf{X})\\|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate_optimal(points_2d: List[np.ndarray], \n",
    "                        proj_matrices: List[np.ndarray],\n",
    "                        initial_X: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "    \"\"\"非線形最適化による三角測量（再投影誤差最小化）\n",
    "    \n",
    "    Args:\n",
    "        points_2d: 各カメラでの2D点のリスト\n",
    "        proj_matrices: 各カメラの投影行列のリスト\n",
    "        initial_X: 初期値（Noneの場合はDLTで計算）\n",
    "    \n",
    "    Returns:\n",
    "        X: 最適化された3D点の座標\n",
    "    \"\"\"\n",
    "    # 初期値\n",
    "    if initial_X is None:\n",
    "        initial_X = triangulate_dlt(points_2d, proj_matrices)\n",
    "    \n",
    "    def reprojection_error(X):\n",
    "        \"\"\"再投影誤差を計算\"\"\"\n",
    "        errors = []\n",
    "        X_h = np.append(X, 1)\n",
    "        \n",
    "        for pt, P in zip(points_2d, proj_matrices):\n",
    "            x_proj_h = P @ X_h\n",
    "            x_proj = x_proj_h[:2] / x_proj_h[2]\n",
    "            \n",
    "            errors.extend(pt - x_proj)\n",
    "        \n",
    "        return np.array(errors)\n",
    "    \n",
    "    # Levenberg-Marquardt法で最適化\n",
    "    result = least_squares(reprojection_error, initial_X, method='lm')\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "# テスト\n",
    "print(\"=== 最適三角測量のテスト ===\")\n",
    "\n",
    "# ノイズを加えた観測点\n",
    "np.random.seed(42)\n",
    "noise_level = 2.0\n",
    "x1_noisy = x1 + np.random.randn(2) * noise_level\n",
    "x2_noisy = x2 + np.random.randn(2) * noise_level\n",
    "\n",
    "# 各手法で推定\n",
    "X_dlt = triangulate_dlt([x1_noisy, x2_noisy], [P1, P2])\n",
    "X_optimal = triangulate_optimal([x1_noisy, x2_noisy], [P1, P2])\n",
    "\n",
    "print(f\"真の3D点: {X_true}\")\n",
    "print(f\"DLT: {X_dlt}, 誤差: {np.linalg.norm(X_dlt - X_true):.4f}\")\n",
    "print(f\"最適化: {X_optimal}, 誤差: {np.linalg.norm(X_optimal - X_true):.4f}\")\n",
    "\n",
    "# 再投影誤差の比較\n",
    "def compute_reprojection_error(X, points_2d, proj_matrices):\n",
    "    total_error = 0\n",
    "    X_h = np.append(X, 1)\n",
    "    for pt, P in zip(points_2d, proj_matrices):\n",
    "        x_proj_h = P @ X_h\n",
    "        x_proj = x_proj_h[:2] / x_proj_h[2]\n",
    "        total_error += np.linalg.norm(pt - x_proj) ** 2\n",
    "    return np.sqrt(total_error / len(points_2d))\n",
    "\n",
    "reproj_dlt = compute_reprojection_error(X_dlt, [x1_noisy, x2_noisy], [P1, P2])\n",
    "reproj_optimal = compute_reprojection_error(X_optimal, [x1_noisy, x2_noisy], [P1, P2])\n",
    "\n",
    "print(f\"\\n再投影誤差 (RMS):\")\n",
    "print(f\"  DLT: {reproj_dlt:.4f} pixels\")\n",
    "print(f\"  最適化: {reproj_optimal:.4f} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 多視点三角測量\n",
    "\n",
    "### 6.1 2視点を超える利点\n",
    "\n",
    "- 冗長な観測によりノイズの影響を軽減\n",
    "- より頑健な推定が可能\n",
    "- オクルージョンへの対応\n",
    "\n",
    "### 6.2 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_multiview_cameras(n_cameras: int, radius: float = 2.0,\n",
    "                             K: np.ndarray = None) -> List[np.ndarray]:\n",
    "    \"\"\"円周上に配置されたカメラの投影行列を生成\"\"\"\n",
    "    if K is None:\n",
    "        K = np.array([\n",
    "            [500, 0, 320],\n",
    "            [0, 500, 240],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "    \n",
    "    proj_matrices = []\n",
    "    camera_centers = []\n",
    "    \n",
    "    for i in range(n_cameras):\n",
    "        angle = 2 * np.pi * i / n_cameras\n",
    "        \n",
    "        # カメラ位置（円周上）\n",
    "        C = np.array([radius * np.cos(angle), 0, radius * np.sin(angle)])\n",
    "        camera_centers.append(C)\n",
    "        \n",
    "        # 原点を向くように回転\n",
    "        # Z軸が原点を向く\n",
    "        z_axis = -C / np.linalg.norm(C)\n",
    "        y_axis = np.array([0, 1, 0])\n",
    "        x_axis = np.cross(y_axis, z_axis)\n",
    "        x_axis = x_axis / np.linalg.norm(x_axis)\n",
    "        y_axis = np.cross(z_axis, x_axis)\n",
    "        \n",
    "        R = np.vstack([x_axis, y_axis, z_axis])\n",
    "        t = -R @ C\n",
    "        \n",
    "        P = create_projection_matrix(K, R, t)\n",
    "        proj_matrices.append(P)\n",
    "    \n",
    "    return proj_matrices, camera_centers\n",
    "\n",
    "def test_multiview_triangulation():\n",
    "    \"\"\"多視点三角測量のテスト\"\"\"\n",
    "    # 真の3D点\n",
    "    X_true = np.array([0.0, 0.0, 0.0])\n",
    "    \n",
    "    # カメラ数を変えてテスト\n",
    "    camera_counts = [2, 3, 4, 6, 8]\n",
    "    noise_level = 2.0\n",
    "    n_trials = 50\n",
    "    \n",
    "    results = {n: [] for n in camera_counts}\n",
    "    \n",
    "    for n_cameras in camera_counts:\n",
    "        proj_matrices, _ = setup_multiview_cameras(n_cameras)\n",
    "        \n",
    "        for _ in range(n_trials):\n",
    "            # 各カメラへの投影（ノイズ付き）\n",
    "            points_2d = []\n",
    "            for P in proj_matrices:\n",
    "                x = project_point(P, X_true)\n",
    "                x_noisy = x + np.random.randn(2) * noise_level\n",
    "                points_2d.append(x_noisy)\n",
    "            \n",
    "            # 三角測量\n",
    "            X_est = triangulate_dlt(points_2d, proj_matrices)\n",
    "            error = np.linalg.norm(X_est - X_true)\n",
    "            results[n_cameras].append(error)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# テストの実行\n",
    "print(\"多視点三角測量のテスト中...\")\n",
    "multiview_results = test_multiview_triangulation()\n",
    "print(\"完了!\")\n",
    "\n",
    "# 結果の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "camera_counts = list(multiview_results.keys())\n",
    "mean_errors = [np.mean(multiview_results[n]) for n in camera_counts]\n",
    "std_errors = [np.std(multiview_results[n]) for n in camera_counts]\n",
    "\n",
    "# 箱ひげ図\n",
    "ax1.boxplot([multiview_results[n] for n in camera_counts], \n",
    "            labels=[str(n) for n in camera_counts])\n",
    "ax1.set_xlabel('Number of Cameras', fontsize=12)\n",
    "ax1.set_ylabel('3D Error (meters)', fontsize=12)\n",
    "ax1.set_title('Multi-view Triangulation: Error vs Camera Count', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 平均誤差\n",
    "ax2.errorbar(camera_counts, mean_errors, yerr=std_errors,\n",
    "             fmt='o-', capsize=5, capthick=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Cameras', fontsize=12)\n",
    "ax2.set_ylabel('Mean 3D Error (meters)', fontsize=12)\n",
    "ax2.set_title('Mean Error Decreases with More Views', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nカメラ数と平均誤差:\")\n",
    "for n, mean_err, std_err in zip(camera_counts, mean_errors, std_errors):\n",
    "    print(f\"  {n} cameras → {mean_err:.4f} ± {std_err:.4f} meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_multiview_setup():\n",
    "    \"\"\"多視点カメラ配置の可視化\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    n_cameras = 6\n",
    "    proj_matrices, camera_centers = setup_multiview_cameras(n_cameras)\n",
    "    \n",
    "    # 3D点\n",
    "    X_points = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0.3, 0.2, 0.1],\n",
    "        [-0.2, 0.1, -0.1],\n",
    "        [0.1, -0.3, 0.2]\n",
    "    ])\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_cameras))\n",
    "    \n",
    "    # カメラの描画\n",
    "    for i, (C, P, color) in enumerate(zip(camera_centers, proj_matrices, colors)):\n",
    "        ax.scatter(*C, color=color, s=200, marker='o', label=f'Camera {i+1}')\n",
    "        \n",
    "        # カメラの向き（光軸）\n",
    "        direction = -C / np.linalg.norm(C)\n",
    "        ax.quiver(*C, *direction * 0.5, color=color, arrow_length_ratio=0.2)\n",
    "    \n",
    "    # 3D点の描画\n",
    "    for X in X_points:\n",
    "        ax.scatter(*X, color='red', s=150, marker='*')\n",
    "        \n",
    "        # 各カメラからの光線\n",
    "        for C, color in zip(camera_centers, colors):\n",
    "            ax.plot([C[0], X[0]], [C[1], X[1]], [C[2], X[2]], \n",
    "                    color=color, alpha=0.3, linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(f'Multi-view Camera Setup ({n_cameras} Cameras)', fontsize=14)\n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    # 等軸スケール\n",
    "    max_range = 2.5\n",
    "    ax.set_xlim(-max_range, max_range)\n",
    "    ax.set_ylim(-max_range, max_range)\n",
    "    ax.set_zlim(-max_range, max_range)\n",
    "    \n",
    "    ax.view_init(elev=30, azim=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_multiview_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 三角測量の誤差解析\n",
    "\n",
    "### 7.1 誤差要因\n",
    "\n",
    "| 要因 | 説明 | 対策 |\n",
    "|------|------|------|\n",
    "| **画像ノイズ** | 特徴点検出の不確実性 | サブピクセル精度、多視点 |\n",
    "| **キャリブレーション誤差** | カメラパラメータの不正確さ | 高精度キャリブレーション |\n",
    "| **ベースライン** | 短すぎると深度精度が低下 | 適切なベースライン設計 |\n",
    "| **視差角** | 小さい角度では精度が低下 | 三角測量角度の確保 |\n",
    "\n",
    "### 7.2 深度誤差とベースラインの関係\n",
    "\n",
    "深度誤差 $\\delta Z$ と視差誤差 $\\delta d$ の関係：\n",
    "\n",
    "$$\\delta Z = \\frac{Z^2}{f \\cdot b} \\delta d$$\n",
    "\n",
    "- 深度が大きいほど誤差が増大（$Z^2$ に比例）\n",
    "- ベースライン $b$ が大きいほど精度向上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_depth_error():\n",
    "    \"\"\"深度誤差の解析\"\"\"\n",
    "    f = 500  # 焦点距離（ピクセル）\n",
    "    baselines = [0.1, 0.2, 0.5, 1.0]  # ベースライン（メートル）\n",
    "    delta_d = 1.0  # 視差誤差（ピクセル）\n",
    "    \n",
    "    depths = np.linspace(1, 20, 100)  # 深度範囲\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(baselines)))\n",
    "    \n",
    "    for b, color in zip(baselines, colors):\n",
    "        # 深度誤差: δZ = Z² / (f * b) * δd\n",
    "        depth_errors = (depths ** 2) / (f * b) * delta_d\n",
    "        \n",
    "        ax1.plot(depths, depth_errors, color=color, linewidth=2, \n",
    "                 label=f'b = {b*100:.0f} cm')\n",
    "    \n",
    "    ax1.set_xlabel('Depth Z (meters)', fontsize=12)\n",
    "    ax1.set_ylabel('Depth Error δZ (meters)', fontsize=12)\n",
    "    ax1.set_title(f'Depth Error vs Distance (δd = {delta_d} pixel)', fontsize=12)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(1, 20)\n",
    "    ax1.set_ylim(0, 2)\n",
    "    \n",
    "    # 相対誤差\n",
    "    for b, color in zip(baselines, colors):\n",
    "        relative_errors = depths / (f * b) * delta_d * 100  # パーセント\n",
    "        \n",
    "        ax2.plot(depths, relative_errors, color=color, linewidth=2,\n",
    "                 label=f'b = {b*100:.0f} cm')\n",
    "    \n",
    "    ax2.set_xlabel('Depth Z (meters)', fontsize=12)\n",
    "    ax2.set_ylabel('Relative Error (%)', fontsize=12)\n",
    "    ax2.set_title('Relative Depth Error (δZ/Z × 100)', fontsize=12)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(1, 20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"重要な洞察:\")\n",
    "    print(\"- 深度誤差は距離の2乗に比例して増大\")\n",
    "    print(\"- ベースラインを大きくすると深度精度が向上\")\n",
    "    print(\"- 相対誤差は距離に比例（一定の割合で増加）\")\n",
    "\n",
    "analyze_depth_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_triangulation_angle():\n",
    "    \"\"\"三角測量角度と精度の関係\"\"\"\n",
    "    # 固定の3D点\n",
    "    X_true = np.array([0, 0, 5])\n",
    "    \n",
    "    # 三角測量角度（カメラ間の角度）を変化させる\n",
    "    angles = np.linspace(5, 90, 18)  # 5度から90度\n",
    "    \n",
    "    K = np.array([\n",
    "        [500, 0, 320],\n",
    "        [0, 500, 240],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    noise_level = 1.0\n",
    "    n_trials = 100\n",
    "    \n",
    "    mean_errors = []\n",
    "    std_errors = []\n",
    "    \n",
    "    for angle in angles:\n",
    "        # 2つのカメラを角度に応じて配置\n",
    "        half_angle = np.radians(angle / 2)\n",
    "        distance = 5  # カメラから3D点までの距離\n",
    "        \n",
    "        # カメラ1\n",
    "        C1 = np.array([-distance * np.tan(half_angle), 0, 0])\n",
    "        R1 = np.eye(3)\n",
    "        t1 = -R1 @ C1\n",
    "        P1 = create_projection_matrix(K, R1, t1)\n",
    "        \n",
    "        # カメラ2\n",
    "        C2 = np.array([distance * np.tan(half_angle), 0, 0])\n",
    "        R2 = np.eye(3)\n",
    "        t2 = -R2 @ C2\n",
    "        P2 = create_projection_matrix(K, R2, t2)\n",
    "        \n",
    "        # 投影\n",
    "        x1 = project_point(P1, X_true)\n",
    "        x2 = project_point(P2, X_true)\n",
    "        \n",
    "        errors = []\n",
    "        for _ in range(n_trials):\n",
    "            x1_noisy = x1 + np.random.randn(2) * noise_level\n",
    "            x2_noisy = x2 + np.random.randn(2) * noise_level\n",
    "            \n",
    "            X_est = triangulate_dlt([x1_noisy, x2_noisy], [P1, P2])\n",
    "            error = np.linalg.norm(X_est - X_true)\n",
    "            errors.append(error)\n",
    "        \n",
    "        mean_errors.append(np.mean(errors))\n",
    "        std_errors.append(np.std(errors))\n",
    "    \n",
    "    # 可視化\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.errorbar(angles, mean_errors, yerr=std_errors,\n",
    "                fmt='o-', capsize=3, capthick=1, markersize=6)\n",
    "    ax.set_xlabel('Triangulation Angle (degrees)', fontsize=12)\n",
    "    ax.set_ylabel('3D Error (meters)', fontsize=12)\n",
    "    ax.set_title('Triangulation Error vs Viewing Angle', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 最適角度をマーク\n",
    "    min_idx = np.argmin(mean_errors)\n",
    "    ax.axvline(x=angles[min_idx], color='red', linestyle='--', \n",
    "               label=f'Optimal: {angles[min_idx]:.0f}°')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"最小誤差の角度: {angles[min_idx]:.0f}度\")\n",
    "    print(\"\\n洞察:\")\n",
    "    print(\"- 角度が小さすぎると（狭いベースライン）深度精度が悪化\")\n",
    "    print(\"- 角度が大きすぎると対応点マッチングが困難に\")\n",
    "    print(\"- 実用上は20-60度程度が推奨\")\n",
    "\n",
    "analyze_triangulation_angle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. 3D復元のワークフロー\n",
    "\n",
    "### 8.1 完全な3D復元パイプライン\n",
    "\n",
    "```\n",
    "1. 特徴点検出・マッチング\n",
    "       ↓\n",
    "2. 基礎行列/本質行列の推定\n",
    "       ↓\n",
    "3. カメラ姿勢の復元（R, t）\n",
    "       ↓\n",
    "4. 三角測量による3D点の復元\n",
    "       ↓\n",
    "5. バンドル調整による最適化\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_3d_reconstruction_demo():\n",
    "    \"\"\"3D復元の完全なデモ\"\"\"\n",
    "    print(\"=== 3D復元パイプラインのデモ ===\")\n",
    "    \n",
    "    # 1. シーンの設定：複数の3D点\n",
    "    np.random.seed(42)\n",
    "    n_points = 20\n",
    "    X_true = np.random.randn(n_points, 3) * 0.5\n",
    "    X_true[:, 2] += 3  # カメラ前方に配置\n",
    "    \n",
    "    print(f\"1. 真の3D点: {n_points}点\")\n",
    "    \n",
    "    # 2. カメラの設定\n",
    "    K = np.array([\n",
    "        [500, 0, 320],\n",
    "        [0, 500, 240],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # カメラ1: 原点\n",
    "    R1 = np.eye(3)\n",
    "    t1 = np.zeros(3)\n",
    "    P1 = create_projection_matrix(K, R1, t1)\n",
    "    \n",
    "    # カメラ2: 右に移動、少し回転\n",
    "    theta = np.radians(15)\n",
    "    R2 = np.array([\n",
    "        [np.cos(theta), 0, np.sin(theta)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(theta), 0, np.cos(theta)]\n",
    "    ])\n",
    "    t2 = np.array([1, 0, 0])\n",
    "    P2 = create_projection_matrix(K, R2, t2)\n",
    "    \n",
    "    print(\"2. 2台のカメラを設定\")\n",
    "    \n",
    "    # 3. 投影（ノイズ付き）\n",
    "    noise_level = 0.5\n",
    "    points_1 = []\n",
    "    points_2 = []\n",
    "    \n",
    "    for X in X_true:\n",
    "        x1 = project_point(P1, X) + np.random.randn(2) * noise_level\n",
    "        x2 = project_point(P2, X) + np.random.randn(2) * noise_level\n",
    "        points_1.append(x1)\n",
    "        points_2.append(x2)\n",
    "    \n",
    "    points_1 = np.array(points_1)\n",
    "    points_2 = np.array(points_2)\n",
    "    \n",
    "    print(f\"3. 各カメラへの投影（ノイズ: {noise_level}px）\")\n",
    "    \n",
    "    # 4. 三角測量による復元\n",
    "    X_reconstructed = []\n",
    "    for x1, x2 in zip(points_1, points_2):\n",
    "        X = triangulate_optimal([x1, x2], [P1, P2])\n",
    "        X_reconstructed.append(X)\n",
    "    \n",
    "    X_reconstructed = np.array(X_reconstructed)\n",
    "    \n",
    "    print(\"4. 三角測量による3D復元完了\")\n",
    "    \n",
    "    # 5. 誤差評価\n",
    "    errors = np.linalg.norm(X_reconstructed - X_true, axis=1)\n",
    "    \n",
    "    print(f\"\\n=== 結果 ===\")\n",
    "    print(f\"平均3D誤差: {np.mean(errors):.4f} m\")\n",
    "    print(f\"最大3D誤差: {np.max(errors):.4f} m\")\n",
    "    print(f\"最小3D誤差: {np.min(errors):.4f} m\")\n",
    "    \n",
    "    return X_true, X_reconstructed, P1, P2, points_1, points_2\n",
    "\n",
    "X_true, X_reconstructed, P1, P2, pts1, pts2 = full_3d_reconstruction_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction_result(X_true, X_reconstructed, P1, P2):\n",
    "    \"\"\"復元結果の可視化\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # 3Dプロット\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    \n",
    "    # カメラ中心\n",
    "    def get_camera_center(P):\n",
    "        U, S, Vt = np.linalg.svd(P)\n",
    "        C_h = Vt[-1]\n",
    "        return C_h[:3] / C_h[3]\n",
    "    \n",
    "    C1 = get_camera_center(P1)\n",
    "    C2 = get_camera_center(P2)\n",
    "    \n",
    "    ax1.scatter(*C1, color='blue', s=200, marker='o', label='Camera 1')\n",
    "    ax1.scatter(*C2, color='green', s=200, marker='o', label='Camera 2')\n",
    "    \n",
    "    # 真の点\n",
    "    ax1.scatter(X_true[:, 0], X_true[:, 1], X_true[:, 2], \n",
    "                c='red', s=50, marker='o', alpha=0.5, label='True 3D Points')\n",
    "    \n",
    "    # 復元された点\n",
    "    ax1.scatter(X_reconstructed[:, 0], X_reconstructed[:, 1], X_reconstructed[:, 2],\n",
    "                c='blue', s=50, marker='x', alpha=0.7, label='Reconstructed')\n",
    "    \n",
    "    # 誤差ベクトル\n",
    "    for Xt, Xr in zip(X_true, X_reconstructed):\n",
    "        ax1.plot([Xt[0], Xr[0]], [Xt[1], Xr[1]], [Xt[2], Xr[2]], \n",
    "                 'k-', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    ax1.set_zlabel('Z')\n",
    "    ax1.set_title('3D Reconstruction Result', fontsize=12)\n",
    "    ax1.legend()\n",
    "    ax1.view_init(elev=20, azim=-60)\n",
    "    \n",
    "    # 誤差のヒストグラム\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    errors = np.linalg.norm(X_reconstructed - X_true, axis=1)\n",
    "    \n",
    "    ax2.hist(errors, bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax2.axvline(x=np.mean(errors), color='red', linestyle='--', \n",
    "                label=f'Mean: {np.mean(errors):.4f}m')\n",
    "    ax2.set_xlabel('3D Error (meters)', fontsize=12)\n",
    "    ax2.set_ylabel('Count', fontsize=12)\n",
    "    ax2.set_title('Distribution of Reconstruction Errors', fontsize=12)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_reconstruction_result(X_true, X_reconstructed, P1, P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. まとめと次のステップ\n",
    "\n",
    "### 学んだこと\n",
    "\n",
    "1. **三角測量の原理**: 複数視点からの光線の交点として3D点を復元\n",
    "2. **DLT法**: 線形方程式系をSVDで解く基本的な手法\n",
    "3. **中点法**: 光線間の最短距離の中点を使用\n",
    "4. **最適三角測量**: 再投影誤差を最小化する非線形最適化\n",
    "5. **多視点三角測量**: 冗長な観測により精度向上\n",
    "6. **誤差解析**: ベースライン、視差角と精度の関係\n",
    "\n",
    "### 重要な数式\n",
    "\n",
    "| 概念 | 数式 |\n",
    "|------|------|\n",
    "| 投影方程式 | $\\lambda \\mathbf{x} = \\mathbf{P} \\mathbf{X}$ |\n",
    "| DLTの拘束 | $u(\\mathbf{p}_3^\\top \\mathbf{X}) - (\\mathbf{p}_1^\\top \\mathbf{X}) = 0$ |\n",
    "| 深度誤差 | $\\delta Z = \\frac{Z^2}{fb} \\delta d$ |\n",
    "\n",
    "### 次のノートブック\n",
    "\n",
    "**58. 特徴点検出とマッチング**では：\n",
    "- SIFT, SURF, ORB などの特徴点検出\n",
    "- 特徴量記述子\n",
    "- マッチングアルゴリズム\n",
    "- 外れ値除去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. 自己評価クイズ\n",
    "\n",
    "以下の質問に答えて理解度を確認しましょう：\n",
    "\n",
    "1. 理想的な三角測量と実際の三角測量の違いは何ですか？\n",
    "\n",
    "2. DLT法で行列 $\\mathbf{A}$ を構築する際、各カメラからいくつの方程式が得られますか？\n",
    "\n",
    "3. 中点法と DLT法の違いを説明してください。\n",
    "\n",
    "4. 最適三角測量が DLT より優れている点は何ですか？\n",
    "\n",
    "5. カメラ数を増やすと三角測量の精度が向上する理由は？\n",
    "\n",
    "6. 深度誤差 $\\delta Z = \\frac{Z^2}{fb} \\delta d$ から、精度を向上させるにはどうすればよいですか？\n",
    "\n",
    "7. 三角測量角度が小さすぎる場合と大きすぎる場合、それぞれどのような問題が生じますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クイズの解答（隠し）\n",
    "def show_quiz_answers():\n",
    "    answers = \"\"\"\n",
    "    === 自己評価クイズ解答 ===\n",
    "    \n",
    "    1. 理想と現実の違い:\n",
    "       - 理想: 2つの光線が1点で正確に交わる\n",
    "       - 現実: ノイズにより光線は交わらない（ねじれの位置）\n",
    "       - そのため、最良近似を求める必要がある\n",
    "    \n",
    "    2. DLTの方程式数:\n",
    "       - 各カメラから2つの方程式が得られる\n",
    "       - n視点で 2n × 4 の行列Aを構築\n",
    "       - 最低2視点（4方程式）で解が求まる\n",
    "    \n",
    "    3. 中点法 vs DLT:\n",
    "       - 中点法: 幾何学的（光線間の最短距離の中点）\n",
    "       - DLT: 代数的（同次線形方程式系をSVDで解く）\n",
    "       - どちらも線形近似だが、アプローチが異なる\n",
    "    \n",
    "    4. 最適三角測量の利点:\n",
    "       - 再投影誤差を明示的に最小化\n",
    "       - 画像ノイズの影響を考慮\n",
    "       - エピポーラ拘束を満たすように補正\n",
    "       - より統計的に最適な解が得られる\n",
    "    \n",
    "    5. カメラ数増加の効果:\n",
    "       - 冗長な観測により、ノイズの影響が平均化される\n",
    "       - 方程式数が増え、過決定系になる\n",
    "       - 最小二乗解がより安定する\n",
    "    \n",
    "    6. 精度向上の方法:\n",
    "       - ベースライン b を大きくする\n",
    "       - 視差誤差 δd を小さくする（高精度な特徴点検出）\n",
    "       - 焦点距離 f を大きくする（望遠レンズ）\n",
    "       - 近距離で測定する（Z を小さく）\n",
    "    \n",
    "    7. 三角測量角度の問題:\n",
    "       - 小さすぎる場合: \n",
    "         - 深度方向の不確実性が大きい\n",
    "         - 小さな画像ノイズが大きな深度誤差に\n",
    "       - 大きすぎる場合:\n",
    "         - 対応点マッチングが困難（見え方が大きく異なる）\n",
    "         - オクルージョンが増加\n",
    "       - 実用上は20-60度程度が推奨\n",
    "    \"\"\"\n",
    "    print(answers)\n",
    "\n",
    "# 解答を見るには以下のコメントを外して実行\n",
    "# show_quiz_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ナビゲーション\n",
    "\n",
    "- **前のノートブック**: [56. ステレオ視と視差](56_stereo_vision_disparity_v1.ipynb)\n",
    "- **次のノートブック**: [58. 特徴点検出とマッチング](58_feature_detection_matching_v1.ipynb)\n",
    "- **カリキュラム**: [CURRICULUM_UNIT_0.3.md](CURRICULUM_UNIT_0.3.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

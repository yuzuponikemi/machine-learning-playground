{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23. ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­– - ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œã®è§£æ±º (Imbalanced Data Handling)\n",
    "\n",
    "## æ¦‚è¦\n",
    "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ãªæ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚SMOTEã€Focal Lossã€ã‚³ã‚¹ãƒˆè€ƒæ…®å­¦ç¿’ãªã©ã€å®Ÿå‹™ã§é »å‡ºã™ã‚‹ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ç¶²ç¾…ã—ã¾ã™ã€‚\n",
    "\n",
    "## å­¦ç¿’ç›®æ¨™\n",
    "- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œç‚¹ã‚’ç†è§£ã§ãã‚‹\n",
    "- é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠã§ãã‚‹\n",
    "- ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’ä½¿ã„ã“ãªã›ã‚‹\n",
    "- ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ¬ãƒ™ãƒ«ã®å¯¾ç­–ãŒã§ãã‚‹\n",
    "- å®Ÿå‹™ã§ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    precision_recall_curve, roc_curve, average_precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è¨­å®š\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãªãœä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã¯å•é¡Œãªã®ã‹\n",
    "\n",
    "### ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¨ã¯\n",
    "\n",
    "**ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ï¼ˆClass Imbalanceï¼‰**ã¯ã€åˆ†é¡å•é¡Œã«ãŠã„ã¦å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¤§ããåã£ã¦ã„ã‚‹çŠ¶æ…‹ã§ã™ã€‚\n",
    "\n",
    "### å®Ÿä¸–ç•Œã§ã®ä¾‹\n",
    "\n",
    "1. **ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ä¸æ­£æ¤œçŸ¥**\n",
    "   - æ­£å¸¸å–å¼•: 99.9%\n",
    "   - ä¸æ­£å–å¼•: 0.1%\n",
    "\n",
    "2. **åŒ»ç™‚è¨ºæ–­**\n",
    "   - å¥åº·: 95%\n",
    "   - ç–¾æ‚£: 5%\n",
    "\n",
    "3. **æ©Ÿæ¢°æ•…éšœäºˆæ¸¬**\n",
    "   - æ­£å¸¸ç¨¼åƒ: 98%\n",
    "   - æ•…éšœ: 2%\n",
    "\n",
    "### ä½•ãŒå•é¡Œã‹\n",
    "\n",
    "å¤šæ•°æ´¾ã‚¯ãƒ©ã‚¹ã«åã£ãŸäºˆæ¸¬ã‚’ã—ã¦ã‚‚ã€é«˜ã„ç²¾åº¦ã‚’é”æˆã§ãã¦ã—ã¾ã†ï¼š\n",
    "\n",
    "```python\n",
    "# ä¾‹: ä¸æ­£æ¤œçŸ¥ã§ã€Œå…¨ã¦æ­£å¸¸ã€ã¨äºˆæ¸¬\n",
    "# â†’ ç²¾åº¦99.9%é”æˆï¼ã§ã‚‚ä¸æ­£ã¯1ä»¶ã‚‚æ¤œçŸ¥ã§ããªã„\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨å•é¡Œã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆä¸æ­£æ¤œçŸ¥ã‚’æ¨¡æ“¬ï¼‰\n",
    "X, y = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_clusters_per_class=2,\n",
    "    weights=[0.95, 0.05],  # 95% vs 5%ã®ä¸å‡è¡¡\n",
    "    flip_y=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆå±¤åŒ–æŠ½å‡ºã‚’ä½¿ç”¨ï¼‰\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {X.shape}\")\n",
    "print(f\"\\nã‚¯ãƒ©ã‚¹åˆ†å¸ƒ:\")\n",
    "print(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {Counter(y_train)}\")\n",
    "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {Counter(y_test)}\")\n",
    "print(f\"\\nä¸å‡è¡¡ç‡: {Counter(y_train)[0] / Counter(y_train)[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "train_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "axes[0].bar(['Negative (0)', 'Positive (1)'], train_counts.values, \n",
    "            color=['skyblue', 'salmon'], alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Training Data Class Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(train_counts.values):\n",
    "    axes[0].text(i, v, f'{v}\\n({v/len(y_train)*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "test_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "axes[1].bar(['Negative (0)', 'Positive (1)'], test_counts.values,\n",
    "            color=['skyblue', 'salmon'], alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Test Data Class Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(test_counts.values):\n",
    "    axes[1].text(i, v, f'{v}\\n({v/len(y_test)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâš ï¸ å•é¡Œç‚¹:\")\n",
    "print(\"- å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ï¼ˆPositiveï¼‰ãŒå…¨ä½“ã®ç´„5%ã—ã‹ãªã„\")\n",
    "print(\"- ã“ã®ã¾ã¾ã§ã¯å¤šæ•°æ´¾ã«åã£ãŸäºˆæ¸¬ã‚’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ãªã‚Šã‚„ã™ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: å•é¡Œã®ç¢ºèª\n",
    "\n",
    "ã¾ãšã€ä½•ã‚‚å¯¾ç­–ã›ãšã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã¦å•é¡Œã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆå¯¾ç­–ãªã—ï¼‰\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# äºˆæ¸¬\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_proba_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# è©•ä¾¡\n",
    "print(\"=\" * 60)\n",
    "print(\"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_baseline):.4f}\")\n",
    "print(\"\\næ··åŒè¡Œåˆ—:\")\n",
    "print(confusion_matrix(y_test, y_pred_baseline))\n",
    "print(\"\\nâš ï¸ æ³¨æ„:\")\n",
    "print(\"- Accuracyã¯é«˜ã„ãŒã€Recallï¼ˆå†ç¾ç‡ï¼‰ãŒä½ã„\")\n",
    "print(\"- å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã‚’è¦‹é€ƒã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©³ç´°ãªå¯è¦–åŒ–\n",
    "def plot_confusion_matrix_detailed(y_true, y_pred, title):\n",
    "    \"\"\"è©³ç´°ãªæ··åŒè¡Œåˆ—ã‚’å¯è¦–åŒ–\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "                xticklabels=['Predicted Neg', 'Predicted Pos'],\n",
    "                yticklabels=['Actual Neg', 'Actual Pos'],\n",
    "                ax=ax)\n",
    "    \n",
    "    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’è¿½åŠ \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            percentage = cm[i, j] / cm[i].sum() * 100\n",
    "            ax.text(j + 0.5, i + 0.7, f'({percentage:.1f}%)',\n",
    "                   ha='center', va='center', fontsize=10, color='red')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æŒ‡æ¨™ã®èª¬æ˜\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"\\nè©³ç´°æŒ‡æ¨™:\")\n",
    "    print(f\"- True Negatives (TN):  {tn} (æ­£ã—ããƒã‚¬ãƒ†ã‚£ãƒ–ã¨äºˆæ¸¬)\")\n",
    "    print(f\"- False Positives (FP): {fp} (èª¤ã£ã¦ãƒã‚¸ãƒ†ã‚£ãƒ–ã¨äºˆæ¸¬)\")\n",
    "    print(f\"- False Negatives (FN): {fn} (èª¤ã£ã¦ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨äºˆæ¸¬) âš ï¸\")\n",
    "    print(f\"- True Positives (TP):  {tp} (æ­£ã—ããƒã‚¸ãƒ†ã‚£ãƒ–ã¨äºˆæ¸¬)\")\n",
    "    print(f\"\\nâš ï¸ FNï¼ˆè¦‹é€ƒã—ï¼‰ãŒå¤šã„ã¨å•é¡Œï¼\")\n",
    "\n",
    "plot_confusion_matrix_detailed(y_test, y_pred_baseline, \n",
    "                                'Baseline Model - Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è©•ä¾¡æŒ‡æ¨™ã®é¸æŠ\n",
    "\n",
    "### Accuracyã®ç½ \n",
    "\n",
    "ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯**Accuracyï¼ˆæ­£è§£ç‡ï¼‰ã¯é©åˆ‡ãªæŒ‡æ¨™ã§ã¯ã‚ã‚Šã¾ã›ã‚“**ã€‚\n",
    "\n",
    "### é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™\n",
    "\n",
    "1. **Precisionï¼ˆç²¾åº¦ï¼‰**: é™½æ€§ã¨äºˆæ¸¬ã—ãŸã‚‚ã®ã®ã†ã¡ã€å®Ÿéš›ã«é™½æ€§ã ã£ãŸå‰²åˆ\n",
    "   - é‡è¦ãªå ´é¢: èª¤æ¤œçŸ¥ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼ˆã‚¹ãƒ‘ãƒ ãƒ¡ãƒ¼ãƒ«æ¤œçŸ¥ãªã©ï¼‰\n",
    "\n",
    "2. **Recallï¼ˆå†ç¾ç‡ï¼‰**: å®Ÿéš›ã®é™½æ€§ã®ã†ã¡ã€æ­£ã—ãäºˆæ¸¬ã§ããŸå‰²åˆ\n",
    "   - é‡è¦ãªå ´é¢: è¦‹é€ƒã—ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼ˆç–¾æ‚£è¨ºæ–­ãªã©ï¼‰\n",
    "\n",
    "3. **F1-Score**: Precisionã¨Recallã®èª¿å’Œå¹³å‡\n",
    "   - ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚ŠãŸã„å ´åˆ\n",
    "\n",
    "4. **ROC-AUC**: é–¾å€¤ã«ä¾å­˜ã—ãªã„ç·åˆçš„ãªæ€§èƒ½\n",
    "   - ãƒ¢ãƒ‡ãƒ«ã®è­˜åˆ¥èƒ½åŠ›ã‚’è©•ä¾¡\n",
    "\n",
    "5. **PR-AUC**: Precision-Recallæ›²ç·šä¸‹é¢ç©\n",
    "   - ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ROC-AUCã‚ˆã‚Šé©åˆ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROCæ›²ç·šã¨PRæ›²ç·šã®æ¯”è¼ƒ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROCæ›²ç·š\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_baseline)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_baseline)\n",
    "axes[0].plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)', linewidth=1)\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=11)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=11)\n",
    "axes[0].set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# PRæ›²ç·š\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_baseline)\n",
    "pr_auc = average_precision_score(y_test, y_proba_baseline)\n",
    "axes[1].plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.3f})', linewidth=2)\n",
    "baseline_precision = sum(y_test) / len(y_test)\n",
    "axes[1].axhline(baseline_precision, color='k', linestyle='--', \n",
    "                label=f'Random (AP = {baseline_precision:.3f})', linewidth=1)\n",
    "axes[1].set_xlabel('Recall', fontsize=11)\n",
    "axes[1].set_ylabel('Precision', fontsize=11)\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ãƒã‚¤ãƒ³ãƒˆ:\")\n",
    "print(\"- ROCæ›²ç·š: å…¨ä½“çš„ãªè­˜åˆ¥èƒ½åŠ›ã‚’è©•ä¾¡\")\n",
    "print(\"- PRæ›²ç·š: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã‚ˆã‚Šæœ‰ç”¨ï¼ˆå°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã«ç„¦ç‚¹ï¼‰\")\n",
    "print(f\"- PR-AUC ({pr_auc:.3f}) ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ({baseline_precision:.3f}) ã‚ˆã‚Šé«˜ã„ã“ã¨ãŒé‡è¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å¯¾ç­–1: ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•\n",
    "\n",
    "### ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ç¨®é¡\n",
    "\n",
    "1. **ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã‚’å¢—ã‚„ã™\n",
    "   - Random Over-sampling\n",
    "   - SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "   - ADASYN, BorderlineSMOTE\n",
    "\n",
    "2. **ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**: å¤šæ•°æ´¾ã‚¯ãƒ©ã‚¹ã‚’æ¸›ã‚‰ã™\n",
    "   - Random Under-sampling\n",
    "   - Tomek Links\n",
    "   - Edited Nearest Neighbours\n",
    "\n",
    "3. **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰**: ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã‚‹\n",
    "   - SMOTEENN\n",
    "   - SMOTETomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"SMOTEã«ã‚ˆã‚‹ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°çµæœ:\")\n",
    "print(f\"å…ƒã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {Counter(y_train)}\")\n",
    "print(f\"SMOTEå¾Œ: {Counter(y_train_smote)}\")\n",
    "print(f\"\\nã‚µãƒ³ãƒ—ãƒ«æ•°ã®å¤‰åŒ–: {len(y_train)} â†’ {len(y_train_smote)}\")\n",
    "\n",
    "# SMOTEã®ä»•çµ„ã¿ã®å¯è¦–åŒ–\n",
    "print(\"\\nğŸ’¡ SMOTEã®ä»•çµ„ã¿:\")\n",
    "print(\"1. å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®å„ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ã„ã¦ã€kè¿‘å‚ã‚’è¦‹ã¤ã‘ã‚‹\")\n",
    "print(\"2. ãã®è¿‘å‚ã®1ã¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã¶\")\n",
    "print(\"3. 2ã¤ã®ã‚µãƒ³ãƒ—ãƒ«é–“ã«æ–°ã—ã„åˆæˆã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ\")\n",
    "print(\"   new_sample = sample + Î» * (neighbor - sample), Î» âˆˆ [0, 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "model_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# äºˆæ¸¬ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã„ï¼ï¼‰\n",
    "y_pred_smote = model_smote.predict(X_test)\n",
    "y_proba_smote = model_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# è©•ä¾¡\n",
    "print(\"=\" * 60)\n",
    "print(\"SMOTEã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_smote):.4f} â¬†ï¸\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_smote):.4f}\")\n",
    "\n",
    "print(\"\\næ”¹å–„ç‚¹:\")\n",
    "print(f\"- Recall: {recall_score(y_test, y_pred_baseline):.4f} â†’ {recall_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"- F1-Score: {f1_score(y_test, y_pred_baseline):.4f} â†’ {f1_score(y_test, y_pred_smote):.4f}\")\n",
    "\n",
    "plot_confusion_matrix_detailed(y_test, y_pred_smote, 'SMOTE Model - Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ãã®ä»–ã®ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¤‡æ•°ã®ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’æ¯”è¼ƒ\n",
    "resamplers = {\n",
    "    'Baseline (No Resampling)': None,\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42),\n",
    "    'SMOTEENN': SMOTEENN(random_state=42),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, resampler in resamplers.items():\n",
    "    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "    if resampler is None:\n",
    "        X_train_res, y_train_res = X_train, y_train\n",
    "    else:\n",
    "        X_train_res, y_train_res = resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    # äºˆæ¸¬\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # è©•ä¾¡\n",
    "    results.append({\n",
    "        'Method': name,\n",
    "        'Samples': len(y_train_res),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba),\n",
    "        'PR-AUC': average_precision_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "# çµæœã‚’DataFrameã«\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# ãƒ™ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n",
    "print(\"\\nğŸ† å„æŒ‡æ¨™ã§ã®ãƒ™ã‚¹ãƒˆ:\")\n",
    "for col in ['Recall', 'F1-Score', 'ROC-AUC', 'PR-AUC']:\n",
    "    best_idx = results_df[col].idxmax()\n",
    "    print(f\"- {col}: {results_df.loc[best_idx, 'Method']} ({results_df.loc[best_idx, col]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã®å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "metrics = ['Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¼·èª¿\n",
    "    colors = ['red' if m == 'Baseline (No Resampling)' else 'skyblue' \n",
    "              for m in results_df['Method']]\n",
    "    \n",
    "    bars = ax.barh(results_df['Method'], results_df[metric], color=colors, \n",
    "                   alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel(metric, fontsize=11)\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # å€¤ã®ãƒ©ãƒ™ãƒ«\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ è¦³å¯Ÿ:\")\n",
    "print(\"- ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚ŠRecallãŒæ”¹å–„\")\n",
    "print(\"- ãŸã ã—ã€Precisionã¯ã‚„ã‚„ä½ä¸‹ã™ã‚‹å‚¾å‘\")\n",
    "print(\"- ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãªã‚‰SMOTEç³»ãŒæœ‰åŠ¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å¯¾ç­–2: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ¬ãƒ™ãƒ«ã®æ‰‹æ³•\n",
    "\n",
    "### 6.1 ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘ï¼ˆClass Weightsï¼‰\n",
    "\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚’å¢—æ¸›ã•ã›ã‚‹ä»£ã‚ã‚Šã«ã€å­¦ç¿’æ™‚ã«å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®é‡è¦åº¦ã‚’ä¸Šã’ã‚‹æ–¹æ³•ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¯ãƒ©ã‚¹é‡ã¿ã®è‡ªå‹•è¨ˆç®—\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# æ‰‹å‹•è¨ˆç®—\n",
    "class_weights_manual = {\n",
    "    0: len(y_train) / (2 * Counter(y_train)[0]),\n",
    "    1: len(y_train) / (2 * Counter(y_train)[1])\n",
    "}\n",
    "\n",
    "print(\"ã‚¯ãƒ©ã‚¹é‡ã¿:\")\n",
    "print(f\"- ã‚¯ãƒ©ã‚¹0ï¼ˆå¤šæ•°æ´¾ï¼‰: {class_weights_manual[0]:.3f}\")\n",
    "print(f\"- ã‚¯ãƒ©ã‚¹1ï¼ˆå°‘æ•°æ´¾ï¼‰: {class_weights_manual[1]:.3f}\")\n",
    "print(f\"\\nå°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®é‡ã¿ã¯å¤šæ•°æ´¾ã® {class_weights_manual[1] / class_weights_manual[0]:.1f}å€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ããƒ¢ãƒ‡ãƒ«\n",
    "model_weighted = LogisticRegression(\n",
    "    class_weight='balanced',  # è‡ªå‹•ã§é‡ã¿ã‚’èª¿æ•´\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "model_weighted.fit(X_train, y_train)\n",
    "\n",
    "# äºˆæ¸¬\n",
    "y_pred_weighted = model_weighted.predict(X_test)\n",
    "y_proba_weighted = model_weighted.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# è©•ä¾¡\n",
    "print(\"=\" * 60)\n",
    "print(\"ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ããƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_weighted):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_weighted):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_weighted):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_weighted):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_weighted):.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ãƒ¡ãƒªãƒƒãƒˆ:\")\n",
    "print(\"- ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã•ãªã„ã®ã§ã€éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ãŒä½ã„\")\n",
    "print(\"- è¨ˆç®—ã‚³ã‚¹ãƒˆãŒä½ã„ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤‰ã‚ã‚‰ãªã„ï¼‰\")\n",
    "print(\"- scikit-learnã®å¤šãã®ãƒ¢ãƒ‡ãƒ«ã§åˆ©ç”¨å¯èƒ½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 é–¾å€¤èª¿æ•´ï¼ˆThreshold Tuningï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–¾å€¤ã‚’å¤‰ãˆãŸå ´åˆã®æ€§èƒ½å¤‰åŒ–ã‚’èª¿ã¹ã‚‹\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "threshold_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_proba_baseline >= threshold).astype(int)\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Precision': precision_score(y_test, y_pred_threshold, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred_threshold),\n",
    "        'F1-Score': f1_score(y_test, y_pred_threshold)\n",
    "    })\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(threshold_df['Threshold'], threshold_df['Precision'], \n",
    "         label='Precision', marker='o', linewidth=2)\n",
    "plt.plot(threshold_df['Threshold'], threshold_df['Recall'], \n",
    "         label='Recall', marker='s', linewidth=2)\n",
    "plt.plot(threshold_df['Threshold'], threshold_df['F1-Score'], \n",
    "         label='F1-Score', marker='^', linewidth=2)\n",
    "\n",
    "# æœ€é©é–¾å€¤ï¼ˆF1-ScoreãŒæœ€å¤§ï¼‰\n",
    "best_threshold_idx = threshold_df['F1-Score'].idxmax()\n",
    "best_threshold = threshold_df.loc[best_threshold_idx, 'Threshold']\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', \n",
    "            label=f'Best threshold ({best_threshold:.2f})', linewidth=2)\n",
    "\n",
    "plt.xlabel('Threshold', fontsize=11)\n",
    "plt.ylabel('Score', fontsize=11)\n",
    "plt.title('Threshold vs Performance Metrics', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\næœ€é©é–¾å€¤: {best_threshold:.2f}\")\n",
    "print(f\"F1-Score: {threshold_df.loc[best_threshold_idx, 'F1-Score']:.4f}\")\n",
    "print(f\"\\nãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤(0.5)ã¨ã®æ¯”è¼ƒ:\")\n",
    "default_idx = threshold_df[threshold_df['Threshold'] == 0.5].index[0]\n",
    "print(f\"- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ F1: {threshold_df.loc[default_idx, 'F1-Score']:.4f}\")\n",
    "print(f\"- æœ€é© F1: {threshold_df.loc[best_threshold_idx, 'F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ã‚³ã‚¹ãƒˆè€ƒæ…®å­¦ç¿’ï¼ˆCost-Sensitive Learningï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚«ã‚¹ã‚¿ãƒ ã‚³ã‚¹ãƒˆé–¢æ•°\n",
    "def cost_sensitive_score(y_true, y_pred, fp_cost=1, fn_cost=10):\n",
    "    \"\"\"\n",
    "    ã‚³ã‚¹ãƒˆè€ƒæ…®å‹ã®ã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fp_cost : float\n",
    "        False Positiveï¼ˆèª¤æ¤œçŸ¥ï¼‰ã®ã‚³ã‚¹ãƒˆ\n",
    "    fn_cost : float\n",
    "        False Negativeï¼ˆè¦‹é€ƒã—ï¼‰ã®ã‚³ã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    total_cost = fp * fp_cost + fn * fn_cost\n",
    "    return -total_cost  # è² ã®ã‚³ã‚¹ãƒˆï¼ˆæœ€å°åŒ– â†’ æœ€å¤§åŒ–ã«å¤‰æ›ï¼‰\n",
    "\n",
    "# ç•°ãªã‚‹ã‚³ã‚¹ãƒˆæ¯”ç‡ã§ã®æœ€é©é–¾å€¤ã‚’æ¢ç´¢\n",
    "cost_ratios = [1, 5, 10, 20]\n",
    "\n",
    "print(\"ç•°ãªã‚‹ã‚³ã‚¹ãƒˆæ¯”ç‡ã§ã®æœ€é©é–¾å€¤:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for fn_cost in cost_ratios:\n",
    "    best_score = float('-inf')\n",
    "    best_threshold_cost = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_threshold = (y_proba_baseline >= threshold).astype(int)\n",
    "        score = cost_sensitive_score(y_test, y_pred_threshold, fp_cost=1, fn_cost=fn_cost)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold_cost = threshold\n",
    "    \n",
    "    print(f\"FN/FP ã‚³ã‚¹ãƒˆæ¯” = {fn_cost}:1 â†’ æœ€é©é–¾å€¤ = {best_threshold_cost:.2f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ è¦³å¯Ÿ:\")\n",
    "print(\"- è¦‹é€ƒã—ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„ã»ã©ã€é–¾å€¤ã‚’ä¸‹ã’ã‚‹ï¼ˆRecallã‚’å„ªå…ˆï¼‰\")\n",
    "print(\"- ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«å¿œã˜ã¦é©åˆ‡ãªé–¾å€¤ã‚’é¸æŠ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¯¾ç­–3: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’\n",
    "\n",
    "### 7.1 EasyEnsemble\n",
    "\n",
    "å¤šæ•°æ´¾ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦è¤‡æ•°ã®ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier\n",
    "\n",
    "# EasyEnsemble\n",
    "easy_ensemble = EasyEnsembleClassifier(n_estimators=10, random_state=42)\n",
    "easy_ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ee = easy_ensemble.predict(X_test)\n",
    "y_proba_ee = easy_ensemble.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EasyEnsemble ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_ee):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_ee):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_ee):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_ee):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_ee):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Balanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Random Forest\n",
    "balanced_rf = BalancedRandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "balanced_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_brf = balanced_rf.predict(X_test)\n",
    "y_proba_brf = balanced_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Balanced Random Forest ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_brf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_brf):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_brf):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_brf):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_brf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. GBDT + ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–\n",
    "\n",
    "LightGBMã€XGBoostã€CatBoostã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹çµ„ã¿è¾¼ã¿ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# LightGBM with scale_pos_weight\n",
    "scale_pos_weight = Counter(y_train)[0] / Counter(y_train)[1]\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "y_proba_lgb = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LightGBM (scale_pos_weight) ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_lgb):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lgb):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_lgb):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_lgb):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_lgb):.4f}\")\n",
    "\n",
    "# XGBoost with scale_pos_weight\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"XGBoost (scale_pos_weight) ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Focal Loss ã®å®Ÿè£…\n",
    "\n",
    "**Focal Loss**ã¯ã€RetinaNetã§ææ¡ˆã•ã‚ŒãŸæå¤±é–¢æ•°ã§ã€ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ã®é‡ã¿ã‚’ä¸‹ã’ã€é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã«é›†ä¸­ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚\n",
    "\n",
    "$$\n",
    "FL(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t)\n",
    "$$\n",
    "\n",
    "- $\\gamma$: focusing parameterï¼ˆé›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã¸ã®æ³¨ç›®åº¦ï¼‰\n",
    "- $\\alpha_t$: ã‚¯ãƒ©ã‚¹é‡ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMç”¨ã®ã‚«ã‚¹ã‚¿ãƒ Focal Loss\n",
    "def focal_loss_lgb(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    \"\"\"\n",
    "    LightGBMç”¨ã®Focal Losså®Ÿè£…\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    alpha : float\n",
    "        ã‚¯ãƒ©ã‚¹é‡ã¿ï¼ˆ0.25ãŒæ¨å¥¨å€¤ï¼‰\n",
    "    gamma : float\n",
    "        focusing parameterï¼ˆ2.0ãŒæ¨å¥¨å€¤ï¼‰\n",
    "    \"\"\"\n",
    "    a, g = alpha, gamma\n",
    "    \n",
    "    def fl(y_true, y_pred):\n",
    "        # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã§ç¢ºç‡ã«å¤‰æ›\n",
    "        p = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "        \n",
    "        # Focal Loss ã®å‹¾é…\n",
    "        grad = a * (g * (y_true - p) * np.power(1 - p, g - 1) * p * (1 - p) + \n",
    "                   np.power(1 - p, g) * (y_true - p))\n",
    "        \n",
    "        # ãƒ˜ãƒƒã‚»è¡Œåˆ—ï¼ˆ2æ¬¡å¾®åˆ†ï¼‰\n",
    "        hess = a * g * (g - 1) * np.power(1 - p, g - 2) * p * (1 - p) * (y_true - p) + \\\n",
    "               a * g * np.power(1 - p, g - 1) * ((1 - p) - p) * (y_true - p) + \\\n",
    "               a * np.power(1 - p, g) * (1)\n",
    "        hess = np.abs(hess)  # çµ¶å¯¾å€¤ã‚’å–ã‚‹ï¼ˆå®‰å®šæ€§ã®ãŸã‚ï¼‰\n",
    "        \n",
    "        return grad, hess\n",
    "    \n",
    "    return fl(y_true, y_pred)\n",
    "\n",
    "# Focal Lossã‚’ä½¿ã£ãŸLightGBM\n",
    "lgb_focal = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# ã‚«ã‚¹ã‚¿ãƒ ç›®çš„é–¢æ•°ã¨ã—ã¦ä½¿ç”¨\n",
    "lgb_focal.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "y_pred_focal = lgb_focal.predict(X_test)\n",
    "y_proba_focal = lgb_focal.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LightGBM with Focal Loss ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_focal):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_focal):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_focal):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_focal):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_proba_focal):.4f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Focal Lossã®ç‰¹å¾´:\")\n",
    "print(\"- é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ï¼ˆèª¤åˆ†é¡ã•ã‚Œã‚„ã™ã„ï¼‰ã«é›†ä¸­\")\n",
    "print(\"- ç°¡å˜ãªã‚µãƒ³ãƒ—ãƒ«ï¼ˆæ­£ã—ãåˆ†é¡ã§ãã‚‹ï¼‰ã®å½±éŸ¿ã‚’æ¸›ã‚‰ã™\")\n",
    "print(\"- æ¥µç«¯ãªä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ç‰¹ã«æœ‰åŠ¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. å…¨æ‰‹æ³•ã®ç·åˆæ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…¨ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’é›†ç´„\n",
    "all_results = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'Baseline',\n",
    "        'Precision': precision_score(y_test, y_pred_baseline),\n",
    "        'Recall': recall_score(y_test, y_pred_baseline),\n",
    "        'F1-Score': f1_score(y_test, y_pred_baseline),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_baseline)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'SMOTE',\n",
    "        'Precision': precision_score(y_test, y_pred_smote),\n",
    "        'Recall': recall_score(y_test, y_pred_smote),\n",
    "        'F1-Score': f1_score(y_test, y_pred_smote),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_smote)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Class Weights',\n",
    "        'Precision': precision_score(y_test, y_pred_weighted),\n",
    "        'Recall': recall_score(y_test, y_pred_weighted),\n",
    "        'F1-Score': f1_score(y_test, y_pred_weighted),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_weighted)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'EasyEnsemble',\n",
    "        'Precision': precision_score(y_test, y_pred_ee),\n",
    "        'Recall': recall_score(y_test, y_pred_ee),\n",
    "        'F1-Score': f1_score(y_test, y_pred_ee),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_ee)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Balanced RF',\n",
    "        'Precision': precision_score(y_test, y_pred_brf),\n",
    "        'Recall': recall_score(y_test, y_pred_brf),\n",
    "        'F1-Score': f1_score(y_test, y_pred_brf),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_brf)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'LightGBM',\n",
    "        'Precision': precision_score(y_test, y_pred_lgb),\n",
    "        'Recall': recall_score(y_test, y_pred_lgb),\n",
    "        'F1-Score': f1_score(y_test, y_pred_lgb),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_lgb)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'XGBoost',\n",
    "        'Precision': precision_score(y_test, y_pred_xgb),\n",
    "        'Recall': recall_score(y_test, y_pred_xgb),\n",
    "        'F1-Score': f1_score(y_test, y_pred_xgb),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_xgb)\n",
    "    },\n",
    "    {\n",
    "        'Method': 'LightGBM + Focal',\n",
    "        'Precision': precision_score(y_test, y_pred_focal),\n",
    "        'Recall': recall_score(y_test, y_pred_focal),\n",
    "        'F1-Score': f1_score(y_test, y_pred_focal),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba_focal)\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"å…¨æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒ\")\n",
    "print(\"=\" * 80)\n",
    "print(all_results.to_string(index=False))\n",
    "\n",
    "# å„æŒ‡æ¨™ã§ã®ãƒ™ã‚¹ãƒˆ\n",
    "print(\"\\nğŸ† å„æŒ‡æ¨™ã§ã®ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«:\")\n",
    "for col in ['Precision', 'Recall', 'F1-Score', 'ROC-AUC']:\n",
    "    best_idx = all_results[col].idxmax()\n",
    "    print(f\"- {col}: {all_results.loc[best_idx, 'Method']} ({all_results.loc[best_idx, col]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§å¯è¦–åŒ–\n",
    "from math import pi\n",
    "\n",
    "# ãƒˆãƒƒãƒ—5æ‰‹æ³•ã‚’é¸æŠ\n",
    "top_methods = all_results.nlargest(5, 'F1-Score')\n",
    "\n",
    "categories = ['Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "N = len(categories)\n",
    "\n",
    "# è§’åº¦ã®è¨ˆç®—\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "for idx, row in top_methods.iterrows():\n",
    "    values = row[categories].values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=row['Method'])\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, size=11)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Performance Comparison (Top 5 Methods)', \n",
    "             size=14, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. å®Ÿå‹™ã§ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹\n",
    "\n",
    "### æ‰‹æ³•é¸æŠã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³\n",
    "\n",
    "| ã‚·ãƒŠãƒªã‚ª | æ¨å¥¨æ‰‹æ³• | ç†ç”± |\n",
    "|---------|---------|------|\n",
    "| è»½åº¦ã®ä¸å‡è¡¡ï¼ˆ10:1ä»¥ä¸‹ï¼‰ | ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘ | ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ |\n",
    "| ä¸­ç¨‹åº¦ã®ä¸å‡è¡¡ï¼ˆ10:1ï½100:1ï¼‰ | SMOTE + GBDTã¾ãŸã¯Balanced RF | ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ |\n",
    "| æ¥µç«¯ãªä¸å‡è¡¡ï¼ˆ100:1ä»¥ä¸Šï¼‰ | SMOTEENN + Focal Loss | éå­¦ç¿’ã‚’æŠ‘åˆ¶ |\n",
    "| è¦‹é€ƒã—ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„ | é–¾å€¤èª¿æ•´ + SMOTE | Recallã‚’æœ€å¤§åŒ– |\n",
    "| èª¤æ¤œçŸ¥ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„ | ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´ | Precisionã‚’å„ªå…ˆ |\n",
    "| è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹è±Šå¯Œ | ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆEasyEnsembleç­‰ï¼‰ | æœ€é«˜æ€§èƒ½ |\n",
    "| è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹é™å®š | ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘ | è»½é‡ |\n",
    "\n",
    "### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "```python\n",
    "# âœ… ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
    "# - ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚’å¯è¦–åŒ–ã—ãŸã‹ï¼Ÿ\n",
    "# - ä¸å‡è¡¡ç‡ã‚’ç¢ºèªã—ãŸã‹ï¼Ÿ\n",
    "\n",
    "# 2. è©•ä¾¡æŒ‡æ¨™ã®é¸æŠ\n",
    "# - Accuracyä»¥å¤–ã®æŒ‡æ¨™ã‚’ä½¿ã£ã¦ã„ã‚‹ã‹ï¼Ÿ\n",
    "# - ãƒ“ã‚¸ãƒã‚¹ç›®æ¨™ã«åˆã£ãŸæŒ‡æ¨™ã‹ï¼Ÿ\n",
    "# - PR-AUCã‚„F1-Scoreã‚’è¦‹ã¦ã„ã‚‹ã‹ï¼Ÿ\n",
    "\n",
    "# 3. å±¤åŒ–æŠ½å‡º\n",
    "# - train_test_split ã§ stratify ã‚’ä½¿ã£ãŸã‹ï¼Ÿ\n",
    "# - ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ StratifiedKFold ã‚’ä½¿ã£ãŸã‹ï¼Ÿ\n",
    "\n",
    "# 4. å¯¾ç­–æ‰‹æ³•ã®é¸æŠ\n",
    "# - è¤‡æ•°ã®æ‰‹æ³•ã‚’è©¦ã—ãŸã‹ï¼Ÿ\n",
    "# - ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ç”¨ã—ã¦ã„ãªã„ã‹ï¼Ÿ\n",
    "# - ã‚¯ãƒ©ã‚¹é‡ã¿ã‚„Focal Lossã‚’æ¤œè¨ã—ãŸã‹ï¼Ÿ\n",
    "\n",
    "# 5. é–¾å€¤ã®èª¿æ•´\n",
    "# - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤(0.5)ãŒæœ€é©ã‹ç¢ºèªã—ãŸã‹ï¼Ÿ\n",
    "# - ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«åˆã‚ã›ã¦èª¿æ•´ã—ãŸã‹ï¼Ÿ\n",
    "\n",
    "# 6. æ¤œè¨¼\n",
    "# - æ··åŒè¡Œåˆ—ã‚’è©³ã—ãè¦‹ãŸã‹ï¼Ÿ\n",
    "# - False Negativeã¨False Positiveã®ãƒãƒ©ãƒ³ã‚¹ã¯é©åˆ‡ã‹ï¼Ÿ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ã¾ã¨ã‚\n",
    "\n",
    "### æœ¬ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã‚“ã ã“ã¨\n",
    "\n",
    "1. **ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œ**\n",
    "   - ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¨ã¯ä½•ã‹\n",
    "   - ãªãœAccuracyãŒä¸é©åˆ‡ã‹\n",
    "   - å®Ÿä¸–ç•Œã§ã®é‡è¦æ€§\n",
    "\n",
    "2. **é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™**\n",
    "   - Precisionã€Recallã€F1-Score\n",
    "   - ROC-AUCã¨PR-AUC\n",
    "   - ãƒ“ã‚¸ãƒã‚¹ç›®æ¨™ã«å¿œã˜ãŸæŒ‡æ¨™é¸æŠ\n",
    "\n",
    "3. **ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•**\n",
    "   - SMOTEã€ADASYNã€BorderlineSMOTE\n",
    "   - ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "   - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ï¼ˆSMOTEENNã€SMOTETomekï¼‰\n",
    "\n",
    "4. **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ¬ãƒ™ãƒ«ã®å¯¾ç­–**\n",
    "   - ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘\n",
    "   - é–¾å€¤èª¿æ•´\n",
    "   - ã‚³ã‚¹ãƒˆè€ƒæ…®å­¦ç¿’\n",
    "\n",
    "5. **é«˜åº¦ãªæ‰‹æ³•**\n",
    "   - EasyEnsembleã€Balanced Random Forest\n",
    "   - GBDTã®ä¸å‡è¡¡å¯¾ç­–ï¼ˆscale_pos_weightï¼‰\n",
    "   - Focal Loss\n",
    "\n",
    "6. **å®Ÿå‹™ã§ã®é©ç”¨**\n",
    "   - ã‚·ãƒŠãƒªã‚ªåˆ¥ã®æ‰‹æ³•é¸æŠ\n",
    "   - ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹\n",
    "   - ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ\n",
    "\n",
    "- âœ… **Accuracyã«é¨™ã•ã‚Œã‚‹ãª**: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯å¿…ãšPrecisionã€Recallã€F1ã‚‚ç¢ºèª\n",
    "- âœ… **ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã„**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã«é©ç”¨\n",
    "- âœ… **å±¤åŒ–æŠ½å‡ºã‚’ä½¿ã†**: stratifyãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å¿…é ˆ\n",
    "- âœ… **è¤‡æ•°ã®æ‰‹æ³•ã‚’è©¦ã™**: 1ã¤ã®æ‰‹æ³•ã«å›ºåŸ·ã—ãªã„\n",
    "- âœ… **ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã‚’è€ƒæ…®**: è¦‹é€ƒã—ã¨èª¤æ¤œçŸ¥ã®ã©ã¡ã‚‰ãŒé‡è¦ã‹\n",
    "- âœ… **é–¾å€¤ã‚’èª¿æ•´**: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®0.5ãŒæœ€é©ã¨ã¯é™ã‚‰ãªã„\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "- Notebook 24ã§æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å­¦ã¶\n",
    "- Notebook 25ã§ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®é«˜åº¦ãªå‡¦ç†ã‚’å­¦ã¶\n",
    "- å®Ÿéš›ã®Kaggleã‚³ãƒ³ãƒšã§ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«æŒ‘æˆ¦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

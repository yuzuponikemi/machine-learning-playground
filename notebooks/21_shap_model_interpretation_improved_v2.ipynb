{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21. SHAPモデル解釈 - 説明可能なAI (SHAP Model Interpretation)\n",
    "\n",
    "## 概要\n",
    "SHAPを使って機械学習モデルの予測を解釈し、説明可能にする方法を学びます。\n",
    "\n",
    "## 学習目標\n",
    "- SHAPの基本概念を理解できる\n",
    "- 特徴量の重要度を定量化できる\n",
    "- 個別予測の説明ができる\n",
    "- グローバルな解釈とローカルな解釈の違いを理解できる\n",
    "- 実務でSHAPを活用できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 設定\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)\n",
    "\n",
    "# SHAP JavaScript の初期化（ノートブック用）\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. なぜモデルの解釈が必要か\n",
    "\n",
    "### ブラックボックス問題\n",
    "\n",
    "複雑な機械学習モデル（Random Forest、Gradient Boosting、Neural Networksなど）は高い予測精度を持つ一方、**なぜその予測をしたのか**が分かりにくいという問題があります。\n",
    "\n",
    "### モデル解釈が重要な理由\n",
    "\n",
    "1. **信頼性の向上**\n",
    "   - 予測根拠を理解できる\n",
    "   - バイアスや誤りを検出できる\n",
    "\n",
    "2. **規制対応**\n",
    "   - 金融、医療などの分野で説明責任が求められる\n",
    "   - GDPR（EU一般データ保護規則）など\n",
    "\n",
    "3. **モデル改善**\n",
    "   - 重要な特徴量を特定\n",
    "   - データ収集の優先順位決定\n",
    "\n",
    "4. **ビジネス価値**\n",
    "   - 意思決定者への説明\n",
    "   - アクションプランの策定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SHAPとは\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "ゲーム理論のShapley値に基づいた、統一的なモデル解釈手法です。\n",
    "\n",
    "### SHAPの特徴\n",
    "\n",
    "1. **モデル非依存**\n",
    "   - あらゆる機械学習モデルに適用可能\n",
    "   - 統一的な解釈フレームワーク\n",
    "\n",
    "2. **理論的保証**\n",
    "   - 数学的に厳密な基盤\n",
    "   - 公平な寄与度計算\n",
    "\n",
    "3. **ローカル＆グローバル解釈**\n",
    "   - 個別予測の説明\n",
    "   - 全体的なパターンの理解\n",
    "\n",
    "### SHAP値の意味\n",
    "\n",
    "各特徴量が予測値にどれだけ貢献したかを示す値です。\n",
    "\n",
    "- **正のSHAP値**: 予測を増加させる方向に寄与\n",
    "- **負のSHAP値**: 予測を減少させる方向に寄与\n",
    "- **SHAP値の合計**: ベースライン予測からの差分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 分類問題でのSHAP\n",
    "\n",
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乳がんデータセット\n",
    "cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"データサイズ: {X.shape}\")\n",
    "print(f\"\\n特徴量の一部:\")\n",
    "print(X.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "model_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"訓練精度: {model_rf.score(X_train, y_train):.4f}\")\n",
    "print(f\"テスト精度: {model_rf.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP値の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TreeExplainer（ツリーベースモデル用の高速explainer）\n",
    "explainer = shap.TreeExplainer(model_rf)\n",
    "\n",
    "# テストデータのSHAP値を計算\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(f\"SHAP値の形状: {shap_values[1].shape}\")\n",
    "print(f\"クラス数: {len(shap_values)}\")\n",
    "print(f\"\\nベースライン値（期待値）: {explainer.expected_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. グローバル解釈: 特徴量の重要度\n",
    "\n",
    "全データに対する各特徴量の平均的な影響を見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Plot: 特徴量重要度と値の分布\n",
    "shap.summary_plot(shap_values[1], X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('Feature Importance (Mean |SHAP value|)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"このグラフの読み方:\")\n",
    "print(\"- 上位の特徴量ほど予測に大きく影響\")\n",
    "print(\"- 平均絶対SHAP値で順位付け\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm Plot: 詳細な分布\n",
    "shap.summary_plot(shap_values[1], X_test, show=False)\n",
    "plt.title('SHAP Summary Plot (Beeswarm)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBeeswarm Plotの読み方:\")\n",
    "print(\"- 各点が1つのサンプル\")\n",
    "print(\"- 色: 特徴量の値（赤=高、青=低）\")\n",
    "print(\"- X軸: SHAP値（予測への影響）\")\n",
    "print(\"- Y軸: 特徴量（重要度順）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ローカル解釈: 個別予測の説明\n",
    "\n",
    "特定のサンプルに対する予測の理由を詳しく見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1つのサンプルを選択\n",
    "sample_idx = 0\n",
    "sample = X_test.iloc[sample_idx]\n",
    "\n",
    "# 予測\n",
    "prediction = model_rf.predict([sample])[0]\n",
    "probability = model_rf.predict_proba([sample])[0]\n",
    "\n",
    "print(f\"サンプル #{sample_idx}\")\n",
    "print(f\"予測クラス: {cancer.target_names[prediction]}\")\n",
    "print(f\"予測確率: {probability}\")\n",
    "print(f\"実際のクラス: {cancer.target_names[y_test.iloc[sample_idx]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Plot: ウォーターフォール式の説明\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],\n",
    "    shap_values[1][sample_idx],\n",
    "    X_test.iloc[sample_idx],\n",
    "    matplotlib=True,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Force Plot for Sample #{sample_idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nForce Plotの読み方:\")\n",
    "print(\"- 基準値（expected value）から予測値への変化を示す\")\n",
    "print(\"- 赤: 陽性方向に押す特徴量\")\n",
    "print(\"- 青: 陰性方向に押す特徴量\")\n",
    "print(\"- 幅: 影響の大きさ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall Plot: より詳細な表示\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values[1][sample_idx],\n",
    "        base_values=explainer.expected_value[1],\n",
    "        data=X_test.iloc[sample_idx].values,\n",
    "        feature_names=X_test.columns.tolist()\n",
    "    ),\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Waterfall Plot for Sample #{sample_idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 依存関係プロット\n",
    "\n",
    "特定の特徴量がどのように予測に影響するかを詳しく見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も重要な特徴量を選択\n",
    "feature_name = 'worst perimeter'\n",
    "\n",
    "# Dependence Plot\n",
    "shap.dependence_plot(\n",
    "    feature_name,\n",
    "    shap_values[1],\n",
    "    X_test,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Dependence Plot: {feature_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDependence Plotの読み方:\")\n",
    "print(\"- X軸: 特徴量の値\")\n",
    "print(\"- Y軸: SHAP値（予測への影響）\")\n",
    "print(\"- 色: 他の重要な特徴量の値（相互作用）\")\n",
    "print(\"- 傾向: 特徴量と予測の関係性\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 回帰問題でのSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カリフォルニア住宅価格データセット\n",
    "housing = fetch_california_housing()\n",
    "X_reg = pd.DataFrame(housing.data[:1000], columns=housing.feature_names)\n",
    "y_reg = housing.target[:1000]\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# モデル学習\n",
    "model_gbr = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "model_gbr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(f\"訓練R²: {model_gbr.score(X_train_reg, y_train_reg):.4f}\")\n",
    "print(f\"テストR²: {model_gbr.score(X_test_reg, y_test_reg):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP値の計算\n",
    "explainer_reg = shap.TreeExplainer(model_gbr)\n",
    "shap_values_reg = explainer_reg.shap_values(X_test_reg)\n",
    "\n",
    "# 特徴量重要度\n",
    "shap.summary_plot(shap_values_reg, X_test_reg, plot_type=\"bar\", show=False)\n",
    "plt.title('Feature Importance for Housing Price Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詳細なSummary Plot\n",
    "shap.summary_plot(shap_values_reg, X_test_reg, show=False)\n",
    "plt.title('SHAP Summary for Housing Price')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n解釈例:\")\n",
    "print(\"- MedInc（所得）が高いほど価格が上昇（正のSHAP値）\")\n",
    "print(\"- Latitude/Longitudeの影響（地理的要因）\")\n",
    "print(\"- 特徴量間の相互作用も可視化\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 実務での活用\n",
    "\n",
    "### ユースケース別の使い分け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction(model, explainer, sample, feature_names, target_names=None):\n",
    "    \"\"\"\n",
    "    予測結果を詳しく説明する関数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : 学習済みモデル\n",
    "    explainer : SHAP explainer\n",
    "    sample : 説明したいサンプル\n",
    "    feature_names : 特徴量名のリスト\n",
    "    target_names : クラス名のリスト（分類の場合）\n",
    "    \"\"\"\n",
    "    # 予測\n",
    "    prediction = model.predict([sample])[0]\n",
    "    \n",
    "    # SHAP値\n",
    "    shap_val = explainer.shap_values([sample])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"予測結果の説明\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if target_names:\n",
    "        # 分類\n",
    "        proba = model.predict_proba([sample])[0]\n",
    "        print(f\"予測クラス: {target_names[prediction]}\")\n",
    "        print(f\"予測確率: {proba[prediction]:.4f}\")\n",
    "        \n",
    "        # 上位寄与特徴量\n",
    "        shap_abs = np.abs(shap_val[1][0])\n",
    "    else:\n",
    "        # 回帰\n",
    "        print(f\"予測値: {prediction:.4f}\")\n",
    "        shap_abs = np.abs(shap_val[0])\n",
    "    \n",
    "    # 重要な特徴量トップ5\n",
    "    top_indices = np.argsort(shap_abs)[-5:][::-1]\n",
    "    \n",
    "    print(\"\\n影響の大きい特徴量 TOP 5:\")\n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        if target_names:\n",
    "            shap_value = shap_val[1][0][idx]\n",
    "        else:\n",
    "            shap_value = shap_val[0][idx]\n",
    "        \n",
    "        direction = \"↑\" if shap_value > 0 else \"↓\"\n",
    "        print(f\"{i}. {feature_names[idx]}: {sample[idx]:.2f}\")\n",
    "        print(f\"   SHAP値: {shap_value:.4f} {direction}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# 使用例\n",
    "explain_prediction(\n",
    "    model_rf, \n",
    "    explainer, \n",
    "    X_test.iloc[0].values,\n",
    "    X_test.columns.tolist(),\n",
    "    cancer.target_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. まとめ\n",
    "\n",
    "### 本ノートブックで学んだこと\n",
    "\n",
    "1. **モデル解釈の重要性**\n",
    "   - ブラックボックス問題\n",
    "   - 信頼性、規制対応、ビジネス価値\n",
    "\n",
    "2. **SHAPの基礎**\n",
    "   - Shapley値に基づく統一的手法\n",
    "   - 理論的保証と実用性\n",
    "\n",
    "3. **グローバル解釈**\n",
    "   - 特徴量重要度\n",
    "   - Summary plot\n",
    "   - 全体的なパターン理解\n",
    "\n",
    "4. **ローカル解釈**\n",
    "   - 個別予測の説明\n",
    "   - Force plot、Waterfall plot\n",
    "   - 予測根拠の可視化\n",
    "\n",
    "5. **依存関係分析**\n",
    "   - Dependence plot\n",
    "   - 特徴量と予測の関係\n",
    "   - 相互作用の発見\n",
    "\n",
    "6. **実務での活用**\n",
    "   - 分類・回帰両方での適用\n",
    "   - カスタム説明関数\n",
    "   - レポート自動生成\n",
    "\n",
    "### SHAPを使うべきとき\n",
    "\n",
    "- ✅ モデルの信頼性を高めたい\n",
    "- ✅ ステークホルダーへの説明が必要\n",
    "- ✅ 規制対応が求められる\n",
    "- ✅ 特徴量エンジニアリングの改善\n",
    "- ✅ バイアスや誤りの検出\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "- Notebook 22でStackingアンサンブルを学ぶ\n",
    "- 実際のプロジェクトでSHAPを活用\n",
    "- より高度な解釈手法を探求（LIME、Integrated Gradientsなど）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

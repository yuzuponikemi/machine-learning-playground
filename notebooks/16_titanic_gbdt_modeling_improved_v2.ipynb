{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ç¬¬16ç« : æœ€çµ‚æ±ºæˆ¦ï¼ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ Ã— GBDTãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n",
    "\n",
    "## ğŸ“‹ ã“ã®ç« ã§å­¦ã¶ã“ã¨\n",
    "\n",
    "ã“ã®ç« ã‚’çµ‚ãˆã‚‹ã¨ã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š\n",
    "\n",
    "- [ ] LightGBMã€XGBoostã€CatBoostã§ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã§ãã‚‹\n",
    "- [ ] Stratified K-Fold Cross-Validationã§æ­£ç¢ºãªè©•ä¾¡ãŒã§ãã‚‹\n",
    "- [ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã§ãã‚‹\n",
    "- [ ] Feature Importanceã‚’åˆ†æã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ç†è§£ã§ãã‚‹\n",
    "- [ ] ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ç²¾åº¦ã‚’å‘ä¸Šã§ãã‚‹\n",
    "\n",
    "## ğŸ¯ å‰æçŸ¥è­˜\n",
    "\n",
    "ã“ã®ç« ã‚’å­¦ã¶ã«ã¯ä»¥ä¸‹ã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ï¼š\n",
    "\n",
    "- âœ… Notebook 13ï¼ˆGBDTå…¥é–€ï¼‰\n",
    "- âœ… Notebook 14ï¼ˆCatBoostï¼‰\n",
    "- âœ… Notebook 15ï¼ˆã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯EDAï¼‰\n",
    "\n",
    "â±ï¸ **æ¨å®šå­¦ç¿’æ™‚é–“**: 120åˆ†  \n",
    "ğŸ“Š **é›£æ˜“åº¦**: â˜…â˜…â˜…â˜…â˜…ï¼ˆæœ€ä¸Šç´šï¼‰  \n",
    "ğŸ“ **ã‚«ãƒ†ã‚´ãƒª**: å®Ÿè·µãƒ»ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ã“ã®ç« ã®ç›®æ¨™\n",
    "\n",
    "**Kaggle Titanic Competition**ã§é«˜ã‚¹ã‚³ã‚¢ï¼ˆAccuracy > 0.80ï¼‰ã‚’ç›®æŒ‡ã—ã¾ã™ï¼\n",
    "\n",
    "**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ï¼š\n",
    "1. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆå‰ç« ã®å¾©ç¿’ï¼‰\n",
    "2. 3ã¤ã®GBDTãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "3. Cross-Validationã§æœ¬å½“ã®å®ŸåŠ›ã‚’æ¸¬å®š\n",
    "4. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "5. Feature Importanceåˆ†æ\n",
    "6. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§æœ€çµ‚ã‚¹ã‚³ã‚¢å‘ä¸Š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GBDT libraries\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå‰ç« ã®å¾©ç¿’ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['survived'].value_counts())\n",
    "\n",
    "# Feature engineering function\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Fill missing age with group median\n",
    "    for sex in ['male', 'female']:\n",
    "        for pclass in [1, 2, 3]:\n",
    "            mask = (df['sex'] == sex) & (df['pclass'] == pclass) & (df['age'].isnull())\n",
    "            group_median = df[(df['sex'] == sex) & (df['pclass'] == pclass)]['age'].median()\n",
    "            df.loc[mask, 'age'] = group_median\n",
    "    \n",
    "    # Fill missing embarked\n",
    "    df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Family size\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    \n",
    "    # Alone\n",
    "    df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
    "    \n",
    "    # Has deck info\n",
    "    df['has_deck'] = df['deck'].notnull().astype(int)\n",
    "    \n",
    "    # Title extraction (simplified)\n",
    "    def get_title(row):\n",
    "        if row['sex'] == 'female':\n",
    "            return 'Miss' if row['age'] < 18 else 'Mrs'\n",
    "        else:\n",
    "            return 'Master' if row['age'] < 18 else 'Mr'\n",
    "    \n",
    "    df['title'] = df.apply(get_title, axis=1)\n",
    "    \n",
    "    # Fare per person\n",
    "    df['fare_per_person'] = df['fare'] / df['family_size']\n",
    "    df['fare_per_person'].fillna(df['fare_per_person'].median(), inplace=True)\n",
    "    \n",
    "    # Age categories\n",
    "    df['is_child'] = (df['age'] < 12).astype(int)\n",
    "    df['is_senior'] = (df['age'] > 60).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df_processed = engineer_features(df)\n",
    "\n",
    "print(\"\\nFeature engineering completed!\")\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "**ãƒ‡ãƒ¼ã‚¿æº–å‚™ã®è¦ç‚¹**ï¼š\n",
    "\n",
    "å‰ç« ã§å­¦ã‚“ã ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’é–¢æ•°ã«ã¾ã¨ã‚ã¾ã—ãŸï¼š\n",
    "- å¹´é½¢ã®æ¬ æè£œå®Œï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®ä¸­å¤®å€¤ï¼‰\n",
    "- å®¶æ—ã‚µã‚¤ã‚ºã®è¨ˆç®—\n",
    "- æ•¬ç§°ã®ä½œæˆ\n",
    "- 1äººã‚ãŸã‚Šã®é‹è³ƒ\n",
    "- å­ä¾›/é«˜é½¢è€…ãƒ•ãƒ©ã‚°\n",
    "\n",
    "ã“ã‚Œã‚‰ã®ç‰¹å¾´é‡ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "numeric_features = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'family_size', \n",
    "                    'is_alone', 'has_deck', 'fare_per_person', 'is_child', 'is_senior']\n",
    "categorical_features = ['sex', 'embarked', 'title']\n",
    "\n",
    "all_features = numeric_features + categorical_features\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_processed[all_features].copy()\n",
    "y = df_processed['survived'].copy()\n",
    "\n",
    "print(\"Features for modeling:\")\n",
    "print(f\"  Numeric: {numeric_features}\")\n",
    "print(f\"  Categorical: {categorical_features}\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Part 2: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features for LightGBM/XGBoost\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train[col])\n",
    "    X_test_encoded[col] = le.transform(X_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"\\nLabel encoding completed for LightGBM/XGBoost\")\n",
    "print(\"\\nEncoded training data (first 3 rows):\")\n",
    "print(X_train_encoded.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "**ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æˆ¦ç•¥**ï¼š\n",
    "\n",
    "- **LightGBM/XGBoost**: LabelEncodingãŒå¿…è¦\n",
    "- **CatBoost**: æ–‡å­—åˆ—ã®ã¾ã¾ã§OK\n",
    "\n",
    "2ã¤ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—ã¾ã™ï¼š\n",
    "1. `X_train_encoded` / `X_test_encoded`: LightGBM/XGBoostç”¨\n",
    "2. `X_train` / `X_test`: CatBoostç”¨ï¼ˆå…ƒã®ã¾ã¾ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Part 3: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_seed=42, verbose=False)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    if name == 'CatBoost':\n",
    "        # CatBoost: use original data\n",
    "        model.fit(X_train, y_train, cat_features=categorical_features, verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "    else:\n",
    "        # LightGBM/XGBoost: use encoded data\n",
    "        model.fit(X_train_encoded, y_train)\n",
    "        y_pred = model.predict(X_test_encoded)\n",
    "        y_pred_train = model.predict(X_train_encoded)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Overfit': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    print(f\"  Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Baseline Model Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "x = np.arange(len(df_results))\n",
    "width = 0.35\n",
    "axes[0].bar(x - width/2, df_results['Train Accuracy'], width, label='Train', alpha=0.8)\n",
    "axes[0].bar(x + width/2, df_results['Test Accuracy'], width, label='Test', alpha=0.8)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Baseline Model Performance', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(df_results['Model'])\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim([0.7, 1.0])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting\n",
    "axes[1].bar(df_results['Model'], df_results['Overfit'], color='orange', alpha=0.7)\n",
    "axes[1].set_ylabel('Overfit (Train - Test)')\n",
    "axes[1].set_title('Overfitting Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "**ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœã®è§£é‡ˆ**ï¼š\n",
    "\n",
    "- **ãƒ†ã‚¹ãƒˆç²¾åº¦**: 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚80%å‰å¾Œï¼ˆè‰¯å¥½ï¼ï¼‰\n",
    "- **éå­¦ç¿’**: Trainç²¾åº¦ - Testç²¾åº¦ãŒå°ã•ã„ã»ã©è‰¯ã„\n",
    "- **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**: å…¨å“¡ã€Œæ­»äº¡ã€ã¨äºˆæ¸¬ã™ã‚‹ã¨62%ãªã®ã§ã€å¤§ããä¸Šå›ã£ã¦ã„ã‚‹\n",
    "\n",
    "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: Cross-Validationã§ã‚ˆã‚Šæ­£ç¢ºãªè©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Part 4: Cross-Validationï¼ˆæ­£ç¢ºãªè©•ä¾¡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nCross-validating {name}...\")\n",
    "    \n",
    "    if name == 'CatBoost':\n",
    "        # CatBoost: use original data\n",
    "        # Note: CatBoost doesn't support cat_features in cross_val_score directly\n",
    "        # We'll train manually\n",
    "        fold_scores = []\n",
    "        for train_idx, val_idx in cv.split(X, y):\n",
    "            X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model_fold = CatBoostClassifier(iterations=100, random_seed=42, verbose=False)\n",
    "            model_fold.fit(X_fold_train, y_fold_train, cat_features=categorical_features, verbose=False)\n",
    "            score = model_fold.score(X_fold_val, y_fold_val)\n",
    "            fold_scores.append(score)\n",
    "        \n",
    "        scores = np.array(fold_scores)\n",
    "    else:\n",
    "        # LightGBM/XGBoost: use encoded data\n",
    "        X_encoded = X.copy()\n",
    "        for col in categorical_features:\n",
    "            le = LabelEncoder()\n",
    "            X_encoded[col] = le.fit_transform(X[col])\n",
    "        \n",
    "        scores = cross_val_score(model, X_encoded, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean CV Score': scores.mean(),\n",
    "        'Std CV Score': scores.std(),\n",
    "        'Min Score': scores.min(),\n",
    "        'Max Score': scores.max()\n",
    "    })\n",
    "    \n",
    "    print(f\"  CV Scores: {scores}\")\n",
    "    print(f\"  Mean: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "df_cv = pd.DataFrame(cv_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Cross-Validation Results (5-Fold)\")\n",
    "print(\"=\"*70)\n",
    "print(df_cv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "**Cross-Validationã®é‡è¦æ€§**ï¼š\n",
    "\n",
    "å˜ä¸€ã®ãƒ†ã‚¹ãƒˆåˆ†å‰²ã§ã¯ã€é‹ãŒè‰¯ã„/æ‚ªã„ã ã‘ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n",
    "**Stratified K-Fold CV**ã§5å›è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã€\n",
    "**æœ¬å½“ã®å®ŸåŠ›**ã‚’æ¸¬å®šã§ãã¾ã™ã€‚\n",
    "\n",
    "**çµæœã®è¦‹æ–¹**ï¼š\n",
    "- **Mean CV Score**: å¹³å‡ç²¾åº¦ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰\n",
    "- **Std CV Score**: æ¨™æº–åå·®ï¼ˆå°ã•ã„ã»ã©å®‰å®šï¼‰\n",
    "- **Min/Max Score**: æœ€æ‚ª/æœ€è‰¯ã®ã‚±ãƒ¼ã‚¹\n",
    "\n",
    "**ç›®æ¨™**: Mean CV Score > 0.80 ã‚’ç›®æŒ‡ã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Part 5: Feature Importanceåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Train final models for feature importance\n",
    "lgbm_final = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "lgbm_final.fit(X_train_encoded, y_train)\n",
    "\n",
    "xgb_final = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "xgb_final.fit(X_train_encoded, y_train)\n",
    "\n",
    "catboost_final = CatBoostClassifier(iterations=100, random_seed=42, verbose=False)\n",
    "catboost_final.fit(X_train, y_train, cat_features=categorical_features, verbose=False)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance_lgbm = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': lgbm_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': xgb_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance_catboost = pd.DataFrame({\n",
    "    'feature': all_features,\n",
    "    'importance': catboost_final.get_feature_importance()\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(\"\\nLightGBM:\")\n",
    "print(feature_importance_lgbm.head(10).to_string(index=False))\n",
    "print(\"\\nXGBoost:\")\n",
    "print(feature_importance_xgb.head(10).to_string(index=False))\n",
    "print(\"\\nCatBoost:\")\n",
    "print(feature_importance_catboost.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# LightGBM\n",
    "top_n = 10\n",
    "axes[0].barh(range(top_n), feature_importance_lgbm['importance'].head(top_n))\n",
    "axes[0].set_yticks(range(top_n))\n",
    "axes[0].set_yticklabels(feature_importance_lgbm['feature'].head(top_n))\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('LightGBM Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].barh(range(top_n), feature_importance_xgb['importance'].head(top_n))\n",
    "axes[1].set_yticks(range(top_n))\n",
    "axes[1].set_yticklabels(feature_importance_xgb['feature'].head(top_n))\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('XGBoost Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# CatBoost\n",
    "axes[2].barh(range(top_n), feature_importance_catboost['importance'].head(top_n))\n",
    "axes[2].set_yticks(range(top_n))\n",
    "axes[2].set_yticklabels(feature_importance_catboost['feature'].head(top_n))\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].set_xlabel('Importance')\n",
    "axes[2].set_title('CatBoost Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "**Feature Importanceã‹ã‚‰åˆ†ã‹ã‚‹ã“ã¨**ï¼š\n",
    "\n",
    "**å…±é€šã—ã¦é‡è¦ãªç‰¹å¾´é‡**ï¼š\n",
    "1. **titleï¼ˆæ•¬ç§°ï¼‰**: æœ€é‡è¦ï¼æ€§åˆ¥ãƒ»å¹´é½¢ãƒ»ç¤¾ä¼šçš„åœ°ä½ã‚’çµ±åˆ\n",
    "2. **sexï¼ˆæ€§åˆ¥ï¼‰**: ã€Œå¥³æ€§ã¨å­ä¾›å„ªå…ˆã€ã‚’åæ˜ \n",
    "3. **fare / fare_per_personï¼ˆé‹è³ƒï¼‰**: çµŒæ¸ˆçŠ¶æ³ã®æŒ‡æ¨™\n",
    "4. **ageï¼ˆå¹´é½¢ï¼‰**: å­ä¾›ã‚„é«˜é½¢è€…ã§ç”Ÿå­˜ç‡ãŒç•°ãªã‚‹\n",
    "5. **pclassï¼ˆãƒã‚±ãƒƒãƒˆã‚¯ãƒ©ã‚¹ï¼‰**: ä¸Šç´šå®¢å®¤ã»ã©ç”Ÿå­˜ç‡ãŒé«˜ã„\n",
    "\n",
    "**ãƒ¢ãƒ‡ãƒ«é–“ã®é•ã„**ï¼š\n",
    "- LightGBM: fareã‚’é‡è¦–\n",
    "- XGBoost: titleã‚’æœ€é‡è¦–\n",
    "- CatBoost: ãƒãƒ©ãƒ³ã‚¹ã‚ˆãå…¨ç‰¹å¾´é‡ã‚’æ´»ç”¨\n",
    "\n",
    "**æ´å¯Ÿ**ï¼š\n",
    "- å‰ç« ã§ä½œæˆã—ãŸ`title`ã¨`fare_per_person`ãŒéå¸¸ã«åŠ¹æœçš„\n",
    "- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ä¾¡å€¤ãŒè¨¼æ˜ã•ã‚ŒãŸï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Part 6: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# LightGBM tuning\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [15, 31, 63]\n",
    "}\n",
    "\n",
    "print(\"Tuning LightGBM...\")\n",
    "lgbm_grid = GridSearchCV(\n",
    "    LGBMClassifier(random_state=42, verbose=-1),\n",
    "    param_grid_lgbm,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "lgbm_grid.fit(X_train_encoded, y_train)\n",
    "\n",
    "print(f\"\\nBest LightGBM Parameters:\")\n",
    "for param, value in lgbm_grid.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest CV Score: {lgbm_grid.best_score_:.4f}\")\n",
    "print(f\"Test Score: {lgbm_grid.score(X_test_encoded, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "**ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é‡è¦æ€§**ï¼š\n",
    "\n",
    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚‚è‰¯ã„çµæœãŒå‡ºã¾ã™ãŒã€\n",
    "ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã•ã‚‰ã«**1-2%ã®ç²¾åº¦å‘ä¸Š**ãŒæœŸå¾…ã§ãã¾ã™ã€‚\n",
    "\n",
    "**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ï¼š\n",
    "- `n_estimators`: æœ¨ã®æ•°ï¼ˆå¤šã„ã»ã©ç²¾åº¦å‘ä¸Šã€æ™‚é–“ã‚‚ã‹ã‹ã‚‹ï¼‰\n",
    "- `max_depth`: æœ¨ã®æ·±ã•ï¼ˆæ·±ã™ãã‚‹ã¨éå­¦ç¿’ï¼‰\n",
    "- `learning_rate`: å­¦ç¿’ç‡ï¼ˆå°ã•ã„ã»ã©æ…é‡ã€`n_estimators`ã‚’å¢—ã‚„ã™å¿…è¦ï¼‰\n",
    "- `num_leaves`: è‘‰ã®æ•°ï¼ˆLightGBMç‰¹æœ‰ã€å¤šã„ã»ã©è¤‡é›‘ï¼‰\n",
    "\n",
    "**æ³¨æ„**: GridSearchã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚å®Ÿå‹™ã§ã¯ç¯„å›²ã‚’çµã‚‹ã‹ã€RandomizedSearchCVã‚’ä½¿ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Part 7: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆæœ€çµ‚å…µå™¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Get predictions from all models\n",
  "lgbm_pred_proba = lgbm_final.predict_proba(X_test_encoded)[:, 1]\n",
    "    xgb_pred_proba = xgb_final.predict_proba(X_test_encoded)[:, 1]\n",
    "    catboost_pred_proba = catboost_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Simple averaging ensemble\n",
    "ensemble_pred_proba = (lgbm_pred_proba + xgb_pred_proba + catboost_pred_proba) / 3\n",
    "ensemble_pred = (ensemble_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Weighted averaging (based on CV performance)\n",
    "weights = [0.33, 0.34, 0.33]  # Adjust based on CV scores\n",
    "ensemble_weighted_proba = (\n",
    "    weights[0] * lgbm_pred_proba +\n",
    "    weights[1] * xgb_pred_proba +\n",
    "    weights[2] * catboost_pred_proba\n",
    ")\n",
    "ensemble_weighted_pred = (ensemble_weighted_proba >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Ensemble Results\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nLightGBM Test Accuracy: {lgbm_final.score(X_test_encoded, y_test):.4f}\")\n",
    "print(f\"XGBoost Test Accuracy: {xgb_final.score(X_test_encoded, y_test):.4f}\")\n",
    "print(f\"CatBoost Test Accuracy: {catboost_final.score(X_test, y_test):.4f}\")\n",
    "print(f\"\\nSimple Ensemble Accuracy: {accuracy_score(y_test, ensemble_pred):.4f}\")\n",
    "print(f\"Weighted Ensemble Accuracy: {accuracy_score(y_test, ensemble_weighted_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "**ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®å¨åŠ›**ï¼š\n",
    "\n",
    "**ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’**ã¨ã¯ã€è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’çµ„ã¿åˆã‚ã›ã‚‹æ‰‹æ³•ã§ã™ã€‚\n",
    "\n",
    "**ãªãœåŠ¹æœçš„ï¼Ÿ**\n",
    "- å„ãƒ¢ãƒ‡ãƒ«ã¯ç•°ãªã‚‹ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã™\n",
    "- å¹³å‡ã™ã‚‹ã“ã¨ã§ã€å€‹ã€…ã®ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«\n",
    "- **ã€Œä¸‰äººå¯„ã‚Œã°æ–‡æ®Šã®çŸ¥æµã€**\n",
    "\n",
    "**æ–¹æ³•**ï¼š\n",
    "1. **Simple Averaging**: å…¨ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡ã‚’å¹³å‡\n",
    "2. **Weighted Averaging**: CVæ€§èƒ½ã«åŸºã¥ã„ã¦é‡ã¿ä»˜ã‘\n",
    "3. **Voting**: å¤šæ•°æ±ºï¼ˆä»Šå›ã¯ä½¿ç”¨ã›ãšï¼‰\n",
    "\n",
    "**çµæœ**ï¼š\n",
    "- å¤šãã®å ´åˆã€å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Š1-2%ç²¾åº¦ãŒå‘ä¸Š\n",
    "- Kaggleã§ã¯å¿…é ˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Part 8: è©³ç´°ãªè©•ä¾¡ã¨å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Classification report for ensemble\n",
    "print(\"\\nEnsemble Classification Report:\")\n",
    "print(classification_report(y_test, ensemble_pred, target_names=['Died', 'Survived']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, ensemble_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Died', 'Survived'], yticklabels=['Died', 'Survived'])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (Ensemble)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ROC curve\n",
    "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_test, lgbm_pred_proba)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_pred_proba)\n",
    "fpr_cat, tpr_cat, _ = roc_curve(y_test, catboost_pred_proba)\n",
    "fpr_ens, tpr_ens, _ = roc_curve(y_test, ensemble_pred_proba)\n",
    "\n",
    "axes[1].plot(fpr_lgbm, tpr_lgbm, label=f'LightGBM (AUC={roc_auc_score(y_test, lgbm_pred_proba):.3f})')\n",
    "axes[1].plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={roc_auc_score(y_test, xgb_pred_proba):.3f})')\n",
    "axes[1].plot(fpr_cat, tpr_cat, label=f'CatBoost (AUC={roc_auc_score(y_test, catboost_pred_proba):.3f})')\n",
    "axes[1].plot(fpr_ens, tpr_ens, 'k-', linewidth=2, label=f'Ensemble (AUC={roc_auc_score(y_test, ensemble_pred_proba):.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "**è©•ä¾¡æŒ‡æ¨™ã®è§£é‡ˆ**ï¼š\n",
    "\n",
    "**Confusion Matrixï¼ˆæ··åŒè¡Œåˆ—ï¼‰**ï¼š\n",
    "- True Positive (TP): æ­£ã—ãã€Œç”Ÿå­˜ã€ã¨äºˆæ¸¬\n",
    "- True Negative (TN): æ­£ã—ãã€Œæ­»äº¡ã€ã¨äºˆæ¸¬\n",
    "- False Positive (FP): ã€Œç”Ÿå­˜ã€ã¨èª¤äºˆæ¸¬ï¼ˆå®Ÿéš›ã¯æ­»äº¡ï¼‰\n",
    "- False Negative (FN): ã€Œæ­»äº¡ã€ã¨èª¤äºˆæ¸¬ï¼ˆå®Ÿéš›ã¯ç”Ÿå­˜ï¼‰\n",
    "\n",
    "**ROC-AUC**:\n",
    "- 1.0ã«è¿‘ã„ã»ã©å„ªç§€\n",
    "- 0.5ã¯ã€Œãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ã€ã¨åŒã˜\n",
    "- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãŒæœ€é«˜ã®AUCã‚’é”æˆ\n",
    "\n",
    "**Classification Report**:\n",
    "- Precision: äºˆæ¸¬ãŒå½“ãŸã‚‹ç¢ºç‡\n",
    "- Recall: å®Ÿéš›ã®æ­£ä¾‹ã‚’ã©ã‚Œã ã‘è¦‹é€ƒã•ãªã„ã‹\n",
    "- F1-Score: Precisionã¨Recallã®èª¿å’Œå¹³å‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Part 9: Kaggleæå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Note: For actual Kaggle submission, you'd need the test.csv file\n",
    "# This is a demonstration of how to create submission file\n",
    "\n",
    "# Example code for Kaggle submission:\n",
    "# test_df = pd.read_csv('test.csv')\n",
    "# test_processed = engineer_features(test_df)\n",
    "# X_submission = test_processed[all_features]\n",
    "# \n",
    "# # Encode for LightGBM/XGBoost\n",
    "# X_submission_encoded = X_submission.copy()\n",
    "# for col in categorical_features:\n",
    "#     X_submission_encoded[col] = label_encoders[col].transform(X_submission[col])\n",
    "# \n",
    "# # Get ensemble predictions\n",
    "# lgbm_pred = lgbm_final.predict_proba(X_submission_encoded)[:, 1]\n",
    "# xgb_pred = xgb_final.predict_proba(X_submission_encoded)[:, 1]\n",
    "# catboost_pred = catboost_final.predict_proba(X_submission)[:, 1]\n",
    "# \n",
    "# ensemble_pred = (lgbm_pred + xgb_pred + catboost_pred) / 3\n",
    "# final_pred = (ensemble_pred >= 0.5).astype(int)\n",
    "# \n",
    "# # Create submission file\n",
    "# submission = pd.DataFrame({\n",
    "#     'PassengerId': test_df['PassengerId'],\n",
    "#     'Survived': final_pred\n",
    "# })\n",
    "# submission.to_csv('titanic_submission.csv', index=False)\n",
    "# print(\"Submission file created: titanic_submission.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Kaggle Submissionæº–å‚™å®Œäº†ï¼\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ã€å®Ÿéš›ã®test.csvã§äºˆæ¸¬ã‚’è¡Œã„ã€\")\n",
    "print(\"submission.csvã‚’ä½œæˆã—ã¦Kaggleã«æå‡ºã§ãã¾ã™ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "**Kaggleæå‡ºã®æµã‚Œ**ï¼š\n",
    "\n",
    "1. **ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: Kaggleã‹ã‚‰`test.csv`ã‚’å–å¾—\n",
    "2. **åŒã˜å‰å‡¦ç†ã‚’é©ç”¨**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "3. **äºˆæ¸¬**: 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã—ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "4. **submission.csvä½œæˆ**: `PassengerId`ã¨`Survived`ã®2åˆ—\n",
    "5. **æå‡º**: Kaggleã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¹ã‚³ã‚¢ã‚’ç¢ºèª\n",
    "\n",
    "**æœŸå¾…ã‚¹ã‚³ã‚¢**: 0.78ã€œ0.82ï¼ˆä¸Šä½30%ç¨‹åº¦ï¼‰\n",
    "\n",
    "**ã•ã‚‰ã«æ”¹å–„ã™ã‚‹ã«ã¯**:\n",
    "- ã‚ˆã‚Šé«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "- ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼ˆãƒ¡ã‚¿å­¦ç¿’ï¼‰\n",
    "- ã‚ˆã‚Šå¤šãã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the Titanic GBDT modeling challenge!\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "**ãƒ‡ãƒ¼ã‚¿æº–å‚™**\n",
    "- å‰ç« ã§å­¦ã‚“ã ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè·µ\n",
    "- ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "- è¨“ç·´/ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
    "\n",
    "**ãƒ¢ãƒ‡ãƒªãƒ³ã‚°**\n",
    "- LightGBMã€XGBoostã€CatBoostã®æ§‹ç¯‰\n",
    "- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\n",
    "- Stratified K-Fold Cross-Validation\n",
    "\n",
    "**æœ€é©åŒ–**\n",
    "- Feature Importanceåˆ†æ\n",
    "- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGridSearchCVï¼‰\n",
    "- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆå¹³å‡ã€é‡ã¿ä»˜ã‘å¹³å‡ï¼‰\n",
    "\n",
    "**è©•ä¾¡**\n",
    "- æ··åŒè¡Œåˆ—ï¼ˆConfusion Matrixï¼‰\n",
    "- ROC-AUCæ›²ç·š\n",
    "- Classification Report\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "âœ… **80%ä»¥ä¸Šã®ç²¾åº¦ã‚’é”æˆ**ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³62%ã‚’å¤§ããä¸Šå›ã‚‹ï¼‰\n",
    "âœ… **3ã¤ã®GBDTãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã„ã“ãªã›ã‚‹ã‚ˆã†ã«ãªã£ãŸ**\n",
    "âœ… **å®Ÿè·µçš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—**\n",
    "âœ… **Kaggleæå‡ºã®æº–å‚™ãŒæ•´ã£ãŸ**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**å®Ÿè·µ**:\n",
    "1. Kaggleã«å®Ÿéš›ã«æå‡ºã—ã¦ã¿ã‚‹\n",
    "2. ä»–ã®Kaggleã‚³ãƒ³ãƒšã«æŒ‘æˆ¦ï¼ˆHouse Prices, Store Salesãªã©ï¼‰\n",
    "3. è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§GBDTã‚’è©¦ã™\n",
    "\n",
    "**ã•ã‚‰ã«å­¦ã¶**:\n",
    "- ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼ˆãƒ¡ã‚¿å­¦ç¿’ï¼‰\n",
    "- Optunaã«ã‚ˆã‚‹é«˜åº¦ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\n",
    "- SHAPå€¤ã«ã‚ˆã‚‹è©³ç´°ãªãƒ¢ãƒ‡ãƒ«è§£é‡ˆ\n",
    "\n",
    "### ğŸ‰ å®Œèµ°ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼\n",
    "\n",
    "ã“ã‚Œã§ã€æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ã‹ã‚‰å®Ÿè·µçš„ãªGBDTæ´»ç”¨ã¾ã§ã€\n",
    "ä¸€é€£ã®æµã‚Œã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ã¾ã—ãŸã€‚\n",
    "\n",
    "**ã‚ãªãŸã¯ä»Šã€Kaggleã‚„å®Ÿå‹™ã§GBDTã‚’ä½¿ã£ã¦ã€Œå‹ã¤ã€ãŸã‚ã®æ­¦å™¨ã‚’æ‰‹ã«å…¥ã‚Œã¾ã—ãŸï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "### âš ï¸ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ #1: LabelEncoderã§æœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒª\n",
    "\n",
    "ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§è¦‹ãŸã“ã¨ã®ãªã„ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "**åŸå› :**\n",
    "1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒãŒç•°ãªã‚‹\n",
    "2. ãƒ¬ã‚¢ãªã‚«ãƒ†ã‚´ãƒªãŒå­˜åœ¨ã™ã‚‹\n",
    "\n",
    "**âœ… è§£æ±ºæ³•:**\n",
    "\n",
    "```python\n",
    "# âŒ å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰\n",
    "le = LabelEncoder()\n",
    "X_train['category'] = le.fit_transform(X_train['category'])\n",
    "X_test['category'] = le.transform(X_test['category'])  # æœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒªã§ã‚¨ãƒ©ãƒ¼\n",
    "\n",
    "# âœ… å®‰å…¨ãªã‚³ãƒ¼ãƒ‰\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class SafeLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.le.fit(data)\n",
    "        self.classes_ = set(self.le.classes_)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        # æœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒªã‚’æœ€é »å€¤ã«ç½®ãæ›ãˆ\n",
    "        data = data.copy()\n",
    "        mask = ~data.isin(self.classes_)\n",
    "        if mask.any():\n",
    "            most_common = self.le.classes_[0]\n",
    "            data[mask] = most_common\n",
    "        return self.le.transform(data)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "### âš ï¸ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ #2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§æ¬¡å…ƒãŒåˆã‚ãªã„\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ä½¿ã†ã¨ã€äºˆæ¸¬çµæœã®çµåˆæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¾ã™ã€‚\n",
    "\n",
    "**åŸå› :**\n",
    "1. CatBoostã¯å…ƒãƒ‡ãƒ¼ã‚¿ã€LightGBM/XGBoostã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨\n",
    "2. äºˆæ¸¬ç¢ºç‡ã®æ¬¡å…ƒãŒç•°ãªã‚‹\n",
    "\n",
    "**âœ… è§£æ±ºæ³•:**\n",
    "\n",
    "```python\n",
    "# âœ… æ­£ã—ã„ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "# LightGBM/XGBoost: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "lgbm_pred_proba = lgbm_model.predict_proba(X_test_encoded)[:, 1]\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# CatBoost: å…ƒãƒ‡ãƒ¼ã‚¿\n",
    "catboost_pred_proba = catboost_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ã™ã¹ã¦1æ¬¡å…ƒé…åˆ—ã§ã€é•·ã•ãŒåŒã˜ã“ã¨ã‚’ç¢ºèª\n",
    "assert lgbm_pred_proba.shape == xgb_pred_proba.shape == catboost_pred_proba.shape\n",
    "\n",
    "# å¹³å‡\n",
    "ensemble_pred_proba = (lgbm_pred_proba + xgb_pred_proba + catboost_pred_proba) / 3\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ è‡ªå·±è©•ä¾¡ã‚¯ã‚¤ã‚º\n",
    "\n",
    "å­¦ç¿’å†…å®¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ï¼ã™ãã«ç­”ãˆã‚’è¦‹ãšã«ã€ã¾ãšè‡ªåˆ†ã§è€ƒãˆã¦ã¿ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "### Q1: ãªãœStratified K-Fold Cross-Validationã‚’ä½¿ã†ã®ã§ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ä¿ã¡ãªãŒã‚‰ã€è¤‡æ•°å›è©•ä¾¡ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®çœŸã®æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹ãŸã‚\n",
    "\n",
    "ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã¯ä¸å‡è¡¡ï¼ˆç”Ÿå­˜38% vs æ­»äº¡62%ï¼‰ã§ã™ã€‚é€šå¸¸ã®K-Foldã§ã¯ã€ãŸã¾ãŸã¾ã‚ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã«ç”Ÿå­˜è€…ãŒåã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚Stratified K-Foldã¯ã€å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã§å…ƒãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ä¿ã¤ãŸã‚ã€ã‚ˆã‚Šæ­£ç¢ºã§å®‰å®šã—ãŸè©•ä¾¡ãŒã§ãã¾ã™ã€‚ã¾ãŸã€5å›è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã€å˜ä¸€ã®åˆ†å‰²ã§ã¯åˆ†ã‹ã‚‰ãªã„ã€Œæœ¬å½“ã®å®ŸåŠ›ã€ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã¯ãªãœå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šç²¾åº¦ãŒé«˜ã„ã®ã§ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: å„ãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã‚‹ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã™ãŸã‚ã€å¹³å‡ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã§ãã‚‹ã‹ã‚‰\n",
    "\n",
    "LightGBMã€XGBoostã€CatBoostã¯ãã‚Œãã‚Œç•°ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨å®Ÿè£…ã‚’æŒã¡ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã§èª¤äºˆæ¸¬ã—ã¾ã™ã€‚ä¾‹ãˆã°ã€ã‚µãƒ³ãƒ—ãƒ«Aã§LightGBMã¯æ­£è§£ã ãŒXGBoostã¯é–“é•ã„ã€ã‚µãƒ³ãƒ—ãƒ«Bã§ã¯ãã®é€†ã€ã¨ã„ã†ã“ã¨ãŒèµ·ãã¾ã™ã€‚3ã¤ã®äºˆæ¸¬ç¢ºç‡ã‚’å¹³å‡ã™ã‚‹ã¨ã€ã“ã†ã—ãŸå€‹ã€…ã®ã‚¨ãƒ©ãƒ¼ãŒç›¸æ®ºã•ã‚Œã€ç·åˆçš„ãªç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ã€‚ã“ã‚ŒãŒã€Œä¸‰äººå¯„ã‚Œã°æ–‡æ®Šã®çŸ¥æµã€ã®åŸç†ã§ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q3: Feature Importanceã‚’è¦‹ã‚‹æ„ç¾©ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆã€ãƒ‡ãƒãƒƒã‚°ã€ã•ã‚‰ãªã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æŒ‡é‡ã«ãªã‚‹ã‹ã‚‰\n",
    "\n",
    "Feature Importanceã‹ã‚‰ï¼š\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆ**: ã©ã®ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«åŠ¹ã„ã¦ã„ã‚‹ã‹ç†è§£ã§ãã‚‹ï¼ˆä¾‹: titleãŒæœ€é‡è¦ï¼‰\n",
    "2. **ãƒ‡ãƒãƒƒã‚°**: æœŸå¾…ã¨ç•°ãªã‚‹ç‰¹å¾´é‡ãŒé‡è¦ã ã¨ã€ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œã‚„ãƒã‚°ã®å¯èƒ½æ€§\n",
    "3. **ç‰¹å¾´é‡é¸æŠ**: é‡è¦åº¦ã®ä½ã„ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¦ã‚·ãƒ³ãƒ—ãƒ«åŒ–\n",
    "4. **æ–°ç‰¹å¾´é‡ã®ç™ºè¦‹**: é‡è¦ãªç‰¹å¾´é‡ã‹ã‚‰æ´¾ç”Ÿç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹ãƒ’ãƒ³ãƒˆ\n",
    "5. **ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤**: å®Ÿå‹™ã§ã¯æ„æ€æ±ºå®šè€…ã¸ã®èª¬æ˜ã«å¿…é ˆ\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â¡ï¸ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "### ğŸ¯ å®Ÿè·µã«æŒ‘æˆ¦\n",
    "\n",
    "**Kaggle Competitions:**\n",
    "1. **Titanic**: å®Ÿéš›ã«æå‡ºã—ã¦ã¿ã‚‹ï¼ˆç›®æ¨™: Top 30%ï¼‰\n",
    "2. **House Prices**: å›å¸°å•é¡Œã§GBDTã‚’è©¦ã™\n",
    "3. **Store Item Demand Forecasting**: æ™‚ç³»åˆ—Ã—GBDT\n",
    "\n",
    "**è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:**\n",
    "- èˆˆå‘³ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¢ã™ï¼ˆUCI ML Repositoryã€Kaggle Datasetsãªã©ï¼‰\n",
    "- EDA â†’ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â†’ GBDTãƒ¢ãƒ‡ãƒªãƒ³ã‚° ã®æµã‚Œã‚’å®Ÿè·µ\n",
    "\n",
    "### ğŸ“š ã•ã‚‰ã«å­¦ã¶ãŸã‚ã«\n",
    "\n",
    "**æ›¸ç±:**\n",
    "- ã€ŒKaggleã§å‹ã¤ãƒ‡ãƒ¼ã‚¿åˆ†æã®æŠ€è¡“ã€é–€è„‡å¤§è¼”ã»ã‹\n",
    "- \"Hands-On Gradient Boosting with XGBoost and scikit-learn\"\n",
    "\n",
    "**é«˜åº¦ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯:**\n",
    "- **Optuna**: è‡ªå‹•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\n",
    "- **SHAP**: ãƒ¢ãƒ‡ãƒ«è§£é‡ˆã®æ±ºå®šç‰ˆ\n",
    "- **Stacking**: ãƒ¡ã‚¿å­¦ç¿’ã«ã‚ˆã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "\n",
    "**ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£:**\n",
    "- Kaggle Discussions: ä»–ã®äººã®è§£æ³•ã‚’å­¦ã¶\n",
    "- GitHub: ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Kaggleè§£æ³•ã‚’ç ”ç©¶\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‰ å…¨13-16ç« å®Œèµ°ã€æœ¬å½“ã«ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼\n",
    "\n",
    "**ã‚ãªãŸã¯ä»Šã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼š**\n",
    "- âœ… LightGBMã€XGBoostã€CatBoostã‚’è‡ªåœ¨ã«ä½¿ãˆã‚‹\n",
    "- âœ… å®Ÿè·µçš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒã§ãã‚‹\n",
    "- âœ… Cross-Validationã§æ­£ç¢ºãªè©•ä¾¡ãŒã§ãã‚‹\n",
    "- âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ç²¾åº¦ã‚’æœ€å¤§åŒ–ã§ãã‚‹\n",
    "- âœ… Kaggleã§æˆ¦ãˆã‚‹æ­¦å™¨ã‚’æ‰‹ã«å…¥ã‚ŒãŸ\n",
    "\n",
    "**ã“ã‚Œã‹ã‚‰ãŒæœ¬å½“ã®ã‚¹ã‚¿ãƒ¼ãƒˆã§ã™ã€‚å­¦ã‚“ã ã‚¹ã‚­ãƒ«ã‚’å®Ÿè·µã§ç£¨ãç¶šã‘ã¦ãã ã•ã„ï¼**\n",
    "\n",
    "Happy Learning & Happy Kaggling! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

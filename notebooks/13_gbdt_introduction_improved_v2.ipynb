{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ç¬¬13ç« : GBDTå…¥é–€ - LightGBM & XGBoost\n",
    "\n",
    "## ğŸ“‹ ã“ã®ç« ã§å­¦ã¶ã“ã¨\n",
    "\n",
    "ã“ã®ç« ã‚’çµ‚ãˆã‚‹ã¨ã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š\n",
    "\n",
    "- [ ] LightGBMã¨XGBoostã®Scikit-learnãƒ©ãƒƒãƒ‘ãƒ¼ãŒä½¿ãˆã‚‹\n",
    "- [ ] Early Stoppingã§éå­¦ç¿’ã‚’é˜²ã’ã‚‹\n",
    "- [ ] å­¦ç¿’æ›²ç·šã‚’å¯è¦–åŒ–ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã‚’ç†è§£ã§ãã‚‹\n",
    "- [ ] Scikit-learnã®ãƒ¢ãƒ‡ãƒ«ã¨GBDTã‚’æ¯”è¼ƒã§ãã‚‹\n",
    "\n",
    "## ğŸ¯ å‰æçŸ¥è­˜\n",
    "\n",
    "ã“ã®ç« ã‚’å­¦ã¶ã«ã¯ä»¥ä¸‹ã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ï¼š\n",
    "\n",
    "- âœ… Notebook 05ï¼ˆæ±ºå®šæœ¨ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼‰\n",
    "- âœ… Notebook 03ï¼ˆè©•ä¾¡æŒ‡æ¨™ã¨ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰\n",
    "- âœ… Notebook 02ï¼ˆå‰å‡¦ç†ï¼‰\n",
    "\n",
    "â±ï¸ **æ¨å®šå­¦ç¿’æ™‚é–“**: 90åˆ†  \n",
    "ğŸ“Š **é›£æ˜“åº¦**: â˜…â˜…â˜…â˜…â˜†ï¼ˆä¸Šç´šï¼‰  \n",
    "ğŸ“ **ã‚«ãƒ†ã‚´ãƒª**: æ©Ÿæ¢°å­¦ç¿’ãƒ»GBDT\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ GBDTã¨ã¯ï¼Ÿ\n",
    "\n",
    "**GBDTï¼ˆGradient Boosting Decision Treeï¼‰** ã¯ã€Kaggleã‚„å®Ÿå‹™ã§æœ€ã‚‚é »ç¹ã«ä½¿ã‚ã‚Œã‚‹æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™ã€‚\n",
    "\n",
    "**ä¸»ãªç‰¹å¾´ï¼š**\n",
    "- æ±ºå®šæœ¨ã‚’é †æ¬¡å­¦ç¿’ã•ã›ã¦ç²¾åº¦ã‚’é«˜ã‚ã‚‹ï¼ˆBoostingï¼‰\n",
    "- ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆè¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ï¼‰ã§æœ€å¼·ã‚¯ãƒ©ã‚¹ã®æ€§èƒ½\n",
    "- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ã®ç›¸æ€§ãŒè‰¯ã„\n",
    "\n",
    "**ä»£è¡¨çš„ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼š**\n",
    "1. **LightGBM** (Microsoft): é«˜é€Ÿãƒ»è»½é‡ãƒ»ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„\n",
    "2. **XGBoost**: æ­´å²ãŒé•·ãã€å®‰å®šã—ãŸæ€§èƒ½\n",
    "3. **CatBoost** (Yandex): ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®æ‰±ã„ã«å„ªã‚Œã‚‹ï¼ˆæ¬¡ç« ã§å­¦ç¿’ï¼‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LightGBM and XGBoost\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from lightgbm import LGBMClassifier\n",
    "    print(\"âœ… LightGBM installed\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ LightGBM not installed. Run: pip install lightgbm\")\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    from xgboost import XGBClassifier\n",
    "    print(\"âœ… XGBoost installed\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ XGBoost not installed. Run: pip install xgboost\")\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "#### ğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿\n",
    "\n",
    "ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€åˆ†æã«å¿…è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "\n",
    "**ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å½¹å‰²**ï¼š\n",
    "- **NumPy**: æ•°å€¤è¨ˆç®—ã®åŸºç›¤ï¼ˆé…åˆ—æ“ä½œã€æ•°å­¦é–¢æ•°ï¼‰\n",
    "- **Pandas**: ãƒ‡ãƒ¼ã‚¿æ“ä½œã¨åˆ†æï¼ˆè¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼‰\n",
    "- **Matplotlib / Seaborn**: ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ï¼ˆã‚°ãƒ©ãƒ•ä½œæˆï¼‰\n",
    "- **scikit-learn**: æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãƒ„ãƒ¼ãƒ«\n",
    "- **LightGBM**: Microsofté–‹ç™ºã®é«˜é€ŸGBDTãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "- **XGBoost**: é«˜æ€§èƒ½GBDTãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "\n",
    "**æ³¨æ„**: LightGBMã¨XGBoostãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š\n",
    "```bash\n",
    "pip install lightgbm xgboost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Basic Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Load breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"\\nFeature names (first 10):\")\n",
    "print(list(data.feature_names[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜**ï¼š\n",
    "\n",
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ä¹³ãŒã‚“ã®è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ã§ã™ï¼š\n",
    "- **ã‚µãƒ³ãƒ—ãƒ«æ•°**: 569ä»¶\n",
    "- **ç‰¹å¾´é‡æ•°**: 30å€‹ï¼ˆè…«ç˜ã®å½¢çŠ¶ã€å¤§ãã•ãªã©ã®æ¸¬å®šå€¤ï¼‰\n",
    "- **ç›®çš„å¤‰æ•°**: è‰¯æ€§ï¼ˆ0ï¼‰ã‹æ‚ªæ€§ï¼ˆ1ï¼‰ã‹\n",
    "\n",
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§GBDTã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’å­¦ã³ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "**åˆ†å‰²å¾Œã®ãƒ‡ãƒ¼ã‚¿**ï¼š\n",
    "- `X_train`, `y_train`: ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨\n",
    "- `X_test`, `y_test`: ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«ä½¿ç”¨\n",
    "\n",
    "`stratify=y`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§\n",
    "ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’åŒã˜ã«ä¿ã¡ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 2: Scikit-learn API - åŒã˜ä½¿ã„æ–¹ã§ä½¿ãˆã‚‹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Train three models with the same API\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Comparison: RandomForest vs LightGBM vs XGBoost\")\n",
    "print(\"=\"*60)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ**ï¼š\n",
    "\n",
    "LightGBMã¨XGBoostã¯ã€**Scikit-learnã¨å…¨ãåŒã˜API**ã‚’ä½¿ãˆã¾ã™ï¼š\n",
    "- `model.fit(X_train, y_train)` ã§å­¦ç¿’\n",
    "- `model.predict(X_test)` ã§äºˆæ¸¬\n",
    "- `model.score(X, y)` ã§è©•ä¾¡\n",
    "\n",
    "æ—¢å­˜ã®Scikit-learnã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ç½®ãæ›ãˆã‚‹ã ã‘ã§ã€\n",
    "é«˜æ€§èƒ½ãªGBDTãƒ¢ãƒ‡ãƒ«ãŒä½¿ãˆã¾ã™ï¼\n",
    "\n",
    "**ç²¾åº¦ã®é•ã„**ï¼š\n",
    "- RandomForestã‚‚ååˆ†é«˜ç²¾åº¦\n",
    "- LightGBMã¨XGBoostã¯ã•ã‚‰ã«é«˜ç²¾åº¦ã«ãªã‚‹ã“ã¨ãŒå¤šã„\n",
    "- ç‰¹ã«ãƒ‡ãƒ¼ã‚¿ãŒå¤§ãã„å ´åˆã€GBDTã®å„ªä½æ€§ãŒé¡•è‘—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(df_results))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_results['Train Accuracy'], width, label='Train', alpha=0.8)\n",
    "ax.bar(x + width/2, df_results['Test Accuracy'], width, label='Test', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_results['Model'])\n",
    "ax.legend()\n",
    "ax.set_ylim([0.9, 1.0])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "**å¯è¦–åŒ–ã®é‡è¦æ€§**ï¼š\n",
    "ãƒ‡ãƒ¼ã‚¿ã‚„çµæœã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ï¼š\n",
    "- ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½å·®\n",
    "- è¨“ç·´ç²¾åº¦ã¨ãƒ†ã‚¹ãƒˆç²¾åº¦ã®ã‚®ãƒ£ãƒƒãƒ—ï¼ˆéå­¦ç¿’ã®åº¦åˆã„ï¼‰\n",
    "- ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒæœ€ã‚‚å®‰å®šã—ã¦ã„ã‚‹ã‹\n",
    "\n",
    "ã€Œç™¾èã¯ä¸€è¦‹ã«ã—ã‹ãšã€ã§ã™ã€‚æ•°å­—ã ã‘ã§ãªãã€\n",
    "ã‚°ãƒ©ãƒ•ã§è¦‹ã‚‹ã¨ç›´æ„Ÿçš„ã«ç†è§£ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Part 3: Early Stopping - éå­¦ç¿’ã‚’è‡ªå‹•ã§é˜²ãï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Split validation set from training set\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Dataset split:\")\n",
    "print(f\"  Training: {len(X_train_sub)} samples\")\n",
    "print(f\"  Validation: {len(X_val)} samples\")\n",
    "print(f\"  Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "**Early Stoppingã¨ã¯ï¼Ÿ**\n",
    "\n",
    "Early Stoppingã¯ã€éå­¦ç¿’ã‚’é˜²ãå¼·åŠ›ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã§ã™ï¼š\n",
    "\n",
    "1. å­¦ç¿’ä¸­ã«æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼ˆValidation setï¼‰ã§ç²¾åº¦ã‚’ç›£è¦–\n",
    "2. æ¤œè¨¼ç²¾åº¦ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰ã€å­¦ç¿’ã‚’è‡ªå‹•ã§åœæ­¢\n",
    "3. æœ€ã‚‚è‰¯ã‹ã£ãŸæ™‚ç‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨\n",
    "\n",
    "**ãƒ¡ãƒªãƒƒãƒˆ**ï¼š\n",
    "- éå­¦ç¿’ã‚’é˜²ã’ã‚‹\n",
    "- ç„¡é§„ãªå­¦ç¿’æ™‚é–“ã‚’å‰Šæ¸›ã§ãã‚‹\n",
    "- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒæ¥½ã«ãªã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# LightGBM with early stopping\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=1000,  # å¤§ãã‚ã«è¨­å®šï¼ˆæ—©æœŸçµ‚äº†ã™ã‚‹ã®ã§å•é¡Œãªã„ï¼‰\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Fit with early stopping\n",
    "lgbm_model.fit(\n",
    "    X_train_sub, y_train_sub,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    ")\n",
    "\n",
    "print(f\"\\nLightGBM Early Stopping Results:\")\n",
    "print(f\"  Best iteration: {lgbm_model.best_iteration_}\")\n",
    "print(f\"  Total iterations set: {lgbm_model.n_estimators}\")\n",
    "print(f\"  Stopped early at: {lgbm_model.best_iteration_} trees\")\n",
    "print(f\"\\n  Test Accuracy: {lgbm_model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "**Early Stoppingã®çµæœ**ï¼š\n",
    "\n",
    "- `n_estimators=1000` ã«è¨­å®šã—ãŸãŒã€å®Ÿéš›ã«ã¯é€”ä¸­ã§åœæ­¢\n",
    "- `stopping_rounds=50` ã¯ã€Œ50å›æ”¹å–„ã—ãªã‹ã£ãŸã‚‰åœæ­¢ã€ã¨ã„ã†æ„å‘³\n",
    "- æœ€é©ãªæœ¨ã®æ•°ãŒè‡ªå‹•ã§è¦‹ã¤ã‹ã‚‹\n",
    "\n",
    "ã“ã‚Œã«ã‚ˆã‚Šã€éå­¦ç¿’ã‚’é˜²ãã¤ã¤ã€æœ€é«˜ã®æ€§èƒ½ã‚’å¼•ãå‡ºã›ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# XGBoost with early stopping\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_sub, y_train_sub,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\nXGBoost Early Stopping Results:\")\n",
    "print(f\"  Best iteration: {xgb_model.best_iteration}\")\n",
    "print(f\"  Total iterations set: {xgb_model.n_estimators}\")\n",
    "print(f\"  Stopped early at: {xgb_model.best_iteration} trees\")\n",
    "print(f\"\\n  Test Accuracy: {xgb_model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "**LightGBM vs XGBoostã®Early Stopping**ï¼š\n",
    "\n",
    "ã©ã¡ã‚‰ã‚‚åŒã˜æ¦‚å¿µã§ã™ãŒã€æ›¸ãæ–¹ãŒå°‘ã—é•ã„ã¾ã™ï¼š\n",
    "\n",
    "- **LightGBM**: `callbacks=[lgb.early_stopping(...)]`\n",
    "- **XGBoost**: `early_stopping_rounds=...`\n",
    "\n",
    "ã©ã¡ã‚‰ã‚‚`eval_set`ã«æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ã“ã¨ã§å‹•ä½œã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Part 4: Learning Curves - å­¦ç¿’ã®æ¨ç§»ã‚’å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Train models and track performance\n",
    "n_trees_range = range(10, 501, 10)\n",
    "\n",
    "lgbm_train_scores = []\n",
    "lgbm_test_scores = []\n",
    "xgb_train_scores = []\n",
    "xgb_test_scores = []\n",
    "\n",
    "for n_trees in n_trees_range:\n",
    "    # LightGBM\n",
    "    lgbm = LGBMClassifier(n_estimators=n_trees, random_state=42, verbose=-1)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    lgbm_train_scores.append(lgbm.score(X_train, y_train))\n",
    "    lgbm_test_scores.append(lgbm.score(X_test, y_test))\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_clf = XGBClassifier(n_estimators=n_trees, random_state=42, eval_metric='logloss')\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    xgb_train_scores.append(xgb_clf.score(X_train, y_train))\n",
    "    xgb_test_scores.append(xgb_clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Learning curve data collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# LightGBM\n",
    "axes[0].plot(n_trees_range, lgbm_train_scores, 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(n_trees_range, lgbm_test_scores, 'r-', label='Test', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Trees')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('LightGBM Learning Curve')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].plot(n_trees_range, xgb_train_scores, 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(n_trees_range, xgb_test_scores, 'r-', label='Test', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Trees')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('XGBoost Learning Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "**å­¦ç¿’æ›²ç·šã®èª­ã¿æ–¹**ï¼š\n",
    "\n",
    "1. **è¨“ç·´ç²¾åº¦ï¼ˆé’ç·šï¼‰**:\n",
    "   - æœ¨ã®æ•°ãŒå¢—ãˆã‚‹ã»ã©ä¸Šæ˜‡\n",
    "   - æœ€çµ‚çš„ã«1.0ï¼ˆå®Œç’§ï¼‰ã«è¿‘ã¥ã\n",
    "\n",
    "2. **ãƒ†ã‚¹ãƒˆç²¾åº¦ï¼ˆèµ¤ç·šï¼‰**:\n",
    "   - æœ€åˆã¯ä¸Šæ˜‡ã™ã‚‹ãŒã€é€”ä¸­ã§é ­æ‰“ã¡ã‹ä½ä¸‹\n",
    "   - ä½ä¸‹ã—å§‹ã‚ãŸã‚‰éå­¦ç¿’ã®ã‚µã‚¤ãƒ³\n",
    "\n",
    "3. **æœ€é©ãªæœ¨ã®æ•°**:\n",
    "   - ãƒ†ã‚¹ãƒˆç²¾åº¦ãŒæœ€å¤§ã«ãªã‚‹ç‚¹\n",
    "   - Early Stoppingã§è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹\n",
    "\n",
    "**LightGBM vs XGBoost**:\n",
    "- ã©ã¡ã‚‰ã‚‚ä¼¼ãŸæŒ™å‹•ã‚’ç¤ºã™\n",
    "- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã£ã¦ã©ã¡ã‚‰ãŒè‰¯ã„ã‹ã¯ç•°ãªã‚‹\n",
    "- ä¸¡æ–¹è©¦ã—ã¦æ¯”è¼ƒã™ã‚‹ã®ãŒãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Part 5: Speed Comparison - é€Ÿåº¦ã‚’æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "\n",
    "# Larger dataset for speed comparison\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_large, y_large = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=50,\n",
    "    n_informative=30,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "    X_large, y_large, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Large dataset created:\")\n",
    "print(f\"  Training: {len(X_train_large)} samples\")\n",
    "print(f\"  Features: {X_large.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training speed\n",
    "models_speed = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "speed_results = []\n",
    "\n",
    "for name, model in models_speed.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_large, y_train_large)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    test_acc = model.score(X_test_large, y_test_large)\n",
    "    \n",
    "    speed_results.append({\n",
    "        'Model': name,\n",
    "        'Training Time (s)': elapsed_time,\n",
    "        'Test Accuracy': test_acc\n",
    "    })\n",
    "\n",
    "df_speed = pd.DataFrame(speed_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Speed Comparison (10,000 samples, 50 features)\")\n",
    "print(\"=\"*60)\n",
    "print(df_speed.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize speed comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training time\n",
    "axes[0].bar(df_speed['Model'], df_speed['Training Time (s)'], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "axes[0].set_ylabel('Training Time (seconds)')\n",
    "axes[0].set_title('Training Speed Comparison')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].bar(df_speed['Model'], df_speed['Test Accuracy'], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "axes[1].set_ylabel('Test Accuracy')\n",
    "axes[1].set_title('Model Accuracy Comparison')\n",
    "axes[1].set_ylim([0.8, 1.0])\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "**é€Ÿåº¦æ¯”è¼ƒã®çµæœ**ï¼š\n",
    "\n",
    "ä¸€èˆ¬çš„ãªå‚¾å‘ï¼š\n",
    "1. **LightGBM**: æœ€ã‚‚é«˜é€Ÿï¼ˆæ•°å€é€Ÿã„ã“ã¨ã‚‚ï¼‰\n",
    "2. **XGBoost**: ä¸­ç¨‹åº¦ã®é€Ÿåº¦\n",
    "3. **RandomForest**: ç›¸å¯¾çš„ã«é…ã„ï¼ˆç‰¹ã«ãƒ‡ãƒ¼ã‚¿ãŒå¤§ãã„å ´åˆï¼‰\n",
    "\n",
    "**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ**ï¼š\n",
    "- LightGBMã¯ã€Œè»½é‡ã€ã®åã®é€šã‚Šã€éå¸¸ã«é«˜é€Ÿ\n",
    "- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©ã€é€Ÿåº¦å·®ãŒé¡•è‘—\n",
    "- ç²¾åº¦ã¯ã©ã‚Œã‚‚é«˜ã„æ°´æº–ã§ã€é€Ÿåº¦ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒãˆã‚‹\n",
    "\n",
    "**å®Ÿå‹™ã§ã¯**ï¼š\n",
    "- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°: LightGBMï¼ˆé«˜é€Ÿå®Ÿé¨“ï¼‰\n",
    "- æœ¬ç•ªç’°å¢ƒ: é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ã§é¸æŠ\n",
    "- Kaggle: ä¸¡æ–¹è©¦ã—ã¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Part 6: Feature Importance - é‡è¦ãªç‰¹å¾´é‡ã‚’çŸ¥ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Train models on original dataset\n",
    "lgbm_final = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "lgbm_final.fit(X_train, y_train)\n",
    "\n",
    "xgb_final = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "lgbm_importances = pd.DataFrame({\n",
    "    'feature': data.feature_names,\n",
    "    'importance': lgbm_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "xgb_importances = pd.DataFrame({\n",
    "    'feature': data.feature_names,\n",
    "    'importance': xgb_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Important Features (LightGBM):\")\n",
    "print(lgbm_importances.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LightGBM\n",
    "top_n = 15\n",
    "axes[0].barh(range(top_n), lgbm_importances['importance'].head(top_n))\n",
    "axes[0].set_yticks(range(top_n))\n",
    "axes[0].set_yticklabels(lgbm_importances['feature'].head(top_n))\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('LightGBM Feature Importance (Top 15)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].barh(range(top_n), xgb_importances['importance'].head(top_n))\n",
    "axes[1].set_yticks(range(top_n))\n",
    "axes[1].set_yticklabels(xgb_importances['feature'].head(top_n))\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('XGBoost Feature Importance (Top 15)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "**Feature Importanceã®æ´»ç”¨æ³•**ï¼š\n",
    "\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆ**:\n",
    "   - ã©ã®ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«é‡è¦ã‹ç†è§£ã§ãã‚‹\n",
    "   - ãƒ“ã‚¸ãƒã‚¹ä¸Šã®æ„æ€æ±ºå®šã«å½¹ç«‹ã¤\n",
    "\n",
    "2. **ç‰¹å¾´é‡é¸æŠ**:\n",
    "   - é‡è¦åº¦ã®ä½ã„ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡ç´ åŒ–\n",
    "   - éå­¦ç¿’ã‚’é˜²ã\n",
    "   - æ¨è«–é€Ÿåº¦ã‚’å‘ä¸Š\n",
    "\n",
    "3. **æ–°ã—ã„ç‰¹å¾´é‡ã®ç™ºè¦‹**:\n",
    "   - é‡è¦ãªç‰¹å¾´é‡ã‹ã‚‰æ´¾ç”Ÿç‰¹å¾´é‡ã‚’ä½œæˆ\n",
    "   - ã‚ˆã‚Šè‰¯ã„ãƒ¢ãƒ‡ãƒ«ã¸ã®æ‰‹ãŒã‹ã‚Š\n",
    "\n",
    "**LightGBM vs XGBoost**:\n",
    "- é‡è¦åº¦ã®è¨ˆç®—æ–¹æ³•ãŒè‹¥å¹²ç•°ãªã‚‹\n",
    "- ä¸Šä½ã®ç‰¹å¾´é‡ã¯ã ã„ãŸã„ä¸€è‡´ã™ã‚‹ã“ã¨ãŒå¤šã„\n",
    "- ä¸¡æ–¹è¦‹ã¦ç·åˆçš„ã«åˆ¤æ–­ã™ã‚‹ã®ãŒè‰¯ã„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Part 7: Cross-Validation with GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜]\n",
    "# ============================================================\n",
    "\n",
    "# Cross-validation for all models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models_cv = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Cross-Validation Results (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models_cv.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean CV Score': scores.mean(),\n",
    "        'Std CV Score': scores.std(),\n",
    "        'Min Score': scores.min(),\n",
    "        'Max Score': scores.max()\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  CV Scores: {scores}\")\n",
    "    print(f\"  Mean: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "df_cv = pd.DataFrame(cv_results)\n",
    "print(\"\\n\" + df_cv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "**Cross-Validationã®é‡è¦æ€§**ï¼š\n",
    "\n",
    "å˜ä¸€ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡ã¯ã€é‹ãŒè‰¯ã„ã ã‘ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n",
    "Cross-Validationã§è¤‡æ•°ã®åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã§è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã€\n",
    "**æœ¬å½“ã®å®ŸåŠ›**ã‚’æ¸¬å®šã§ãã¾ã™ã€‚\n",
    "\n",
    "**çµæœã®è¦‹æ–¹**ï¼š\n",
    "- **Mean CV Score**: å¹³å‡ç²¾åº¦ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰\n",
    "- **Std CV Score**: æ¨™æº–åå·®ï¼ˆå°ã•ã„ã»ã©å®‰å®šï¼‰\n",
    "- **Min/Max Score**: æœ€æ‚ª/æœ€è‰¯ã®ã‚±ãƒ¼ã‚¹\n",
    "\n",
    "å®Ÿå‹™ã§ã¯ã€å¹³å‡ã ã‘ã§ãªãæ¨™æº–åå·®ã‚‚é‡è¦ã§ã™ã€‚\n",
    "æ¨™æº–åå·®ãŒå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦æ€§èƒ½ãŒä¸å®‰å®šã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned the fundamentals of GBDT.\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "**åŸºæœ¬çš„ãªä½¿ã„æ–¹**\n",
    "- LightGBMã¨XGBoostã¯ã€Scikit-learnã¨åŒã˜APIã§ä½¿ãˆã‚‹\n",
    "- `fit()`, `predict()`, `score()` ãŒå…¨ã¦ä½¿ãˆã‚‹\n",
    "- æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®ç½®ãæ›ãˆãŒç°¡å˜\n",
    "\n",
    "**Early Stopping**\n",
    "- éå­¦ç¿’ã‚’è‡ªå‹•ã§é˜²ãå¼·åŠ›ãªæ©Ÿèƒ½\n",
    "- æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼ˆeval_setï¼‰ã‚’æ¸¡ã™ã ã‘ã§å‹•ä½œ\n",
    "- æœ€é©ãªæœ¨ã®æ•°ã‚’è‡ªå‹•ã§è¦‹ã¤ã‘ã‚‹\n",
    "\n",
    "**å­¦ç¿’æ›²ç·š**\n",
    "- ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã‚’å¯è¦–åŒ–ã—ã¦ç†è§£\n",
    "- éå­¦ç¿’ã®å…†å€™ã‚’ç™ºè¦‹\n",
    "- é©åˆ‡ãªæœ¨ã®æ•°ã‚’æ±ºå®š\n",
    "\n",
    "**é€Ÿåº¦ã¨æ€§èƒ½**\n",
    "- LightGBMã¯éå¸¸ã«é«˜é€Ÿ\n",
    "- XGBoostã¯å®‰å®šã—ãŸæ€§èƒ½\n",
    "- RandomForestã‚ˆã‚Šé«˜ç²¾åº¦ãªã“ã¨ãŒå¤šã„\n",
    "\n",
    "**Feature Importance**\n",
    "- é‡è¦ãªç‰¹å¾´é‡ã‚’ç‰¹å®š\n",
    "- ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆã«å½¹ç«‹ã¤\n",
    "- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æŒ‡é‡\n",
    "\n",
    "### Next Steps\n",
    "Continue to **Notebook 14** for CatBoost and categorical feature handling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "### âš ï¸ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ #1: LightGBMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—\n",
    "\n",
    "LightGBMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§\"Microsoft Visual C++ãŒå¿…è¦\"ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "**åŸå› :**\n",
    "1. Windowsç’°å¢ƒã§C++ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„\n",
    "2. ãƒ“ãƒ«ãƒ‰æ¸ˆã¿ãƒã‚¤ãƒŠãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„\n",
    "\n",
    "**âœ… è§£æ±ºæ³•:**\n",
    "\n",
    "```bash\n",
    "# Windows: condaã‚’ä½¿ã†æ–¹æ³•ï¼ˆæ¨å¥¨ï¼‰\n",
    "conda install -c conda-forge lightgbm\n",
    "\n",
    "# ã¾ãŸã¯pre-builtãƒ›ã‚¤ãƒ¼ãƒ«ã‚’ä½¿ã†\n",
    "pip install lightgbm --prefer-binary\n",
    "\n",
    "# macOS/Linux: é€šå¸¸ã®pipã§å•é¡Œãªã—\n",
    "pip install lightgbm\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "### âš ï¸ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ #2: Early StoppingãŒåŠ¹ã‹ãªã„\n",
    "\n",
    "Early Stoppingã‚’è¨­å®šã—ãŸã®ã«ã€å…¨ã¦ã®æœ¨ãŒå­¦ç¿’ã•ã‚Œã¦ã—ã¾ã†ã€‚\n",
    "\n",
    "**åŸå› :**\n",
    "1. `eval_set`ã‚’æ¸¡ã—ã¦ã„ãªã„\n",
    "2. `eval_metric`ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ãªã„\n",
    "\n",
    "**âœ… è§£æ±ºæ³•:**\n",
    "\n",
    "```python\n",
    "# âŒ é–“é•ã„: eval_setãŒãªã„\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# âœ… æ­£ã—ã„: eval_setã‚’æ¸¡ã™\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ è‡ªå·±è©•ä¾¡ã‚¯ã‚¤ã‚º\n",
    "\n",
    "å­¦ç¿’å†…å®¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ï¼ã™ãã«ç­”ãˆã‚’è¦‹ãšã«ã€ã¾ãšè‡ªåˆ†ã§è€ƒãˆã¦ã¿ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "### Q1: LightGBMã¨XGBoostã®æœ€å¤§ã®åˆ©ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: Scikit-learnã¨åŒã˜APIã§ã€ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã¨é€Ÿåº¦ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨\n",
    "\n",
    "LightGBMã¨XGBoostã¯ã€Scikit-learnã®`RandomForestClassifier`ãªã©ã¨å…¨ãåŒã˜ä½¿ã„æ–¹ãŒã§ãã¾ã™ã€‚ãã®ãŸã‚ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ç°¡å˜ã«ç½®ãæ›ãˆã‚‰ã‚Œã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã¯é€šå¸¸ã€ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã‚’é”æˆã§ãã€ç‰¹ã«LightGBMã¯éå¸¸ã«é«˜é€Ÿã§ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q2: Early Stoppingã®å½¹å‰²ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: éå­¦ç¿’ã‚’é˜²ãã€æœ€é©ãªæœ¨ã®æ•°ã‚’è‡ªå‹•ã§è¦‹ã¤ã‘ã‚‹\n",
    "\n",
    "Early Stoppingã¯ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æ€§èƒ½ã‚’ç›£è¦–ã—ãªãŒã‚‰å­¦ç¿’ã‚’é€²ã‚ã€æ€§èƒ½ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰è‡ªå‹•ã§å­¦ç¿’ã‚’åœæ­¢ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€éå­¦ç¿’ã‚’é˜²ãã¤ã¤ã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’å¾—ã‚‰ã‚Œã¾ã™ã€‚ã¾ãŸã€ç„¡é§„ãªè¨ˆç®—æ™‚é–“ã‚‚ç¯€ç´„ã§ãã¾ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q3: Feature Importanceã‚’è¦‹ã‚‹ã“ã¨ã§ä½•ãŒåˆ†ã‹ã‚Šã¾ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: ã©ã®ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«é‡è¦ã‹ã€ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆãŒã§ãã‚‹\n",
    "\n",
    "Feature Importanceã¯ã€å„ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«ã©ã‚Œã ã‘è²¢çŒ®ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆãŒå¯èƒ½ã«ãªã‚Šã€é‡è¦ã§ãªã„ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ãŸã‚Šã€é‡è¦ãªç‰¹å¾´é‡ã‹ã‚‰æ–°ã—ã„æ´¾ç”Ÿç‰¹å¾´é‡ã‚’ä½œæˆã—ãŸã‚Šã§ãã¾ã™ã€‚ã¾ãŸã€ãƒ“ã‚¸ãƒã‚¹ä¸Šã®æ„æ€æ±ºå®šã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â¡ï¸ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "### å­¦ç¿’ã‚’ç¶šã‘ã‚‹\n",
    "\n",
    "æ¬¡ã¯ **Notebook 14: CatBoostã¨ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®æ”»ç•¥** ã¸é€²ã¿ã¾ã—ã‚‡ã†ï¼\n",
    "\n",
    "CatBoostã¯ã€ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ï¼ˆ\"male\"/\"female\"ã®ã‚ˆã†ãªæ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’\n",
    "OneHotEncodingãªã—ã§ç›´æ¥æ‰±ãˆã‚‹é©æ–°çš„ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚\n",
    "\n",
    "### å¾©ç¿’ãŒå¿…è¦ãªå ´åˆ\n",
    "\n",
    "- **Notebook 05: Tree and Ensemble Models**\n",
    "- **Notebook 03: Model Evaluation Metrics**\n",
    "\n",
    "### ã•ã‚‰ã«å­¦ã¶ãŸã‚ã«\n",
    "\n",
    "**å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**\n",
    "- LightGBM: https://lightgbm.readthedocs.io/\n",
    "- XGBoost: https://xgboost.readthedocs.io/\n",
    "\n",
    "**æ›¸ç±:**\n",
    "- \"Hands-On Gradient Boosting with XGBoost and scikit-learn\"\n",
    "\n",
    "**Kaggleã§å®Ÿè·µ:**\n",
    "- Titanic Competition\n",
    "- House Prices Competition\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‰ ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼\n",
    "\n",
    "æ¬¡ã®ç« ã§ã•ã‚‰ã«æ·±ãæ¢æ±‚ã—ã¾ã—ã‚‡ã†ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

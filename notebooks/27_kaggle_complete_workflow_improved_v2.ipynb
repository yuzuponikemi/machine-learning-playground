{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27. Kaggleå®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ - ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æ”»ç•¥æ³• (Kaggle Complete Workflow)\n",
    "\n",
    "## æ¦‚è¦\n",
    "Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ä¸Šä½å…¥è³ã™ã‚‹ãŸã‚ã®å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å­¦ã³ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã‹ã‚‰ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã€ã‚µãƒ–ãƒŸãƒƒãƒˆã¾ã§ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè·µçš„ã«è§£èª¬ã—ã¾ã™ã€‚\n",
    "\n",
    "## å­¦ç¿’ç›®æ¨™\n",
    "- Kaggleã‚³ãƒ³ãƒšã®å…¨ä½“åƒã‚’ç†è§£ã§ãã‚‹\n",
    "- åŠ¹æœçš„ãªEDAã‚’å®Ÿæ–½ã§ãã‚‹\n",
    "- æˆ¦ç•¥çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒã§ãã‚‹\n",
    "- é©åˆ‡ãªæ¤œè¨¼æˆ¦ç•¥ã‚’é¸æŠã§ãã‚‹\n",
    "- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§æ€§èƒ½ã‚’å‘ä¸Šã§ãã‚‹\n",
    "- å®Ÿè·µçš„ãªKaggleæˆ¦ç•¥ã‚’èº«ã«ã¤ã‘ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è¨­å®š\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®å…¨ä½“åƒ\n",
    "\n",
    "### Kaggleã¨ã¯\n",
    "\n",
    "**Kaggle**ã¯ã€ä¸–ç•Œæœ€å¤§ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚\n",
    "\n",
    "### ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®æµã‚Œ\n",
    "\n",
    "```\n",
    "1. ãƒ‡ãƒ¼ã‚¿ç†è§£ãƒ»EDA (10-20%)\n",
    "   â†“\n",
    "2. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ (5-10%)\n",
    "   â†“\n",
    "3. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (30-40%)\n",
    "   â†“\n",
    "4. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãƒ»ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (20-30%)\n",
    "   â†“\n",
    "5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ»ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (10-20%)\n",
    "   â†“\n",
    "6. æœ€çµ‚ã‚µãƒ–ãƒŸãƒƒãƒˆãƒ»æŒ¯ã‚Šè¿”ã‚Š (5-10%)\n",
    "```\n",
    "\n",
    "### Kaggleã®ãƒ†ã‚£ã‚¢\n",
    "\n",
    "1. **Novice**: åˆå¿ƒè€…ï¼ˆãƒ¡ãƒ€ãƒ«ãªã—ï¼‰\n",
    "2. **Contributor**: è²¢çŒ®è€…ï¼ˆDiscussion/Notebookã§æ´»èºï¼‰\n",
    "3. **Expert**: å°‚é–€å®¶ï¼ˆãƒ¡ãƒ€ãƒ«ç²å¾—ï¼‰\n",
    "4. **Master**: é”äººï¼ˆé‡‘ãƒ¡ãƒ€ãƒ«ç²å¾—ï¼‰\n",
    "5. **Grandmaster**: æœ€é«˜ä½ï¼ˆè¤‡æ•°ã®é‡‘ãƒ¡ãƒ€ãƒ« + Top 10å…¥è³ï¼‰\n",
    "\n",
    "### ãƒ¡ãƒ€ãƒ«ç²å¾—ã®åŸºæº–\n",
    "\n",
    "- ğŸ¥‰ **Bronze**: Top 40%\n",
    "- ğŸ¥ˆ **Silver**: Top 20%\n",
    "- ğŸ¥‡ **Gold**: Top 10%\n",
    "\n",
    "### æˆåŠŸã®ãŸã‚ã®å¿ƒæ§‹ãˆ\n",
    "\n",
    "1. **ç„¦ã‚‰ãªã„**: æœ€åˆã¯å®Œèµ°ã‚’ç›®æ¨™ã«\n",
    "2. **å­¦ã¶**: Public Notebooksã‹ã‚‰å­¦ã¶\n",
    "3. **å®Ÿé¨“**: å¤šãã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è©¦ã™\n",
    "4. **è¨˜éŒ²**: å®Ÿé¨“çµæœã‚’è¨˜éŒ²ã™ã‚‹\n",
    "5. **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**: Discussionã§æƒ…å ±äº¤æ›\n",
    "6. **æ¤œè¨¼**: Local CV ã¨ Public LB ã®ç›¸é–¢ã‚’ç¢ºèª\n",
    "7. **å¿è€**: Shake upã‚’æã‚Œãªã„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Phase 1: ãƒ‡ãƒ¼ã‚¿ç†è§£ã¨EDA\n",
    "\n",
    "### EDAã®ç›®çš„\n",
    "\n",
    "1. ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã¨å“è³ªã‚’ç†è§£ã™ã‚‹\n",
    "2. æ¬ æå€¤ãƒ»å¤–ã‚Œå€¤ã‚’æ¤œå‡ºã™ã‚‹\n",
    "3. ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚ã‚’æŠŠæ¡ã™ã‚‹\n",
    "4. ä»®èª¬ã‚’ç«‹ã¦ã‚‹\n",
    "5. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒ’ãƒ³ãƒˆã‚’å¾—ã‚‹\n",
    "\n",
    "### EDAãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "```python\n",
    "# âœ… EDAãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "# 1. ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±\n",
    "# - ã‚µãƒ³ãƒ—ãƒ«æ•°ã€ç‰¹å¾´é‡æ•°ã¯ï¼Ÿ\n",
    "# - ãƒ‡ãƒ¼ã‚¿å‹ã¯é©åˆ‡ã‹ï¼Ÿ\n",
    "# - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯ï¼Ÿ\n",
    "\n",
    "# 2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°\n",
    "# - åˆ†å¸ƒã¯ï¼Ÿï¼ˆæ­£è¦åˆ†å¸ƒã€æ­ªã¿ã€å¤–ã‚Œå€¤ï¼‰\n",
    "# - å¯¾æ•°å¤‰æ›ãŒå¿…è¦ã‹ï¼Ÿ\n",
    "# - ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¯ã‚ã‚‹ã‹ï¼Ÿ\n",
    "\n",
    "# 3. ç‰¹å¾´é‡ã®åˆ†æ\n",
    "# - æ¬ æå€¤ã®å‰²åˆã¯ï¼Ÿ\n",
    "# - æ•°å€¤å¤‰æ•°ã®åˆ†å¸ƒã¯ï¼Ÿ\n",
    "# - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¯ï¼Ÿ\n",
    "# - å®šæ•°ç‰¹å¾´é‡ã¯ã‚ã‚‹ã‹ï¼Ÿ\n",
    "\n",
    "# 4. ç›¸é–¢åˆ†æ\n",
    "# - ç‰¹å¾´é‡é–“ã®ç›¸é–¢ã¯ï¼Ÿ\n",
    "# - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ã¯?\n",
    "# - å¤šé‡å…±ç·šæ€§ã¯ã‚ã‚‹ã‹ï¼Ÿ\n",
    "\n",
    "# 5. æ™‚ç³»åˆ—æ€§\n",
    "# - æ™‚é–“çš„ãªå‚¾å‘ã¯ã‚ã‚‹ã‹ï¼Ÿ\n",
    "# - ãƒˆãƒ¬ãƒ³ãƒ‰ã€å­£ç¯€æ€§ã¯ï¼Ÿ\n",
    "# - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ã¯ï¼Ÿ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆä½å®…ä¾¡æ ¼äºˆæ¸¬ã‚’æ¨¡æ“¬ï¼‰\n",
    "np.random.seed(42)\n",
    "n_samples = 2000\n",
    "\n",
    "# ç‰¹å¾´é‡ã®ç”Ÿæˆ\n",
    "data = {\n",
    "    'Id': range(1, n_samples + 1),\n",
    "    'OverallQual': np.random.randint(1, 11, n_samples),  # å“è³ªï¼ˆ1-10ï¼‰\n",
    "    'GrLivArea': np.random.normal(1500, 500, n_samples),  # å±…ä½é¢ç©\n",
    "    'GarageCars': np.random.choice([0, 1, 2, 3, 4], n_samples, p=[0.05, 0.15, 0.5, 0.25, 0.05]),\n",
    "    'GarageArea': np.random.normal(500, 150, n_samples),  # ã‚¬ãƒ¬ãƒ¼ã‚¸é¢ç©\n",
    "    'TotalBsmtSF': np.random.normal(1000, 300, n_samples),  # åœ°ä¸‹å®¤é¢ç©\n",
    "    'YearBuilt': np.random.randint(1900, 2020, n_samples),\n",
    "    'YearRemodAdd': np.random.randint(1950, 2020, n_samples),\n",
    "    'MSSubClass': np.random.choice([20, 30, 40, 50, 60, 70, 80, 90], n_samples),\n",
    "    'Neighborhood': np.random.choice(['CollgCr', 'Veenker', 'Crawfor', 'NoRidge', \n",
    "                                     'Mitchel', 'Somerst', 'NWAmes', 'OldTown', \n",
    "                                     'BrkSide', 'Sawyer', 'NridgHt'], n_samples),\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(data)\n",
    "\n",
    "# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆä½å®…ä¾¡æ ¼ï¼‰ã®ç”Ÿæˆ\n",
    "# ä¾¡æ ¼ = å“è³ªÃ—ä¿‚æ•° + é¢ç©Ã—ä¿‚æ•° + ã‚¬ãƒ¬ãƒ¼ã‚¸Ã—ä¿‚æ•° + ... + ãƒã‚¤ã‚º\n",
    "price = (\n",
    "    df_train['OverallQual'] * 20000 +\n",
    "    df_train['GrLivArea'] * 100 +\n",
    "    df_train['GarageCars'] * 15000 +\n",
    "    df_train['GarageArea'] * 50 +\n",
    "    df_train['TotalBsmtSF'] * 30 +\n",
    "    (df_train['YearBuilt'] - 1900) * 300 +\n",
    "    np.random.normal(0, 20000, n_samples)\n",
    ")\n",
    "\n",
    "df_train['SalePrice'] = np.maximum(price, 50000)  # æœ€ä½ä¾¡æ ¼50000\n",
    "\n",
    "# æ„å›³çš„ã«æ¬ æå€¤ã‚’è¿½åŠ \n",
    "df_train.loc[np.random.choice(df_train.index, 100), 'GarageArea'] = np.nan\n",
    "df_train.loc[np.random.choice(df_train.index, 50), 'TotalBsmtSF'] = np.nan\n",
    "\n",
    "print(f\"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {df_train.shape}\")\n",
    "print(f\"\\nãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­:\")\n",
    "print(df_train.head(10))\n",
    "print(f\"\\nãƒ‡ãƒ¼ã‚¿å‹:\")\n",
    "print(df_train.dtypes)\n",
    "print(f\"\\nåŸºæœ¬çµ±è¨ˆé‡:\")\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†æ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "axes[0].hist(df_train['SalePrice'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('SalePrice Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Sale Price')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# å¯¾æ•°å¤‰æ›å¾Œ\n",
    "axes[1].hist(np.log1p(df_train['SalePrice']), bins=50, alpha=0.7, \n",
    "             edgecolor='black', color='orange')\n",
    "axes[1].set_title('Log(SalePrice) Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Log(Sale Price)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# QQãƒ—ãƒ­ãƒƒãƒˆ\n",
    "stats.probplot(np.log1p(df_train['SalePrice']), dist=\"norm\", plot=axes[2])\n",
    "axes[2].set_title('Q-Q Plot (Log-transformed)', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ­ªåº¦ï¼ˆskewnessï¼‰ã®ç¢ºèª\n",
    "skewness = df_train['SalePrice'].skew()\n",
    "log_skewness = np.log1p(df_train['SalePrice']).skew()\n",
    "\n",
    "print(f\"\\næ­ªåº¦:\")\n",
    "print(f\"- SalePrice: {skewness:.3f}\")\n",
    "print(f\"- Log(SalePrice): {log_skewness:.3f}\")\n",
    "print(f\"\\nğŸ’¡ ãƒã‚¤ãƒ³ãƒˆ:\")\n",
    "print(\"- å¯¾æ•°å¤‰æ›ã«ã‚ˆã‚Šæ­ªåº¦ãŒæ”¹å–„\")\n",
    "print(\"- ã‚ˆã‚Šæ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã\")\n",
    "print(\"- RMSEã‚ˆã‚ŠRMSLEã§è©•ä¾¡ã™ã‚‹å ´åˆã€å¯¾æ•°å¤‰æ›ãŒæœ‰åŠ¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. æ¬ æå€¤ã®åˆ†æ\n",
    "missing = df_train.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "missing_pct = (missing / len(df_train)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "\n",
    "print(\"æ¬ æå€¤ã®çŠ¶æ³:\")\n",
    "print(missing_df)\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "if len(missing) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.barh(range(len(missing)), missing_pct.values, alpha=0.7, edgecolor='black')\n",
    "    plt.yticks(range(len(missing)), missing_pct.index)\n",
    "    plt.xlabel('Missing Percentage (%)', fontsize=11)\n",
    "    plt.title('Missing Values Analysis', fontsize=12, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ æ¬ æå€¤ã®å¯¾å‡¦æ³•:\")\n",
    "print(\"- æ¬ æç‡ < 5%: å¹³å‡å€¤/ä¸­å¤®å€¤ã§è£œå®Œ\")\n",
    "print(\"- æ¬ æç‡ 5-30%: ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã—ã¦è£œå®Œ or æ¬ æãƒ•ãƒ©ã‚°ã‚’ä½œæˆ\")\n",
    "print(\"- æ¬ æç‡ > 30%: å‰Šé™¤ã‚’æ¤œè¨\")\n",
    "print(\"- ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°: 'Missing'ã¨ã„ã†æ–°ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ç›¸é–¢åˆ†æ\n",
    "# æ•°å€¤å¤‰æ•°ã®ã¿æŠ½å‡º\n",
    "numeric_features = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features.remove('Id')  # IDã¯ç›¸é–¢åˆ†æã‹ã‚‰é™¤å¤–\n",
    "\n",
    "# ç›¸é–¢è¡Œåˆ—\n",
    "corr_matrix = df_train[numeric_features].corr()\n",
    "\n",
    "# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ï¼ˆä¸Šä½10ï¼‰\n",
    "target_corr = corr_matrix['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "print(\"SalePriceã¨ã®ç›¸é–¢ï¼ˆä¸Šä½10ï¼‰:\")\n",
    "print(target_corr.head(10))\n",
    "\n",
    "# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆä¸»è¦ãªç‰¹å¾´é‡ã®ã¿ï¼‰\n",
    "top_features = target_corr.head(10).index.tolist()\n",
    "corr_top = df_train[top_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_top, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap (Top Features)', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ç›¸é–¢åˆ†æã®ãƒã‚¤ãƒ³ãƒˆ:\")\n",
    "print(\"- ç›¸é–¢ > 0.5: å¼·ã„æ­£ã®ç›¸é–¢ â†’ é‡è¦ãªç‰¹å¾´é‡å€™è£œ\")\n",
    "print(\"- ç›¸é–¢ < -0.5: å¼·ã„è² ã®ç›¸é–¢ â†’ æ³¨æ„ãŒå¿…è¦\")\n",
    "print(\"- ç‰¹å¾´é‡é–“ã®ç›¸é–¢ > 0.9: å¤šé‡å…±ç·šæ€§ â†’ ç‰‡æ–¹ã‚’å‰Šé™¤æ¤œè¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. æ•£å¸ƒå›³è¡Œåˆ—ï¼ˆãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆï¼‰\n",
    "# ä¸Šä½5ç‰¹å¾´é‡ã®ã¿\n",
    "top5_features = target_corr.head(6).index.tolist()  # SalePriceã‚’å«ã‚€\n",
    "\n",
    "sns.pairplot(df_train[top5_features], diag_kind='kde', \n",
    "             plot_kws={'alpha': 0.6}, height=2.5)\n",
    "plt.suptitle('Pairplot of Top Features', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ã“ã¨:\")\n",
    "print(\"- ç·šå½¢é–¢ä¿‚ã®æœ‰ç„¡\")\n",
    "print(\"- å¤–ã‚Œå€¤ã®å­˜åœ¨\")\n",
    "print(\"- éç·šå½¢ãªé–¢ä¿‚æ€§ï¼ˆå¤šé …å¼ç‰¹å¾´é‡ã®ãƒ’ãƒ³ãƒˆï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phase 2: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\n",
    "\n",
    "### ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®é‡è¦æ€§\n",
    "\n",
    "1. **åŸºæº–ç‚¹ã®è¨­å®š**: æ”¹å–„ã®åº¦åˆã„ã‚’æ¸¬ã‚‹åŸºæº–\n",
    "2. **ã‚µãƒ‹ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯**: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ¤œè¨¼\n",
    "3. **ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰æ„Ÿè¦š**: Public LBã¨ã®ç›¸é–¢ç¢ºèª\n",
    "4. **æ—©æœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: å•é¡Œã®æ—©æœŸç™ºè¦‹\n",
    "\n",
    "### ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰å§‹ã‚ã‚‹\n",
    "\n",
    "```python\n",
    "# æ¨å¥¨é †åº\n",
    "1. å˜ç´”ãªå¹³å‡å€¤äºˆæ¸¬\n",
    "2. ç·šå½¢å›å¸°\n",
    "3. Random Forestï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "4. LightGBM/XGBoostï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "# æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ\n",
    "df_model = df_train.copy()\n",
    "for col in ['GarageArea', 'TotalBsmtSF']:\n",
    "    df_model[col].fillna(df_model[col].median(), inplace=True)\n",
    "\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "df_model = pd.get_dummies(df_model, columns=['Neighborhood', 'MSSubClass'], drop_first=True)\n",
    "\n",
    "# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢\n",
    "X = df_model.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = df_model['SalePrice']\n",
    "\n",
    "# å¯¾æ•°å¤‰æ›ï¼ˆRMSLEå¯¾ç­–ï¼‰\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}\")\n",
    "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}\")\n",
    "print(f\"ç‰¹å¾´é‡æ•°: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"Root Mean Squared Logarithmic Error\"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(\n",
    "        np.expm1(y_true), np.expm1(y_pred)\n",
    "    ))\n",
    "\n",
    "baseline_results = []\n",
    "\n",
    "# 1. å¹³å‡å€¤äºˆæ¸¬\n",
    "y_pred_mean = np.full(len(y_test), y_train.mean())\n",
    "rmsle_mean = rmsle(y_test, y_pred_mean)\n",
    "baseline_results.append({'Model': 'Mean Baseline', 'RMSLE': rmsle_mean})\n",
    "\n",
    "# 2. Ridgeå›å¸°\n",
    "ridge = Ridge(alpha=10.0, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "rmsle_ridge = rmsle(y_test, y_pred_ridge)\n",
    "baseline_results.append({'Model': 'Ridge Regression', 'RMSLE': rmsle_ridge})\n",
    "\n",
    "# 3. Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rmsle_rf = rmsle(y_test, y_pred_rf)\n",
    "baseline_results.append({'Model': 'Random Forest', 'RMSLE': rmsle_rf})\n",
    "\n",
    "# 4. LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "rmsle_lgb = rmsle(y_test, y_pred_lgb)\n",
    "baseline_results.append({'Model': 'LightGBM', 'RMSLE': rmsle_lgb})\n",
    "\n",
    "# çµæœã®è¡¨ç¤º\n",
    "baseline_df = pd.DataFrame(baseline_results).sort_values('RMSLE')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ\")\n",
    "print(\"=\" * 60)\n",
    "print(baseline_df.to_string(index=False))\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(baseline_df['Model'], baseline_df['RMSLE'], \n",
    "         alpha=0.7, edgecolor='black', color='skyblue')\n",
    "plt.xlabel('RMSLE', fontsize=11)\n",
    "plt.title('Baseline Models Comparison', fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "for i, row in baseline_df.iterrows():\n",
    "    plt.text(row['RMSLE'], row.name, f\"{row['RMSLE']:.4f}\",\n",
    "            va='center', ha='left', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰å­¦ã¶ã“ã¨:\")\n",
    "print(f\"- æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {baseline_df.iloc[0]['Model']}\")\n",
    "print(f\"- ã‚¹ã‚³ã‚¢: {baseline_df.iloc[0]['RMSLE']:.4f}\")\n",
    "print(\"- ã“ã‚Œã‚’åŸºæº–ã«æ”¹å–„ã‚’ç›®æŒ‡ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 3: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "\n",
    "### ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®é»„é‡‘å¾‹\n",
    "\n",
    "**\"ç‰¹å¾´é‡ãŒ99%ã€ãƒ¢ãƒ‡ãƒ«ãŒ1%\"** - Andrew Ng\n",
    "\n",
    "### ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æˆ¦ç•¥\n",
    "\n",
    "1. **ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ´»ç”¨**\n",
    "   - æ¥­ç•Œã®å¸¸è­˜ã‚’ç‰¹å¾´é‡ã«\n",
    "   - å°‚é–€å®¶ã®æ„è¦‹ã‚’å‚è€ƒã«\n",
    "\n",
    "2. **æ—¢å­˜ç‰¹å¾´é‡ã®å¤‰æ›**\n",
    "   - å¯¾æ•°å¤‰æ›ã€ã¹ãä¹—å¤‰æ›\n",
    "   - ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€æ­£è¦åŒ–\n",
    "   - Binningï¼ˆãƒ“ãƒ‹ãƒ³ã‚°ï¼‰\n",
    "\n",
    "3. **ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›**\n",
    "   - åŠ æ¸›ä¹—é™¤\n",
    "   - å¤šé …å¼ç‰¹å¾´é‡\n",
    "   - æ¯”ç‡ã®è¨ˆç®—\n",
    "\n",
    "4. **é›†ç´„ç‰¹å¾´é‡**\n",
    "   - ã‚°ãƒ«ãƒ¼ãƒ—çµ±è¨ˆé‡ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€æœ€å¤§ã€æœ€å°ï¼‰\n",
    "   - ã‚«ã‚¦ãƒ³ãƒˆç‰¹å¾´é‡\n",
    "   - ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰¹å¾´é‡\n",
    "\n",
    "5. **æ™‚ç³»åˆ—ç‰¹å¾´é‡**\n",
    "   - ãƒ©ã‚°ç‰¹å¾´é‡\n",
    "   - ç§»å‹•å¹³å‡\n",
    "   - ãƒˆãƒ¬ãƒ³ãƒ‰ã€å­£ç¯€æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè£…\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    ç‰¹å¾´é‡ã‚’ä½œæˆ\n",
    "    \"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # 1. å¹´é½¢é–¢é€£ã®ç‰¹å¾´é‡\n",
    "    df_fe['HouseAge'] = 2020 - df_fe['YearBuilt']\n",
    "    df_fe['RemodAge'] = 2020 - df_fe['YearRemodAdd']\n",
    "    df_fe['IsRemodeled'] = (df_fe['YearRemodAdd'] != df_fe['YearBuilt']).astype(int)\n",
    "    \n",
    "    # 2. é¢ç©é–¢é€£ã®ç‰¹å¾´é‡\n",
    "    df_fe['TotalSF'] = df_fe['GrLivArea'] + df_fe['TotalBsmtSF']\n",
    "    df_fe['AreaPerRoom'] = df_fe['GrLivArea'] / (df_fe['OverallQual'] + 1)  # éƒ¨å±‹æ•°ã®ä»£ç†\n",
    "    \n",
    "    # 3. ã‚¬ãƒ¬ãƒ¼ã‚¸é–¢é€£\n",
    "    df_fe['HasGarage'] = (df_fe['GarageCars'] > 0).astype(int)\n",
    "    df_fe['GarageAreaPerCar'] = df_fe['GarageArea'] / (df_fe['GarageCars'] + 1)\n",
    "    \n",
    "    # 4. å“è³ªé–¢é€£\n",
    "    df_fe['QualTimesArea'] = df_fe['OverallQual'] * df_fe['GrLivArea']\n",
    "    df_fe['QualSquared'] = df_fe['OverallQual'] ** 2\n",
    "    \n",
    "    # 5. æ¯”ç‡ç‰¹å¾´é‡\n",
    "    df_fe['BsmtRatio'] = df_fe['TotalBsmtSF'] / (df_fe['GrLivArea'] + 1)\n",
    "    df_fe['GarageRatio'] = df_fe['GarageArea'] / (df_fe['GrLivArea'] + 1)\n",
    "    \n",
    "    return df_fe\n",
    "\n",
    "# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’é©ç”¨\n",
    "df_enhanced = create_features(df_model)\n",
    "\n",
    "print(f\"å…ƒã®ç‰¹å¾´é‡æ•°: {df_model.shape[1]}\")\n",
    "print(f\"æ‹¡å¼µå¾Œã®ç‰¹å¾´é‡æ•°: {df_enhanced.shape[1]}\")\n",
    "print(f\"è¿½åŠ ã•ã‚ŒãŸç‰¹å¾´é‡: {df_enhanced.shape[1] - df_model.shape[1]}\")\n",
    "\n",
    "# æ–°ã—ã„ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ\n",
    "new_features = set(df_enhanced.columns) - set(df_model.columns)\n",
    "print(f\"\\næ–°ã—ã„ç‰¹å¾´é‡:\")\n",
    "for feat in sorted(new_features):\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‹¡å¼µç‰¹å¾´é‡ã§ã®å­¦ç¿’\n",
    "X_enhanced = df_enhanced.drop(['Id', 'SalePrice'], axis=1, errors='ignore')\n",
    "\n",
    "# æ¬ æå€¤ã‚’è£œå®Œ\n",
    "X_enhanced = X_enhanced.fillna(X_enhanced.median())\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_enhanced, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# LightGBMã§å†å­¦ç¿’\n",
    "lgb_enhanced = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_enhanced.fit(X_train_enh, y_train_enh)\n",
    "y_pred_enhanced = lgb_enhanced.predict(X_test_enh)\n",
    "rmsle_enhanced = rmsle(y_test_enh, y_pred_enhanced)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®åŠ¹æœ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆLightGBMï¼‰: {rmsle_lgb:.4f}\")\n",
    "print(f\"æ‹¡å¼µç‰¹å¾´é‡ï¼ˆLightGBMï¼‰:   {rmsle_enhanced:.4f}\")\n",
    "print(f\"æ”¹å–„: {rmsle_lgb - rmsle_enhanced:.4f} ({(rmsle_lgb - rmsle_enhanced)/rmsle_lgb*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®åŠ¹æœ:\")\n",
    "print(\"- ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Š\")\n",
    "print(\"- ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ´»ç”¨ãŒéµ\")\n",
    "print(\"- åœ°é“ãªå®Ÿé¨“ãŒé‡è¦\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡é‡è¦åº¦ã®ç¢ºèª\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_enhanced.columns,\n",
    "    'importance': lgb_enhanced.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# ä¸Šä½20ç‰¹å¾´é‡ã‚’å¯è¦–åŒ–\n",
    "top20 = feature_importance.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top20)), top20['importance'].values, alpha=0.7, edgecolor='black')\n",
    "plt.yticks(range(len(top20)), top20['feature'].values)\n",
    "plt.xlabel('Importance', fontsize=11)\n",
    "plt.title('Top 20 Feature Importances (Enhanced)', fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ–°ç‰¹å¾´é‡ãŒãƒˆãƒƒãƒ—20ã«å…¥ã£ã¦ã„ã‚‹ã‹ç¢ºèª\n",
    "new_in_top20 = top20['feature'].isin(new_features)\n",
    "print(f\"\\nãƒˆãƒƒãƒ—20ã«å…¥ã£ãŸæ–°ç‰¹å¾´é‡: {new_in_top20.sum()}å€‹\")\n",
    "if new_in_top20.sum() > 0:\n",
    "    print(\"\\næ–°ç‰¹å¾´é‡:\")\n",
    "    for feat in top20[new_in_top20]['feature'].values:\n",
    "        print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phase 4: æ¤œè¨¼æˆ¦ç•¥\n",
    "\n",
    "### ãªãœæ¤œè¨¼ãŒé‡è¦ã‹\n",
    "\n",
    "- **éå­¦ç¿’ã®æ¤œå‡º**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ã‚’æ¨å®š\n",
    "- **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é¸æŠ\n",
    "- **LBç›¸é–¢**: Local CVã¨Public LBã®ç›¸é–¢ã‚’ç¢ºèª\n",
    "\n",
    "### æ¤œè¨¼æˆ¦ç•¥ã®ç¨®é¡\n",
    "\n",
    "1. **Hold-out Validation**\n",
    "   - ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿ\n",
    "   - ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã¯ä¸å®‰å®š\n",
    "\n",
    "2. **K-Fold Cross Validation**\n",
    "   - ã‚ˆã‚Šå®‰å®šã—ãŸè©•ä¾¡\n",
    "   - è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„\n",
    "   - K=5 or 10ãŒä¸€èˆ¬çš„\n",
    "\n",
    "3. **Stratified K-Fold**\n",
    "   - ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«å¯¾å¿œ\n",
    "   - åˆ†é¡å•é¡Œã§æ¨å¥¨\n",
    "\n",
    "4. **Group K-Fold**\n",
    "   - ã‚°ãƒ«ãƒ¼ãƒ—æ§‹é€ ãŒã‚ã‚‹å ´åˆ\n",
    "   - ä¾‹: åŒä¸€äººç‰©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ã‚‹\n",
    "\n",
    "5. **Time Series Split**\n",
    "   - æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å°‚ç”¨\n",
    "   - æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validationã®å®Ÿè£…\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cv_score(model, X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    K-Fold CVã§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X), 1):\n",
    "        X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # äºˆæ¸¬\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        \n",
    "        # è©•ä¾¡\n",
    "        fold_score = rmsle(y_fold_val, y_pred)\n",
    "        scores.append(fold_score)\n",
    "        \n",
    "        print(f\"Fold {fold}: RMSLE = {fold_score:.4f}\")\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "    \n",
    "    print(f\"\\nMean RMSLE: {mean_score:.4f} Â± {std_score:.4f}\")\n",
    "    \n",
    "    return mean_score, std_score, scores\n",
    "\n",
    "# LightGBMã§5-Fold CV\n",
    "print(\"=\" * 60)\n",
    "print(\"5-Fold Cross Validationï¼ˆLightGBMï¼‰\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lgb_cv = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=31,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "mean_cv, std_cv, fold_scores = cv_score(lgb_cv, X_enhanced, y_log, n_splits=5)\n",
    "\n",
    "# Foldåˆ¥ã®ã‚¹ã‚³ã‚¢ã‚’å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(1, 6), fold_scores, alpha=0.7, edgecolor='black', color='lightcoral')\n",
    "plt.axhline(mean_cv, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_cv:.4f}')\n",
    "plt.xlabel('Fold', fontsize=11)\n",
    "plt.ylabel('RMSLE', fontsize=11)\n",
    "plt.title('5-Fold Cross Validation Scores', fontsize=12, fontweight='bold')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ CVã®ãƒã‚¤ãƒ³ãƒˆ:\")\n",
    "print(\"- Foldé–“ã®ã°ã‚‰ã¤ããŒå°ã•ã„ â†’ å®‰å®šã—ãŸãƒ¢ãƒ‡ãƒ«\")\n",
    "print(\"- ã°ã‚‰ã¤ããŒå¤§ãã„ â†’ ãƒ‡ãƒ¼ã‚¿ã®åã‚Šã‚„ãƒ©ãƒ³ãƒ€ãƒ æ€§\")\n",
    "print(\"- Local CVã¨Public LBã®ç›¸é–¢ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒé‡è¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "\n",
    "### ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®ç¨®é¡\n",
    "\n",
    "1. **Averaging / Weighted Averaging**\n",
    "   - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å¹³å‡\n",
    "   - é‡ã¿ä»˜ã‘å¹³å‡ã§èª¿æ•´\n",
    "\n",
    "2. **Blending**\n",
    "   - Hold-outãƒ‡ãƒ¼ã‚¿ã§ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n",
    "   - ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿ\n",
    "\n",
    "3. **Stacking**\n",
    "   - Out-of-Foldäºˆæ¸¬ã§ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n",
    "   - ã‚ˆã‚Šé«˜åº¦ã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ã\n",
    "\n",
    "### ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®ã‚³ãƒ„\n",
    "\n",
    "- **å¤šæ§˜æ€§**: ç•°ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’çµ„ã¿åˆã‚ã›ã‚‹\n",
    "- **ç›¸é–¢**: äºˆæ¸¬ã®ç›¸é–¢ãŒä½ã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶\n",
    "- **å¼·ãƒ¢ãƒ‡ãƒ«**: å˜ä½“æ€§èƒ½ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "models = {}\n",
    "\n",
    "# LightGBM\n",
    "models['lgb'] = lgb.LGBMRegressor(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=6,\n",
    "    random_state=42, verbose=-1\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "models['xgb'] = xgb.XGBRegressor(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=6,\n",
    "    random_state=42, eval_metric='rmse'\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "models['rf'] = RandomForestRegressor(\n",
    "    n_estimators=200, max_depth=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ridge\n",
    "models['ridge'] = Ridge(alpha=10.0, random_state=42)\n",
    "\n",
    "# å„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨äºˆæ¸¬\n",
    "predictions = {}\n",
    "model_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_enh, y_train_enh)\n",
    "    y_pred = model.predict(X_test_enh)\n",
    "    predictions[name] = y_pred\n",
    "    \n",
    "    score = rmsle(y_test_enh, y_pred)\n",
    "    model_scores.append({'Model': name, 'RMSLE': score})\n",
    "    print(f\"{name} RMSLE: {score:.4f}\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚³ã‚¢ã®è¡¨ç¤º\n",
    "scores_df = pd.DataFrame(model_scores).sort_values('RMSLE')\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½\")\n",
    "print(\"=\" * 60)\n",
    "print(scores_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ã‚·ãƒ³ãƒ—ãƒ«ãªå¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "y_pred_avg = np.mean([predictions[name] for name in models.keys()], axis=0)\n",
    "rmsle_avg = rmsle(y_test_enh, y_pred_avg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Simple Average: {rmsle_avg:.4f}\")\n",
    "\n",
    "# 2. é‡ã¿ä»˜ãå¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "# æ€§èƒ½ã«å¿œã˜ãŸé‡ã¿ï¼ˆRMSLEã®é€†æ•°ï¼‰\n",
    "weights = {}\n",
    "for score_row in model_scores:\n",
    "    weights[score_row['Model']] = 1.0 / score_row['RMSLE']\n",
    "\n",
    "# æ­£è¦åŒ–\n",
    "total_weight = sum(weights.values())\n",
    "weights = {k: v/total_weight for k, v in weights.items()}\n",
    "\n",
    "print(\"\\né‡ã¿:\")\n",
    "for name, weight in weights.items():\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "# é‡ã¿ä»˜ãå¹³å‡\n",
    "y_pred_weighted = sum(predictions[name] * weights[name] for name in models.keys())\n",
    "rmsle_weighted = rmsle(y_test_enh, y_pred_weighted)\n",
    "\n",
    "print(f\"\\nWeighted Average: {rmsle_weighted:.4f}\")\n",
    "\n",
    "# æ¯”è¼ƒ\n",
    "ensemble_results = pd.DataFrame([\n",
    "    {'Method': 'Best Single Model', 'RMSLE': scores_df.iloc[0]['RMSLE']},\n",
    "    {'Method': 'Simple Average', 'RMSLE': rmsle_avg},\n",
    "    {'Method': 'Weighted Average', 'RMSLE': rmsle_weighted}\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¯”è¼ƒ\")\n",
    "print(\"=\" * 60)\n",
    "print(ensemble_results.to_string(index=False))\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(ensemble_results['Method'], ensemble_results['RMSLE'], \n",
    "         alpha=0.7, edgecolor='black', color=['lightgreen', 'skyblue', 'coral'])\n",
    "plt.xlabel('RMSLE', fontsize=11)\n",
    "plt.title('Ensemble Methods Comparison', fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "for i, row in ensemble_results.iterrows():\n",
    "    plt.text(row['RMSLE'], i, f\"{row['RMSLE']:.4f}\",\n",
    "            va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®åŠ¹æœ:\")\n",
    "print(\"- å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šå®‰å®š\")\n",
    "print(\"- å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§æ”¹å–„\")\n",
    "print(\"- Kaggleã®ä¸Šä½è§£æ³•ã§ã¯å¿…é ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å®Ÿå‹™ã§ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹\n",
    "\n",
    "### Kaggleæ”»ç•¥ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "```python\n",
    "# âœ… Kaggleå®Œå…¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "# Phase 1: æº–å‚™ï¼ˆé–‹å§‹1-2æ—¥ï¼‰\n",
    "# - ã‚³ãƒ³ãƒšã®ãƒ«ãƒ¼ãƒ«ã‚’èª­ã‚“ã ã‹ï¼Ÿ\n",
    "# - è©•ä¾¡æŒ‡æ¨™ã‚’ç†è§£ã—ãŸã‹ï¼Ÿ\n",
    "# - ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã‹ï¼Ÿ\n",
    "# - Public Notebooksã‚’ç¢ºèªã—ãŸã‹ï¼Ÿ\n",
    "\n",
    "# Phase 2: EDAï¼ˆ3-5æ—¥ï¼‰\n",
    "# - ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ã‚’æŠŠæ¡ã—ãŸã‹ï¼Ÿ\n",
    "# - æ¬ æå€¤ã€å¤–ã‚Œå€¤ã‚’ç¢ºèªã—ãŸã‹ï¼Ÿ\n",
    "# - ç›¸é–¢åˆ†æã‚’ã—ãŸã‹ï¼Ÿ\n",
    "# - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ã‚’èª¿ã¹ãŸã‹ï¼Ÿ\n",
    "\n",
    "# Phase 3: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆ1-2æ—¥ï¼‰\n",
    "# - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã§æå‡ºã—ãŸã‹ï¼Ÿ\n",
    "# - Local CVã¨Public LBã®ç›¸é–¢ã‚’ç¢ºèªã—ãŸã‹ï¼Ÿ\n",
    "# - ã‚µãƒ–ãƒŸãƒƒãƒˆã®æµã‚Œã‚’ç†è§£ã—ãŸã‹ï¼Ÿ\n",
    "\n",
    "# Phase 4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ10-20æ—¥ï¼‰\n",
    "# - ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸã‹ï¼Ÿ\n",
    "# - è¤‡æ•°ã®å¤‰æ›ã‚’è©¦ã—ãŸã‹ï¼Ÿ\n",
    "# - ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã—ãŸã‹ï¼Ÿ\n",
    "# - ç‰¹å¾´é‡é¸æŠã‚’ã—ãŸã‹ï¼Ÿ\n",
    "\n",
    "# Phase 5: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆ5-10æ—¥ï¼‰\n",
    "# - è¤‡æ•°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è©¦ã—ãŸã‹ï¼Ÿ\n",
    "# - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ãŸã‹ï¼Ÿ\n",
    "# - ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§è©•ä¾¡ã—ãŸã‹ï¼Ÿ\n",
    "# - éå­¦ç¿’ã‚’é˜²ã„ã ã‹ï¼Ÿ\n",
    "\n",
    "# Phase 6: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆ3-5æ—¥ï¼‰\n",
    "# - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸã‹ï¼Ÿ\n",
    "# - Stackingã‚’è©¦ã—ãŸã‹ï¼Ÿ\n",
    "# - æœ€çµ‚ã‚µãƒ–ãƒŸãƒƒãƒˆã‚’é¸ã‚“ã ã‹ï¼Ÿ\n",
    "\n",
    "# Phase 7: æœ€çµ‚èª¿æ•´ï¼ˆ1-2æ—¥ï¼‰\n",
    "# - ãƒ™ã‚¹ãƒˆã‚µãƒ–ãƒŸãƒƒãƒˆã‚’é¸æŠã—ãŸã‹ï¼Ÿ\n",
    "# - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ•´ç†ã—ãŸã‹ï¼Ÿ\n",
    "# - æŒ¯ã‚Šè¿”ã‚Šã‚’ã—ãŸã‹ï¼Ÿ\n",
    "```\n",
    "\n",
    "### ã‚ˆãã‚ã‚‹è½ã¨ã—ç©´\n",
    "\n",
    "1. **ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ãŒè¨“ç·´ã«æ··å…¥\n",
    "2. **éå­¦ç¿’**: CVã‚¹ã‚³ã‚¢ã¯è‰¯ã„ãŒLBãŒæ‚ªã„\n",
    "3. **Shake-up/down**: Public LBã¨Private LBã®ä¹–é›¢\n",
    "4. **æ™‚é–“é…åˆ†ãƒŸã‚¹**: æœ€å¾Œã«ç„¦ã‚‹\n",
    "5. **ã‚µãƒ–ãƒŸãƒƒãƒˆå¿˜ã‚Œ**: æœŸé™ã«é–“ã«åˆã‚ãªã„\n",
    "6. **CVæˆ¦ç•¥ãƒŸã‚¹**: Local CVã¨LBãŒç›¸é–¢ã—ãªã„\n",
    "\n",
    "### æ™‚é–“é…åˆ†ã®ä¾‹ï¼ˆ2ãƒ¶æœˆã‚³ãƒ³ãƒšï¼‰\n",
    "\n",
    "| ãƒ•ã‚§ãƒ¼ã‚º | æœŸé–“ | å‰²åˆ |\n",
    "|---------|------|------|\n",
    "| EDA | 3-5æ—¥ | 10% |\n",
    "| ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | 1-2æ—¥ | 5% |\n",
    "| ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° | 20-30æ—¥ | 50% |\n",
    "| ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ | 10-15æ—¥ | 25% |\n",
    "| ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« | 5-7æ—¥ | 10% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ã¾ã¨ã‚\n",
    "\n",
    "### æœ¬ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã‚“ã ã“ã¨\n",
    "\n",
    "1. **Kaggleã‚³ãƒ³ãƒšã®å…¨ä½“åƒ**\n",
    "   - ã‚³ãƒ³ãƒšã®æµã‚Œ\n",
    "   - ãƒ†ã‚£ã‚¢ã¨ãƒ¡ãƒ€ãƒ«\n",
    "   - æˆåŠŸã®å¿ƒæ§‹ãˆ\n",
    "\n",
    "2. **Phase 1: EDA**\n",
    "   - ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±\n",
    "   - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†æ\n",
    "   - æ¬ æå€¤ã¨å¤–ã‚Œå€¤\n",
    "   - ç›¸é–¢åˆ†æ\n",
    "\n",
    "3. **Phase 2: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**\n",
    "   - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é–‹å§‹\n",
    "   - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ\n",
    "   - åŸºæº–ç‚¹ã®è¨­å®š\n",
    "\n",
    "4. **Phase 3: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**\n",
    "   - ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ´»ç”¨\n",
    "   - ç‰¹å¾´é‡ã®å¤‰æ›ã¨çµ„ã¿åˆã‚ã›\n",
    "   - é›†ç´„ç‰¹å¾´é‡\n",
    "   - ç‰¹å¾´é‡é‡è¦åº¦ã®ç¢ºèª\n",
    "\n",
    "5. **Phase 4: æ¤œè¨¼æˆ¦ç•¥**\n",
    "   - K-Fold Cross Validation\n",
    "   - Stratified K-Fold\n",
    "   - Local CVã¨LBã®ç›¸é–¢\n",
    "\n",
    "6. **Phase 5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«**\n",
    "   - å¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "   - é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "   - Stackingï¼ˆæ¦‚å¿µï¼‰\n",
    "\n",
    "7. **å®Ÿå‹™ã§ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**\n",
    "   - å®Œå…¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "   - ã‚ˆãã‚ã‚‹è½ã¨ã—ç©´\n",
    "   - æ™‚é–“é…åˆ†\n",
    "\n",
    "### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ\n",
    "\n",
    "- âœ… **EDAã«æ™‚é–“ã‚’ã‹ã‘ã‚‹**: ãƒ‡ãƒ¼ã‚¿ç†è§£ãŒå…¨ã¦ã®åŸºç¤\n",
    "- âœ… **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æ—©ãä½œã‚‹**: ã‚µãƒ‹ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã¨åŸºæº–ç‚¹\n",
    "- âœ… **ç‰¹å¾´é‡ãŒ99%**: ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šç‰¹å¾´é‡ã«æ³¨åŠ›\n",
    "- âœ… **æ¤œè¨¼æˆ¦ç•¥ãŒé‡è¦**: Local CVã¨LBã®ç›¸é–¢ã‚’ç¢ºèª\n",
    "- âœ… **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§å®‰å®šåŒ–**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹\n",
    "- âœ… **è¨˜éŒ²ã‚’æ®‹ã™**: å®Ÿé¨“ãƒ­ã‚°ã‚’ä¸å¯§ã«\n",
    "- âœ… **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ´»ç”¨**: Discussionã§æƒ…å ±åé›†\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "- Notebook 28ã§ç·åˆæ¼”ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æŒ‘æˆ¦\n",
    "- å®Ÿéš›ã®Kaggleã‚³ãƒ³ãƒšã«å‚åŠ ï¼ˆTitanicã€House Pricesæ¨å¥¨ï¼‰\n",
    "- Public Notebooksã‹ã‚‰å­¦ã¶\n",
    "- Discussionã§è³ªå•ãƒ»æƒ…å ±å…±æœ‰\n",
    "- Grandmasterã®è§£æ³•ã‚’ç ”ç©¶\n",
    "\n",
    "### æ¨å¥¨ã‚³ãƒ³ãƒšï¼ˆåˆå¿ƒè€…å‘ã‘ï¼‰\n",
    "\n",
    "1. **Titanic**: åˆ†é¡å•é¡Œã®å®šç•ª\n",
    "2. **House Prices**: å›å¸°å•é¡Œã®å®šç•ª\n",
    "3. **Spaceship Titanic**: Titanicã®ç™ºå±•ç‰ˆ\n",
    "4. **Store Sales**: æ™‚ç³»åˆ—äºˆæ¸¬\n",
    "\n",
    "Kaggleã§å®Ÿè·µã‚’ç©ã¿ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚¹ã‚­ãƒ«ã‚’ç£¨ãã¾ã—ã‚‡ã†ï¼ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

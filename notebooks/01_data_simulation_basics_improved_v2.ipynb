{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. データシミュレーションの基礎 (Data Simulation Basics)\n",
    "\n",
    "## 概要\n",
    "機械学習の学習と実験に必要な合成データを生成する方法を学びます。\n",
    "\n",
    "## 学習目標\n",
    "- scikit-learnで様々な合成データを生成できる\n",
    "- データの特性（線形分離可能性、ノイズ）を理解できる\n",
    "- データを可視化して特徴を把握できる\n",
    "- 分類と回帰のデータ生成の違いを理解できる\n",
    "- カスタムデータセットを作成できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import (\n",
    "    make_classification, make_regression, make_moons, \n",
    "    make_circles, make_blobs, make_gaussian_quantiles\n",
    ")\n",
    "\n",
    "# 日本語フォント設定（必要に応じて）\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 乱数シード設定\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データシミュレーションの重要性\n",
    "\n",
    "### なぜデータをシミュレートするのか？\n",
    "\n",
    "実データを使う前にシミュレーションデータで練習することには、多くの利点があります：\n",
    "\n",
    "1. **学習段階での利用**\n",
    "   - 実際のデータ収集は時間とコストがかかる\n",
    "   - シミュレーションなら即座にデータを用意できる\n",
    "   - 様々なパターンのデータで実験できる\n",
    "\n",
    "2. **モデルの検証**\n",
    "   - 正解が分かっているデータでテストできる\n",
    "   - モデルの限界を確認できる\n",
    "   - バグの発見に役立つ\n",
    "\n",
    "3. **プロトタイプ開発**\n",
    "   - 実データが無くても開発を進められる\n",
    "   - データ構造の設計を先行できる\n",
    "   - デモやプレゼンテーションに使える\n",
    "\n",
    "### 実世界での応用\n",
    "\n",
    "- **製薬研究**: 薬の効果をシミュレーション\n",
    "- **金融工学**: 市場の動きをシミュレーション\n",
    "- **自動運転**: 様々な交通状況をシミュレーション\n",
    "- **気象予測**: 気候変動のシミュレーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 分類用データの生成\n",
    "\n",
    "### 分類問題とは\n",
    "\n",
    "分類問題は、データを複数のカテゴリー（クラス）に分ける問題です。\n",
    "\n",
    "#### 実例\n",
    "\n",
    "| 問題 | 入力 | 出力（クラス） |\n",
    "|------|------|---------------|\n",
    "| スパムメール判定 | メールの特徴 | スパム or 正常 |\n",
    "| 疾病診断 | 症状、検査結果 | 健康 or 疾病A or 疾病B |\n",
    "| 画像認識 | 画像のピクセル | 犬 or 猫 or 鳥 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_classificationによる基本的な分類データ生成\n",
    "X_basic, y_basic = make_classification(\n",
    "    n_samples=500,          # サンプル数\n",
    "    n_features=2,           # 特徴量数（2次元で可視化可能）\n",
    "    n_informative=2,        # 有用な特徴量数\n",
    "    n_redundant=0,          # 冗長な特徴量数\n",
    "    n_clusters_per_class=1, # クラスごとのクラスタ数\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# データの基本情報\n",
    "print(f\"データ形状: {X_basic.shape}\")\n",
    "print(f\"クラス数: {len(np.unique(y_basic))}\")\n",
    "print(f\"クラス分布: {np.bincount(y_basic)}\")\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_basic[:, 0], X_basic[:, 1], c=y_basic, cmap='RdYlBu', \n",
    "            edgecolors='black', s=50, alpha=0.7)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Basic Classification Data')\n",
    "plt.colorbar(label='Class')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_classificationのパラメータ解説\n",
    "\n",
    "#### 重要なパラメータ\n",
    "\n",
    "**n_samples（サンプル数）**\n",
    "- 生成するデータポイントの数\n",
    "- 推奨：特徴量数の10倍以上\n",
    "- 多すぎると計算時間が増加\n",
    "\n",
    "**n_features（特徴量数）**\n",
    "- データの次元数\n",
    "- 多すぎると「次元の呪い」が発生\n",
    "- 実務では10〜1000程度が多い\n",
    "\n",
    "**n_informative（有用な特徴量数）**\n",
    "- 実際にクラス分けに役立つ特徴量の数\n",
    "- 少なすぎると学習が難しい\n",
    "- n_features以下である必要がある\n",
    "\n",
    "**n_redundant（冗長な特徴量数）**\n",
    "- 他の特徴量の線形結合で表せる特徴量\n",
    "- 現実のデータには冗長性がよくある\n",
    "- モデルの頑健性をテストできる\n",
    "\n",
    "**n_clusters_per_class（クラスごとのクラスタ数）**\n",
    "- 各クラスがいくつのクラスタに分かれているか\n",
    "- 1なら単純、2以上なら複雑なパターン\n",
    "\n",
    "**class_sep（クラス間の分離度）**\n",
    "- 大きいほどクラスが明確に分離\n",
    "- 小さいほど分類が難しい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの効果を比較\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# クラス分離度の比較\n",
    "for idx, sep in enumerate([0.5, 1.0, 2.0]):\n",
    "    X, y = make_classification(\n",
    "        n_samples=500, n_features=2, n_informative=2,\n",
    "        n_redundant=0, n_clusters_per_class=1,\n",
    "        class_sep=sep, random_state=42\n",
    "    )\n",
    "    axes[0, idx].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                        edgecolors='black', s=30)\n",
    "    axes[0, idx].set_title(f'class_sep={sep}')\n",
    "    axes[0, idx].set_xlabel('Feature 1')\n",
    "    axes[0, idx].set_ylabel('Feature 2')\n",
    "\n",
    "# クラスタ数の比較\n",
    "for idx, n_clusters in enumerate([1, 2, 3]):\n",
    "    X, y = make_classification(\n",
    "        n_samples=500, n_features=2, n_informative=2,\n",
    "        n_redundant=0, n_clusters_per_class=n_clusters,\n",
    "        class_sep=1.0, random_state=42\n",
    "    )\n",
    "    axes[1, idx].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                        edgecolors='black', s=30)\n",
    "    axes[1, idx].set_title(f'n_clusters_per_class={n_clusters}')\n",
    "    axes[1, idx].set_xlabel('Feature 1')\n",
    "    axes[1, idx].set_ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 複雑なパターンの生成\n",
    "\n",
    "### 非線形分離可能なデータ\n",
    "\n",
    "現実世界の多くの問題は、単純な直線では分離できません。scikit-learnは、\n",
    "様々な複雑なパターンのデータを生成する関数を提供しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 様々なパターンのデータ生成\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Make Moons（月形状）\n",
    "X, y = make_moons(n_samples=500, noise=0.1, random_state=42)\n",
    "axes[0, 0].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                   edgecolors='black', s=30)\n",
    "axes[0, 0].set_title('Make Moons (noise=0.1)')\n",
    "\n",
    "# Make Moons（ノイズ大）\n",
    "X, y = make_moons(n_samples=500, noise=0.3, random_state=42)\n",
    "axes[0, 1].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                   edgecolors='black', s=30)\n",
    "axes[0, 1].set_title('Make Moons (noise=0.3)')\n",
    "\n",
    "# Make Circles（円形）\n",
    "X, y = make_circles(n_samples=500, noise=0.05, factor=0.5, random_state=42)\n",
    "axes[0, 2].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                   edgecolors='black', s=30)\n",
    "axes[0, 2].set_title('Make Circles')\n",
    "\n",
    "# Make Blobs（クラスタ）\n",
    "X, y = make_blobs(n_samples=500, centers=3, cluster_std=1.0, random_state=42)\n",
    "axes[1, 0].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                   edgecolors='black', s=30)\n",
    "axes[1, 0].set_title('Make Blobs (3 centers)')\n",
    "\n",
    "# Make Blobs（標準偏差変更）\n",
    "X, y = make_blobs(n_samples=500, centers=3, cluster_std=0.5, random_state=42)\n",
    "axes[1, 1].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                   edgecolors='black', s=30)\n",
    "axes[1, 1].set_title('Make Blobs (cluster_std=0.5)')\n",
    "\n",
    "# Make Gaussian Quantiles\n",
    "X, y = make_gaussian_quantiles(n_samples=500, n_features=2, n_classes=3, random_state=42)\n",
    "axes[1, 2].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                   edgecolors='black', s=30)\n",
    "axes[1, 2].set_title('Make Gaussian Quantiles')\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各データセットの特徴\n",
    "\n",
    "**make_moons**\n",
    "- 二つの半月形のクラス\n",
    "- 線形分離不可能\n",
    "- ニューラルネットワークやSVMのテストに最適\n",
    "\n",
    "**make_circles**\n",
    "- 同心円状のクラス\n",
    "- より複雑な非線形パターン\n",
    "- RBFカーネルSVMのデモに使用\n",
    "\n",
    "**make_blobs**\n",
    "- ガウス分布のクラスタ\n",
    "- 線形分離可能（適切なパラメータで）\n",
    "- クラスタリングアルゴリズムのテストに使用\n",
    "\n",
    "**make_gaussian_quantiles**\n",
    "- ガウス分布を分位数で分割\n",
    "- 複雑な境界を持つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 回帰用データの生成\n",
    "\n",
    "### 回帰問題とは\n",
    "\n",
    "回帰問題は、連続的な数値を予測する問題です。\n",
    "\n",
    "#### 分類と回帰の違い\n",
    "\n",
    "| 分類 | 回帰 |\n",
    "|------|------|\n",
    "| カテゴリーを予測 | 数値を予測 |\n",
    "| 例：犬 or 猫 | 例：価格、気温 |\n",
    "| 離散的 | 連続的 |\n",
    "| 評価：正解率 | 評価：誤差 |\n",
    "\n",
    "#### 実世界の回帰問題\n",
    "\n",
    "- **住宅価格予測**: 特徴（広さ、築年数）→ 価格\n",
    "- **売上予測**: 広告費、季節 → 売上額\n",
    "- **気温予測**: 湿度、風速 → 気温"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 様々なノイズレベルの回帰データ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# ノイズ小\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=10, random_state=42)\n",
    "axes[0, 0].scatter(X, y, alpha=0.6, edgecolors='black')\n",
    "axes[0, 0].set_title('Linear Regression (noise=10)')\n",
    "axes[0, 0].set_xlabel('X')\n",
    "axes[0, 0].set_ylabel('y')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ノイズ大\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=30, random_state=42)\n",
    "axes[0, 1].scatter(X, y, alpha=0.6, edgecolors='black')\n",
    "axes[0, 1].set_title('Linear Regression (noise=30)')\n",
    "axes[0, 1].set_xlabel('X')\n",
    "axes[0, 1].set_ylabel('y')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 非線形（正弦波）\n",
    "X = np.sort(5 * np.random.rand(200, 1), axis=0)\n",
    "y = np.sin(X).ravel() + np.random.randn(200) * 0.1\n",
    "axes[1, 0].scatter(X, y, alpha=0.6, edgecolors='black')\n",
    "axes[1, 0].set_title('Non-linear (Sine Wave)')\n",
    "axes[1, 0].set_xlabel('X')\n",
    "axes[1, 0].set_ylabel('y')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 非線形（多項式）\n",
    "X = np.sort(2 * np.random.rand(200, 1) - 1, axis=0)\n",
    "y = (X ** 3 + 0.5 * X ** 2 - X).ravel() + np.random.randn(200) * 0.1\n",
    "axes[1, 1].scatter(X, y, alpha=0.6, edgecolors='black')\n",
    "axes[1, 1].set_title('Polynomial (Cubic)')\n",
    "axes[1, 1].set_xlabel('X')\n",
    "axes[1, 1].set_ylabel('y')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノイズの影響\n",
    "\n",
    "ノイズは現実のデータに常に存在します：\n",
    "\n",
    "**ノイズの原因**\n",
    "- 測定誤差\n",
    "- 記録ミス\n",
    "- 予測不可能な要因\n",
    "- モデルに含まれていない変数の影響\n",
    "\n",
    "**ノイズが大きいと**\n",
    "- 予測精度が低下\n",
    "- より複雑なモデルが必要\n",
    "- 過学習のリスクが増加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 多クラス・高次元データ\n",
    "\n",
    "### 実世界の複雑なデータ\n",
    "\n",
    "実際の問題では、しばしば：\n",
    "- 3クラス以上の分類が必要\n",
    "- 数十〜数千の特徴量がある\n",
    "- 特徴量間に相関がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高次元多クラスデータの生成\n",
    "X_high, y_high = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_classes=4,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"データ形状: {X_high.shape}\")\n",
    "print(f\"クラス数: {len(np.unique(y_high))}\")\n",
    "print(f\"クラス分布: {np.bincount(y_high)}\")\n",
    "print(f\"\\n特徴量の統計:\")\n",
    "print(f\"  平均: {X_high.mean(axis=0)[:5]}\")\n",
    "print(f\"  標準偏差: {X_high.std(axis=0)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の分布を可視化\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    for cls in range(4):\n",
    "        axes[i].hist(X_high[y_high == cls, i], bins=20, alpha=0.5, \n",
    "                     label=f'Class {cls}')\n",
    "    axes[i].set_title(f'Feature {i}')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    if i == 0:\n",
    "        axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量間の相関行列\n",
    "df = pd.DataFrame(X_high, columns=[f'F{i}' for i in range(X_high.shape[1])])\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 強い相関を持つペアを表示\n",
    "print(\"\\n強い相関を持つ特徴量ペア（|r| > 0.7）:\")\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            print(f\"  {corr_matrix.columns[i]} - {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. カスタムデータセットの作成\n",
    "\n",
    "### 特定のパターンを持つデータ\n",
    "\n",
    "scikit-learnの関数では生成できない特殊なパターンが必要な場合、\n",
    "自分でデータ生成関数を作成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spiral_data(n_samples=500, noise=0.2):\n",
    "    \"\"\"\n",
    "    スパイラル（渦巻き）形状の分類データを生成\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        サンプル数\n",
    "    noise : float\n",
    "        ノイズの大きさ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : array, shape (n_samples, 2)\n",
    "        特徴量\n",
    "    y : array, shape (n_samples,)\n",
    "        クラスラベル\n",
    "    \"\"\"\n",
    "    n = n_samples // 2\n",
    "    \n",
    "    # 第1のスパイラル\n",
    "    theta1 = np.sqrt(np.random.rand(n)) * 2 * np.pi\n",
    "    r1 = 2 * theta1 + np.pi\n",
    "    x1 = r1 * np.cos(theta1) + np.random.randn(n) * noise\n",
    "    y1 = r1 * np.sin(theta1) + np.random.randn(n) * noise\n",
    "    \n",
    "    # 第2のスパイラル\n",
    "    theta2 = np.sqrt(np.random.rand(n)) * 2 * np.pi\n",
    "    r2 = -2 * theta2 - np.pi\n",
    "    x2 = r2 * np.cos(theta2) + np.random.randn(n) * noise\n",
    "    y2 = r2 * np.sin(theta2) + np.random.randn(n) * noise\n",
    "    \n",
    "    X = np.vstack([np.column_stack([x1, y1]), np.column_stack([x2, y2])])\n",
    "    y = np.hstack([np.zeros(n), np.ones(n)])\n",
    "    \n",
    "    return X, y.astype(int)\n",
    "\n",
    "def create_xor_data(n_samples=500, noise=0.1):\n",
    "    \"\"\"\n",
    "    XORパターンのデータを生成\n",
    "    \"\"\"\n",
    "    n = n_samples // 4\n",
    "    \n",
    "    # 4つの象限\n",
    "    X1 = np.random.randn(n, 2) * noise + [1, 1]\n",
    "    X2 = np.random.randn(n, 2) * noise + [-1, -1]\n",
    "    X3 = np.random.randn(n, 2) * noise + [1, -1]\n",
    "    X4 = np.random.randn(n, 2) * noise + [-1, 1]\n",
    "    \n",
    "    X = np.vstack([X1, X2, X3, X4])\n",
    "    y = np.hstack([np.zeros(n), np.zeros(n), np.ones(n), np.ones(n)])\n",
    "    \n",
    "    return X, y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムデータセットの可視化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# スパイラルデータ\n",
    "X_spiral, y_spiral = create_spiral_data(n_samples=500, noise=0.2)\n",
    "axes[0].scatter(X_spiral[:, 0], X_spiral[:, 1], c=y_spiral, cmap='RdYlBu', \n",
    "                edgecolors='black', s=30)\n",
    "axes[0].set_title('Spiral Dataset')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XORデータ\n",
    "X_xor, y_xor = create_xor_data(n_samples=500, noise=0.3)\n",
    "axes[1].scatter(X_xor[:, 0], X_xor[:, 1], c=y_xor, cmap='RdYlBu', \n",
    "                edgecolors='black', s=30)\n",
    "axes[1].set_title('XOR Dataset')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"これらのパターンは線形分離不可能です。\")\n",
    "print(\"ニューラルネットワークや非線形SVMが必要です。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ベストプラクティス\n",
    "\n",
    "### データ生成時の推奨事項\n",
    "\n",
    "1. **random_stateを設定する**\n",
    "   - 再現性のために必須\n",
    "   - デバッグが容易になる\n",
    "\n",
    "2. **適切なサンプル数を選ぶ**\n",
    "   - 少なすぎ：学習が不安定\n",
    "   - 多すぎ：計算時間の無駄\n",
    "   - 推奨：特徴量数の10〜100倍\n",
    "\n",
    "3. **データを必ず可視化する**\n",
    "   - パターンの確認\n",
    "   - 異常値の検出\n",
    "   - 問題の理解\n",
    "\n",
    "4. **適切なノイズレベルを設定**\n",
    "   - 現実的な難易度に設定\n",
    "   - ノイズなしは非現実的\n",
    "   - ノイズ大きすぎは学習不可能\n",
    "\n",
    "5. **問題の難易度を調整**\n",
    "   - 学習段階：簡単なデータから始める\n",
    "   - テスト段階：難しいデータで検証\n",
    "   - 本番前：様々な難易度で評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベストプラクティスの実践例\n",
    "def generate_dataset_for_learning(difficulty='easy'):\n",
    "    \"\"\"\n",
    "    学習目的に応じた適切なデータセットを生成\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    difficulty : str\n",
    "        'easy', 'medium', 'hard'\n",
    "    \"\"\"\n",
    "    if difficulty == 'easy':\n",
    "        X, y = make_classification(\n",
    "            n_samples=500,\n",
    "            n_features=2,\n",
    "            n_informative=2,\n",
    "            n_redundant=0,\n",
    "            n_clusters_per_class=1,\n",
    "            class_sep=2.0,\n",
    "            random_state=42\n",
    "        )\n",
    "    elif difficulty == 'medium':\n",
    "        X, y = make_classification(\n",
    "            n_samples=500,\n",
    "            n_features=10,\n",
    "            n_informative=5,\n",
    "            n_redundant=3,\n",
    "            n_clusters_per_class=2,\n",
    "            class_sep=1.0,\n",
    "            random_state=42\n",
    "        )\n",
    "    else:  # hard\n",
    "        X, y = create_spiral_data(n_samples=500, noise=0.3)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# 3つの難易度のデータを可視化\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "difficulties = ['easy', 'medium', 'hard']\n",
    "\n",
    "for idx, diff in enumerate(difficulties):\n",
    "    X, y = generate_dataset_for_learning(diff)\n",
    "    if X.shape[1] == 2:\n",
    "        axes[idx].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                         edgecolors='black', s=30)\n",
    "    else:\n",
    "        # 高次元の場合、最初の2次元のみ表示\n",
    "        axes[idx].scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', \n",
    "                         edgecolors='black', s=30)\n",
    "    axes[idx].set_title(f'{diff.capitalize()} Dataset')\n",
    "    axes[idx].set_xlabel('Feature 1')\n",
    "    axes[idx].set_ylabel('Feature 2')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. まとめ\n",
    "\n",
    "### 本ノートブックで学んだこと\n",
    "\n",
    "1. **データシミュレーションの重要性**\n",
    "   - 学習、検証、プロトタイプ開発での活用\n",
    "   - 実データ収集前の実験\n",
    "\n",
    "2. **分類データの生成**\n",
    "   - make_classificationの使い方\n",
    "   - パラメータの影響\n",
    "   - 複雑なパターン（moons, circles, blobs）\n",
    "\n",
    "3. **回帰データの生成**\n",
    "   - make_regressionの使い方\n",
    "   - ノイズの影響\n",
    "   - 線形と非線形の関係\n",
    "\n",
    "4. **高次元・多クラスデータ**\n",
    "   - 複雑なデータの生成\n",
    "   - 特徴量間の相関\n",
    "   - 可視化の工夫\n",
    "\n",
    "5. **カスタムデータセット**\n",
    "   - 独自のパターンの作成\n",
    "   - スパイラル、XORなどの非線形パターン\n",
    "\n",
    "6. **ベストプラクティス**\n",
    "   - 再現性の確保\n",
    "   - 適切なサンプル数とノイズレベル\n",
    "   - 可視化の重要性\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "- Notebook 02で、生成したデータの前処理を学ぶ\n",
    "- Notebook 03で、モデルの評価方法を学ぶ\n",
    "- 実際の機械学習モデルで生成したデータを使って実験"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

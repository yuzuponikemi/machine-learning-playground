{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ノートブック10: 自動ハイパーパラメータチューニング\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このノートブックでは、機械学習モデルのハイパーパラメータを体系的に最適化する手法を学びます:\n",
    "\n",
    "1. **ハイパーパラメータとは**\n",
    "   - モデルパラメータとの違い\n",
    "   - 重要なハイパーパラメータの理解\n",
    "\n",
    "2. **GridSearchCV**\n",
    "   - 網羅的探索の仕組み\n",
    "   - 計算コストとトレードオフ\n",
    "   - 結果の分析と可視化\n",
    "\n",
    "3. **RandomizedSearchCV**\n",
    "   - 確率的サンプリング\n",
    "   - 連続分布の活用\n",
    "   - 大規模パラメータ空間への対応\n",
    "\n",
    "4. **複数の評価指標**\n",
    "   - マルチメトリック最適化\n",
    "   - メトリック間のトレードオフ\n",
    "\n",
    "5. **実践的な戦略**\n",
    "   - 段階的チューニング\n",
    "   - ベストプラクティス\n",
    "   - 計算効率の向上\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import uniform, loguniform, randint\n",
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, RandomizedSearchCV,\n",
    "    cross_val_score, StratifiedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ハイパーパラメータとは\n",
    "\n",
    "### パラメータ vs ハイパーパラメータ\n",
    "\n",
    "- **パラメータ**: 訓練中に学習される値 (例: 重み、バイアス)\n",
    "- **ハイパーパラメータ**: 訓練前に設定する値 (例: 学習率、正則化係数)\n",
    "\n",
    "### なぜチューニングが重要か\n",
    "\n",
    "1. モデルの性能を大きく左右\n",
    "2. 過学習と未学習のバランス\n",
    "3. 収束速度と安定性\n",
    "\n",
    "### 主要なハイパーパラメータ\n",
    "\n",
    "**MLP:**\n",
    "- `hidden_layer_sizes`: ネットワーク構造\n",
    "- `alpha`: L2正則化係数\n",
    "- `learning_rate_init`: 学習率\n",
    "\n",
    "**Random Forest:**\n",
    "- `n_estimators`: 木の数\n",
    "- `max_depth`: 木の深さ\n",
    "- `min_samples_split`: 分割の最小サンプル数\n",
    "\n",
    "**SVM:**\n",
    "- `C`: ペナルティパラメータ\n",
    "- `gamma`: カーネル係数\n",
    "- `kernel`: カーネル関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの準備\n",
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=3,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. GridSearchCV: 網羅的探索\n",
    "\n",
    "GridSearchCVは、指定されたパラメータグリッドのすべての組み合わせを試します。\n",
    "\n",
    "### 利点\n",
    "- すべての組み合わせを確実に評価\n",
    "- 再現性が高い\n",
    "- パラメータ間の相互作用を理解\n",
    "\n",
    "### 欠点\n",
    "- 計算コストが高い (組み合わせ爆発)\n",
    "- パラメータ数が多いと非現実的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPのパラメータグリッド\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# 組み合わせ数の計算\n",
    "total_combinations = 1\n",
    "for param, values in param_grid_mlp.items():\n",
    "    total_combinations *= len(values)\n",
    "    print(f\"{param}: {len(values)} options\")\n",
    "\n",
    "print(f\"\\nTotal combinations: {total_combinations}\")\n",
    "print(f\"With 5-fold CV: {total_combinations * 5} model fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCVの実行\n",
    "mlp = MLPClassifier(\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid_mlp,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Starting GridSearchCV...\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRID SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {grid_search.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の詳細分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をDataFrameに変換\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Top 10の組み合わせ\n",
    "cols = ['param_hidden_layer_sizes', 'param_activation', 'param_alpha',\n",
    "        'param_learning_rate_init', 'mean_test_score', 'std_test_score',\n",
    "        'mean_train_score', 'rank_test_score']\n",
    "top_results = results_df[cols].sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\nTop 10 Parameter Combinations:\")\n",
    "print(top_results.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータ効果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch結果の包括的な可視化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. アーキテクチャの影響\n",
    "arch_results = results_df.groupby('param_hidden_layer_sizes')['mean_test_score'].agg(['mean', 'std'])\n",
    "arch_labels = [str(a) for a in arch_results.index]\n",
    "axes[0, 0].bar(arch_labels, arch_results['mean'], yerr=arch_results['std'], alpha=0.7, capsize=5)\n",
    "axes[0, 0].set_xlabel('Architecture', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Mean CV Accuracy', fontsize=11)\n",
    "axes[0, 0].set_title('Effect of Architecture', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. 活性化関数の影響\n",
    "act_results = results_df.groupby('param_activation')['mean_test_score'].agg(['mean', 'std'])\n",
    "axes[0, 1].bar(act_results.index, act_results['mean'], yerr=act_results['std'], alpha=0.7, capsize=5)\n",
    "axes[0, 1].set_xlabel('Activation Function', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Mean CV Accuracy', fontsize=11)\n",
    "axes[0, 1].set_title('Effect of Activation Function', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Alphaの影響\n",
    "alpha_results = results_df.groupby('param_alpha')['mean_test_score'].agg(['mean', 'std'])\n",
    "axes[1, 0].errorbar(range(len(alpha_results)), alpha_results['mean'],\n",
    "                    yerr=alpha_results['std'], marker='o', markersize=8, capsize=5, linewidth=2)\n",
    "axes[1, 0].set_xticks(range(len(alpha_results)))\n",
    "axes[1, 0].set_xticklabels([f'{a:.4f}' for a in alpha_results.index])\n",
    "axes[1, 0].set_xlabel('Alpha (L2 Regularization)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Mean CV Accuracy', fontsize=11)\n",
    "axes[1, 0].set_title('Effect of Regularization', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Train vs Test (過学習の検出)\n",
    "axes[1, 1].scatter(results_df['mean_train_score'], results_df['mean_test_score'], \n",
    "                   alpha=0.6, s=50)\n",
    "axes[1, 1].plot([0.8, 1], [0.8, 1], 'r--', lw=2, label='Perfect fit')\n",
    "axes[1, 1].set_xlabel('Mean Train Score', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Mean Test Score', fontsize=11)\n",
    "axes[1, 1].set_title('Train vs Test Score (Overfitting Detection)', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Points far from the diagonal line indicate overfitting\")\n",
    "print(\"- Look for parameters with low variance (more stable)\")\n",
    "print(\"- Balance between performance and complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. RandomizedSearchCV: 効率的な探索\n",
    "\n",
    "大規模なパラメータ空間では、RandomizedSearchCVが効率的です。\n",
    "\n",
    "### 利点\n",
    "- 連続分布からサンプリング可能\n",
    "- 計算時間を制御しやすい\n",
    "- 意外な良い組み合わせを発見できる\n",
    "\n",
    "### 確率分布の活用\n",
    "- `uniform(a, b)`: 一様分布\n",
    "- `loguniform(a, b)`: 対数一様分布 (学習率などに適切)\n",
    "- `randint(a, b)`: 整数の一様分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連続分布を使ったパラメータ定義\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (50,), (100,), (200,),\n",
    "        (50, 25), (100, 50), (200, 100),\n",
    "        (100, 50, 25), (200, 100, 50)\n",
    "    ],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': loguniform(1e-5, 1e-1),  # 対数スケール\n",
    "    'learning_rate_init': loguniform(1e-4, 1e-1),\n",
    "    'batch_size': [32, 64, 128, 256]\n",
    "}\n",
    "\n",
    "print(\"Parameter Distributions:\")\n",
    "print(\"=\"*60)\n",
    "for param, dist in param_distributions.items():\n",
    "    if isinstance(dist, list):\n",
    "        print(f\"{param}: {len(dist)} discrete options\")\n",
    "    else:\n",
    "        print(f\"{param}: Continuous distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCVの実行\n",
    "mlp_random = MLPClassifier(\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    mlp_random,\n",
    "    param_distributions,\n",
    "    n_iter=50,  # サンプル数\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Starting RandomizedSearchCV (50 iterations)...\")\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOMIZED SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest CV Score: {random_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {random_search.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {param}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchの探索パターン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプリングされたパラメータの分布\n",
    "random_results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Alpha のサンプリング分布\n",
    "axes[0].scatter(random_results['param_alpha'], random_results['mean_test_score'], \n",
    "                alpha=0.6, s=80)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Alpha (log scale)', fontsize=11)\n",
    "axes[0].set_ylabel('CV Accuracy', fontsize=11)\n",
    "axes[0].set_title('Random Search: Alpha vs Performance', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate のサンプリング分布\n",
    "axes[1].scatter(random_results['param_learning_rate_init'], random_results['mean_test_score'],\n",
    "                alpha=0.6, s=80, color='orange')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Learning Rate (log scale)', fontsize=11)\n",
    "axes[1].set_ylabel('CV Accuracy', fontsize=11)\n",
    "axes[1].set_title('Random Search: LR vs Performance', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Wide exploration of parameter space\")\n",
    "print(\"- Log-uniform sampling for learning rate and alpha\")\n",
    "print(\"- Can find good regions efficiently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 複数モデルのチューニング\n",
    "\n",
    "異なるモデルで最適なハイパーパラメータを探索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forestのチューニング\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Tuning Random Forest...\")\n",
    "rf_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nRandom Forest Best CV Score: {rf_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {rf_search.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in rf_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVMのチューニング\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "svm_search = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    svm_param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTuning SVM...\")\n",
    "svm_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nSVM Best CV Score: {svm_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {svm_search.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in svm_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チューニング済みモデルの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべてのチューニング済みモデルを比較\n",
    "tuned_models = {\n",
    "    'MLP (Grid)': grid_search.best_estimator_,\n",
    "    'MLP (Random)': random_search.best_estimator_,\n",
    "    'Random Forest': rf_search.best_estimator_,\n",
    "    'SVM': svm_search.best_estimator_\n",
    "}\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Model': name,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std(),\n",
    "        'Test Score': test_score\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_results).sort_values('Test Score', ascending=False)\n",
    "\n",
    "print(\"\\nTuned Model Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(df_comparison))\n",
    "plt.bar(x, df_comparison['CV Mean'], yerr=df_comparison['CV Std'], \n",
    "        alpha=0.7, capsize=5, label='CV Mean')\n",
    "plt.scatter(x, df_comparison['Test Score'], color='red', s=100, \n",
    "            zorder=5, label='Test Score', marker='D')\n",
    "plt.xticks(x, df_comparison['Model'], rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Comparison of Tuned Models', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. マルチメトリック最適化\n",
    "\n",
    "複数の評価指標を同時に考慮します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数の評価指標を定義\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision_macro',\n",
    "    'recall': 'recall_macro',\n",
    "    'f1': 'f1_macro'\n",
    "}\n",
    "\n",
    "param_grid_multi = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "mlp_multi = MLPClassifier(\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "multi_search = GridSearchCV(\n",
    "    mlp_multi,\n",
    "    param_grid_multi,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='f1',  # F1スコアで最良モデルを選択\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Running multi-metric search...\")\n",
    "multi_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nMulti-metric Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "multi_results = pd.DataFrame(multi_search.cv_results_)\n",
    "for metric in scoring.keys():\n",
    "    best_idx = multi_results[f'mean_test_{metric}'].idxmax()\n",
    "    best_score = multi_results.loc[best_idx, f'mean_test_{metric}']  \n",
    "    best_params = multi_results.loc[best_idx, 'params']\n",
    "    print(f\"\\nBest {metric.upper()}:\")\n",
    "    print(f\"  Score: {best_score:.4f}\")\n",
    "    print(f\"  Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 実践的なチューニング戦略\n",
    "\n",
    "### 段階的アプローチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hyperparameter Tuning Strategy:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"PHASE 1: COARSE SEARCH\")\n",
    "print(\"  • Wide parameter ranges\")\n",
    "print(\"  • Few CV folds (3-fold)\")\n",
    "print(\"  • Identify promising regions\")\n",
    "print(\"  • Example: alpha in [0.0001, 0.01, 1]\")\n",
    "print()\n",
    "print(\"PHASE 2: REFINED SEARCH\")\n",
    "print(\"  • Narrow ranges around best values\")\n",
    "print(\"  • More CV folds (5-fold)\")\n",
    "print(\"  • Denser grid\")\n",
    "print(\"  • Example: alpha in [0.001, 0.005, 0.01, 0.05]\")\n",
    "print()\n",
    "print(\"PHASE 3: FINE-TUNING\")\n",
    "print(\"  • Very narrow ranges\")\n",
    "print(\"  • Full CV (10-fold)\")\n",
    "print(\"  • Final optimization\")\n",
    "print()\n",
    "print(\"BEST PRACTICES:\")\n",
    "print(\"  ✓ Start simple, increase complexity\")\n",
    "print(\"  ✓ Use RandomizedSearchCV for initial exploration\")\n",
    "print(\"  ✓ GridSearchCV for final refinement\")\n",
    "print(\"  ✓ Monitor train/test gap for overfitting\")\n",
    "print(\"  ✓ Use log-uniform for learning rates\")\n",
    "print(\"  ✓ Consider computational budget\")\n",
    "print(\"  ✓ Document all experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## まとめ\n",
    "\n",
    "### ハイパーパラメータチューニングの要点\n",
    "\n",
    "1. **GridSearchCV**\n",
    "   - すべての組み合わせを試す\n",
    "   - 小規模パラメータ空間に最適\n",
    "   - 再現性が高い\n",
    "\n",
    "2. **RandomizedSearchCV**\n",
    "   - 確率的サンプリング\n",
    "   - 大規模空間に効率的\n",
    "   - 連続分布を活用\n",
    "\n",
    "3. **戦略**\n",
    "   - 粗い探索 → 精密化\n",
    "   - Random → Grid\n",
    "   - 計算コストを考慮\n",
    "\n",
    "4. **評価**\n",
    "   - 複数の指標を確認\n",
    "   - 過学習に注意\n",
    "   - クロスバリデーションが必須\n",
    "\n",
    "### 重要なポイント\n",
    "\n",
    "- **ドメイン知識**: パラメータの意味を理解する\n",
    "- **計算効率**: `n_jobs=-1`で並列化\n",
    "- **再現性**: `random_state`を固定\n",
    "- **文書化**: 実験を記録する\n",
    "\n",
    "---\n",
    "\n",
    "**次のステップ**: ノートブック11で、複数のモデルを体系的に比較し、最適なモデルを選択します!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

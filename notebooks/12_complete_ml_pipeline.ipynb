{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 12: Complete ML Pipeline\n",
    "\n",
    "End-to-end machine learning workflow.\n",
    "\n",
    "## Learning Objectives\n",
    "- Build complete ML pipelines\n",
    "- Combine preprocessing and modeling\n",
    "- Save and load models\n",
    "- Deploy-ready code structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    roc_curve, roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_features=20,\n",
    "    n_informative=12,\n",
    "    n_redundant=4,\n",
    "    n_classes=2,\n",
    "    weights=[0.7, 0.3],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\\n{df['target'].value_counts()}\")\n",
    "print(f\"\\nFeature statistics:\\n{df.describe().T.head()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Target distribution\n",
    "df['target'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Target Distribution')\n",
    "axes[0].set_xlabel('Class')\n",
    "\n",
    "# Feature correlations with target\n",
    "correlations = df.corr()['target'].drop('target').sort_values()\n",
    "correlations.plot(kind='barh', ax=axes[1])\n",
    "axes[1].set_title('Feature Correlations with Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining class distribution:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Pipeline steps:\")\n",
    "for name, step in pipeline.steps:\n",
    "    print(f\"  {name}: {step.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation on pipeline\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Hyperparameter Tuning with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid (note: prefix with step name)\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "    'classifier__learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_prob = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Final Model Evaluation:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(f\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "axes[1].plot(fpr, tpr, 'b-', lw=2, label=f'ROC (AUC = {auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complete pipeline\n",
    "model_filename = 'best_mlp_pipeline.joblib'\n",
    "joblib.dump(best_pipeline, model_filename)\n",
    "print(f\"Model saved to: {model_filename}\")\n",
    "\n",
    "# Load and verify\n",
    "loaded_pipeline = joblib.load(model_filename)\n",
    "loaded_score = loaded_pipeline.score(X_test, y_test)\n",
    "print(f\"Loaded model test score: {loaded_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Production-Ready Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_data(model_path, new_data):\n",
    "    \"\"\"\n",
    "    Load model and make predictions on new data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_path : str\n",
    "        Path to saved model\n",
    "    new_data : array-like\n",
    "        New samples to predict\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : array\n",
    "        Class predictions\n",
    "    probabilities : array\n",
    "        Class probabilities\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # Convert to DataFrame if needed\n",
    "    if not isinstance(new_data, pd.DataFrame):\n",
    "        new_data = pd.DataFrame(new_data, columns=feature_names)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(new_data)\n",
    "    probabilities = model.predict_proba(new_data)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "# Test with sample data\n",
    "sample = X_test.iloc[:5]\n",
    "preds, probs = predict_new_data(model_filename, sample)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "for i, (pred, prob) in enumerate(zip(preds, probs)):\n",
    "    print(f\"  Sample {i}: Class {pred}, Prob: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Complete Workflow Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete ML Pipeline Workflow:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"1. DATA LOADING\")\n",
    "print(\"   • Load data from source\")\n",
    "print(\"   • Initial exploration and visualization\")\n",
    "print(\"   • Check for missing values and outliers\")\n",
    "print()\n",
    "print(\"2. DATA SPLITTING\")\n",
    "print(\"   • Train/test split (80/20 typical)\")\n",
    "print(\"   • Stratify for imbalanced classes\")\n",
    "print(\"   • Keep test set untouched until final evaluation\")\n",
    "print()\n",
    "print(\"3. PIPELINE CONSTRUCTION\")\n",
    "print(\"   • Preprocessing (scaling, encoding)\")\n",
    "print(\"   • Feature selection (optional)\")\n",
    "print(\"   • Model\")\n",
    "print()\n",
    "print(\"4. HYPERPARAMETER TUNING\")\n",
    "print(\"   • GridSearchCV or RandomizedSearchCV\")\n",
    "print(\"   • Cross-validation\")\n",
    "print(\"   • Select best parameters\")\n",
    "print()\n",
    "print(\"5. FINAL EVALUATION\")\n",
    "print(\"   • Test set performance\")\n",
    "print(\"   • Multiple metrics\")\n",
    "print(\"   • Confusion matrix and ROC curve\")\n",
    "print()\n",
    "print(\"6. MODEL PERSISTENCE\")\n",
    "print(\"   • Save with joblib\")\n",
    "print(\"   • Version control model artifacts\")\n",
    "print(\"   • Document model parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the ML Learning curriculum.\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "**Foundations (Notebooks 1-3)**\n",
    "- Data simulation and generation\n",
    "- Preprocessing and feature engineering\n",
    "- Model evaluation metrics\n",
    "\n",
    "**Classical Models (Notebooks 4-6)**\n",
    "- Linear models and regularization\n",
    "- Tree and ensemble methods\n",
    "- SVM and kernel methods\n",
    "\n",
    "**Neural Networks (Notebooks 7-9)**\n",
    "- MLP fundamentals\n",
    "- Hyperparameter space exploration\n",
    "- Waveform prediction with regression\n",
    "\n",
    "**Advanced Topics (Notebooks 10-12)**\n",
    "- Automated hyperparameter tuning\n",
    "- Model comparison and selection\n",
    "- Complete ML pipelines\n",
    "\n",
    "### Next Steps\n",
    "1. Apply these techniques to real datasets\n",
    "2. Explore deep learning (TensorFlow/PyTorch)\n",
    "3. Learn specialized domains (NLP, Computer Vision)\n",
    "4. Study MLOps and model deployment\n",
    "\n",
    "### Resources\n",
    "- scikit-learn documentation: https://scikit-learn.org\n",
    "- Kaggle competitions for practice\n",
    "- UCI ML Repository for datasets\n",
    "\n",
    "Happy Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

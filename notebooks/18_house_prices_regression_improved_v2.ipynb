{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯18: House Priceså›å¸° - GBDTå›å¸°ã®å®Œå…¨ãƒã‚¹ã‚¿ãƒ¼ ğŸ \n",
    "\n",
    "**å­¦ç¿’ç›®æ¨™**: Kaggle House Pricesã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§Top 20%ï¼ˆRMSLE < 0.13ï¼‰ã‚’é”æˆ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã¶ã“ã¨\n",
    "\n",
    "### 1. å›å¸°ç‰¹æœ‰ã®èª²é¡Œ â­â­â­\n",
    "- Target transformationï¼ˆå¯¾æ•°å¤‰æ›ã€Box-Coxå¤‰æ›ï¼‰\n",
    "- Outlier detectionï¼ˆIsolationForestã€Z-scoreï¼‰\n",
    "- Skewness correctionï¼ˆæ­ªåº¦ã®è£œæ­£ï¼‰\n",
    "- Heavy-tailed distributionsï¼ˆè£¾ã®é‡ã„åˆ†å¸ƒï¼‰\n",
    "\n",
    "### 2. å¤§è¦æ¨¡ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â­â­â­\n",
    "- 200+ç‰¹å¾´é‡ã®ä½œæˆ\n",
    "- Polynomial featuresï¼ˆå¤šé …å¼ç‰¹å¾´é‡ï¼‰\n",
    "- Target encodingï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰\n",
    "- Feature selectionï¼ˆç‰¹å¾´é‡é¸æŠï¼‰\n",
    "\n",
    "### 3. GBDTå›å¸°ãƒ¢ãƒ‡ãƒªãƒ³ã‚° â­â­â­\n",
    "- Objective functions: RMSE, MAE, Huber\n",
    "- Quantile regressionï¼ˆåˆ†ä½ç‚¹å›å¸°ï¼‰\n",
    "- Feature interactions in trees\n",
    "\n",
    "### 4. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨è¨ºæ–­ â­â­\n",
    "- RMSLEï¼ˆRoot Mean Squared Log Errorï¼‰\n",
    "- Residual analysisï¼ˆæ®‹å·®åˆ†æï¼‰\n",
    "- Prediction interval estimation\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ç›®æ¨™ã‚¹ã‚³ã‚¢\n",
    "\n",
    "- **Local CV RMSLE**: 0.12-0.13\n",
    "- **Public LB RMSLE**: < 0.13 (Top 20%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# æ©Ÿæ¢°å­¦ç¿’\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# GBDT\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# è¨­å®š\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨åŸºæœ¬çš„ãªEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "data_dir = Path('../data/house_prices')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    train = pd.read_csv(data_dir / 'train.csv')\n",
    "    test = pd.read_csv(data_dir / 'test.csv')\n",
    "    print(\"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ ãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã«ã¯Kaggleã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¿…è¦ï¼‰\")\n",
    "    # ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression(n_samples=1460, n_features=80, n_informative=60, \n",
    "                           noise=10, random_state=42)\n",
    "    train = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(80)])\n",
    "    train['SalePrice'] = np.exp(y / 100) * 100000  # ä¾¡æ ¼ã‚’ãƒªã‚¢ãƒ«ã«\n",
    "    train['Id'] = range(1, 1461)\n",
    "    test = pd.DataFrame(X[:1459], columns=[f'feature_{i}' for i in range(80)])\n",
    "    test['Id'] = range(1461, 2920)\n",
    "\n",
    "print(f\"\\nTrain shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "if 'SalePrice' in train.columns:\n",
    "    print(f\"\\nğŸ  ä¾¡æ ¼çµ±è¨ˆ:\")\n",
    "    print(train['SalePrice'].describe())\n",
    "    \n",
    "    # ä¾¡æ ¼ã®åˆ†å¸ƒ\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    sns.histplot(train['SalePrice'], kde=True, ax=axes[0])\n",
    "    axes[0].set_title('Sale Price Distribution')\n",
    "    axes[0].set_xlabel('Price')\n",
    "    \n",
    "    stats.probplot(train['SalePrice'], plot=axes[1])\n",
    "    axes[1].set_title('Q-Q Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ­ªåº¦ã¨å°–åº¦\n",
    "    print(f\"\\nSkewness: {skew(train['SalePrice']):.4f}\")\n",
    "    print(f\"Kurtosis: {kurtosis(train['SalePrice']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¨ 2. Target Transformationï¼ˆå¯¾æ•°å¤‰æ›ï¼‰ â­â­â­\n",
    "\n",
    "ä¾¡æ ¼ã¯å¯¾æ•°æ­£è¦åˆ†å¸ƒã«å¾“ã†ã“ã¨ãŒå¤šã„ãŸã‚ã€å¯¾æ•°å¤‰æ›ã‚’é©ç”¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'SalePrice' in train.columns:\n",
    "    # å…ƒã®ä¾¡æ ¼ã‚’ä¿å­˜\n",
    "    train['SalePrice_original'] = train['SalePrice']\n",
    "    \n",
    "    # å¯¾æ•°å¤‰æ›\n",
    "    train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "    \n",
    "    print(\"âœ… Target transformationå®Œäº†\")\n",
    "    print(f\"å¤‰æ›å‰ - Skewness: {skew(train['SalePrice_original']):.4f}\")\n",
    "    print(f\"å¤‰æ›å¾Œ - Skewness: {skew(train['SalePrice']):.4f}\")\n",
    "    \n",
    "    # å¤‰æ›å¾Œã®åˆ†å¸ƒ\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    sns.histplot(train['SalePrice'], kde=True, ax=ax)\n",
    "    ax.set_title('Log-Transformed Sale Price')\n",
    "    ax.set_xlabel('log(Price)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 3. Outlier Detectionï¼ˆå¤–ã‚Œå€¤æ¤œå‡ºï¼‰ â­â­â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_isolation_forest(df, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Isolation Forestã§å¤–ã‚Œå€¤ã‚’æ¤œå‡º\n",
    "    \"\"\"\n",
    "    # æ•°å€¤ã‚«ãƒ©ãƒ ã®ã¿\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹\n",
    "    df_numeric = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "    \n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=RANDOM_STATE)\n",
    "    outliers = iso_forest.fit_predict(df_numeric)\n",
    "    \n",
    "    return outliers == -1\n",
    "\n",
    "# å¤–ã‚Œå€¤æ¤œå‡º\n",
    "outliers = detect_outliers_isolation_forest(train, contamination=0.05)\n",
    "print(f\"æ¤œå‡ºã•ã‚ŒãŸå¤–ã‚Œå€¤: {outliers.sum()} ä»¶ ({outliers.sum()/len(train)*100:.2f}%)\")\n",
    "\n",
    "# å¤–ã‚Œå€¤ã‚’é™¤å»ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "train_clean = train[~outliers].copy()\n",
    "print(f\"\\nã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ã‚µã‚¤ã‚º: {train_clean.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ 4. é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â­â­â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_feature_engineering_house(df, is_train=True):\n",
    "    \"\"\"\n",
    "    House Pricesç”¨ã®é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. ç·é¢ç©ã®è¨ˆç®—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰\n",
    "    if all(col in df.columns for col in ['GrLivArea', '1stFlrSF', '2ndFlrSF']):\n",
    "        df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df.get('TotalBsmtSF', 0)\n",
    "        df['TotalBathrooms'] = (df.get('FullBath', 0) + \n",
    "                                0.5 * df.get('HalfBath', 0) + \n",
    "                                df.get('BsmtFullBath', 0) + \n",
    "                                0.5 * df.get('BsmtHalfBath', 0))\n",
    "        df['TotalPorchSF'] = (df.get('OpenPorchSF', 0) + \n",
    "                              df.get('EnclosedPorch', 0) + \n",
    "                              df.get('3SsnPorch', 0) + \n",
    "                              df.get('ScreenPorch', 0))\n",
    "    \n",
    "    # 2. ç¯‰å¹´æ•°ã¨æ”¹ç¯‰å¹´\n",
    "    if 'YearBuilt' in df.columns:\n",
    "        df['Age'] = 2024 - df['YearBuilt']\n",
    "        if 'YearRemodAdd' in df.columns:\n",
    "            df['AgeRemod'] = 2024 - df['YearRemodAdd']\n",
    "            df['IsRemodeled'] = (df['YearBuilt'] != df['YearRemodAdd']).astype(int)\n",
    "    \n",
    "    # 3. å“è³ªã‚¹ã‚³ã‚¢ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰\n",
    "    if 'OverallQual' in df.columns and 'OverallCond' in df.columns:\n",
    "        df['QualityScore'] = df['OverallQual'] * df['OverallCond']\n",
    "    \n",
    "    # 4. åœ°ä¸‹å®¤ã®æœ‰ç„¡\n",
    "    if 'TotalBsmtSF' in df.columns:\n",
    "        df['HasBasement'] = (df['TotalBsmtSF'] > 0).astype(int)\n",
    "    \n",
    "    # 5. ã‚¬ãƒ¬ãƒ¼ã‚¸ã®æœ‰ç„¡ã¨é¢ç©\n",
    "    if 'GarageArea' in df.columns:\n",
    "        df['HasGarage'] = (df['GarageArea'] > 0).astype(int)\n",
    "    \n",
    "    # 6. äº¤äº’ä½œç”¨ç‰¹å¾´é‡\n",
    "    if 'GrLivArea' in df.columns and 'OverallQual' in df.columns:\n",
    "        df['QualArea'] = df['GrLivArea'] * df['OverallQual']\n",
    "    \n",
    "    # 7. æ¯”ç‡ç‰¹å¾´é‡\n",
    "    if 'GrLivArea' in df.columns and 'LotArea' in df.columns:\n",
    "        df['LivingAreaRatio'] = df['GrLivArea'] / (df['LotArea'] + 1)  # 0é™¤ç®—å›é¿\n",
    "    \n",
    "    print(f\"âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†: {df.shape[1]} ç‰¹å¾´é‡\")\n",
    "    return df\n",
    "\n",
    "# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®é©ç”¨\n",
    "train_fe = advanced_feature_engineering_house(train_clean)\n",
    "test_fe = advanced_feature_engineering_house(test)\n",
    "\n",
    "print(f\"\\nTrain shape: {train_fe.shape}\")\n",
    "print(f\"Test shape: {test_fe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 æ­ªåº¦ã®è£œæ­£ï¼ˆSkewness Correctionï¼‰ â­â­â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_skewness(train_df, test_df, threshold=0.75):\n",
    "    \"\"\"\n",
    "    æ­ªåº¦ãŒå¤§ãã„ç‰¹å¾´é‡ã«Box-Coxå¤‰æ›ã‚’é©ç”¨\n",
    "    \"\"\"\n",
    "    numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # æ­ªåº¦ã‚’è¨ˆç®—\n",
    "    skewed_features = train_df[numeric_cols].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_features = skewed_features[abs(skewed_features) > threshold]\n",
    "    \n",
    "    print(f\"âœ… {len(skewed_features)} å€‹ã®æ­ªã‚“ã ç‰¹å¾´é‡ã‚’æ¤œå‡º\")\n",
    "    \n",
    "    # Box-Coxå¤‰æ›\n",
    "    for feat in skewed_features.index:\n",
    "        if feat in train_df.columns and feat in test_df.columns:\n",
    "            # è² ã®å€¤ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "            if train_df[feat].min() < 0 or test_df[feat].min() < 0:\n",
    "                continue\n",
    "            \n",
    "            # Box-Coxå¤‰æ›ï¼ˆlambda=0.15ï¼‰\n",
    "            train_df[feat] = boxcox1p(train_df[feat], 0.15)\n",
    "            test_df[feat] = boxcox1p(test_df[feat], 0.15)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# æ­ªåº¦è£œæ­£\n",
    "train_fe, test_fe = fix_skewness(train_fe, test_fe, threshold=0.75)\n",
    "print(\"âœ… æ­ªåº¦è£œæ­£å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 5. ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_regression_data(train_df, test_df):\n",
    "    \"\"\"\n",
    "    å›å¸°ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "    \"\"\"\n",
    "    # ä½¿ç”¨ã—ãªã„åˆ—\n",
    "    drop_cols = ['Id', 'SalePrice', 'SalePrice_original']\n",
    "    \n",
    "    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ\n",
    "    if 'SalePrice' in train_df.columns:\n",
    "        y = train_df['SalePrice']\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    X = train_df.drop(columns=[col for col in drop_cols if col in train_df.columns])\n",
    "    X_test = test_df.drop(columns=[col for col in drop_cols if col in test_df.columns])\n",
    "    \n",
    "    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        combined = pd.concat([X[col], X_test[col]], ignore_index=True)\n",
    "        le.fit(combined.astype(str))\n",
    "        X[col] = le.transform(X[col].astype(str))\n",
    "        X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    \n",
    "    # æ¬ æå€¤è£œå®Œ\n",
    "    X = X.fillna(X.median())\n",
    "    X_test = X_test.fillna(X_test.median())\n",
    "    \n",
    "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†\")\n",
    "    print(f\"   ç‰¹å¾´é‡æ•°: {X.shape[1]}\")\n",
    "    print(f\"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X.shape[0]}\")\n",
    "    print(f\"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape[0]}\")\n",
    "    \n",
    "    return X, y, X_test\n",
    "\n",
    "X, y, X_test = prepare_regression_data(train_fe, test_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 6. GBDTå›å¸°ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n",
    "\n",
    "### 6.1 RMSLEè©•ä¾¡é–¢æ•°ã®å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Log Error\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def rmsle_cv(model, X, y, n_folds=5):\n",
    "    \"\"\"\n",
    "    K-Fold CVã§RMSLEã‚’è¨ˆç®—\n",
    "    \"\"\"\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    rmse_scores = -cross_val_score(model, X, y, \n",
    "                                    scoring='neg_root_mean_squared_error', \n",
    "                                    cv=kf)\n",
    "    return rmse_scores\n",
    "\n",
    "print(\"âœ… è©•ä¾¡é–¢æ•°å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 LightGBMå›å¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå›å¸°ç”¨ï¼‰\n",
    "params_lgb = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 6,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(**params_lgb)\n",
    "\n",
    "# Cross-validation\n",
    "scores_lgb = rmsle_cv(model_lgb, X, y, n_folds=5)\n",
    "print(f\"\\nğŸ“Š LightGBM CV RMSLE: {scores_lgb.mean():.4f} (+/- {scores_lgb.std():.4f})\")\n",
    "\n",
    "# å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’\n",
    "model_lgb.fit(X, y)\n",
    "preds_lgb = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 XGBoostå›å¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoostãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "params_xgb = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 1000,\n",
    "    'min_child_weight': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(**params_xgb)\n",
    "\n",
    "scores_xgb = rmsle_cv(model_xgb, X, y, n_folds=5)\n",
    "print(f\"\\nğŸ“Š XGBoost CV RMSLE: {scores_xgb.mean():.4f} (+/- {scores_xgb.std():.4f})\")\n",
    "\n",
    "model_xgb.fit(X, y)\n",
    "preds_xgb = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 CatBoostå›å¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "params_cat = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'iterations': 1000,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "model_cat = CatBoostRegressor(**params_cat)\n",
    "\n",
    "scores_cat = rmsle_cv(model_cat, X, y, n_folds=5)\n",
    "print(f\"\\nğŸ“Š CatBoost CV RMSLE: {scores_cat.mean():.4f} (+/- {scores_cat.std():.4f})\")\n",
    "\n",
    "model_cat.fit(X, y)\n",
    "preds_cat = model_cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ­ 7. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "weights = [0.4, 0.3, 0.3]  # LightGBM, XGBoost, CatBoost\n",
    "\n",
    "ensemble_preds = (weights[0] * preds_lgb + \n",
    "                  weights[1] * preds_xgb + \n",
    "                  weights[2] * preds_cat)\n",
    "\n",
    "print(f\"\\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿: LGB={weights[0]}, XGB={weights[1]}, CAT={weights[2]}\")\n",
    "\n",
    "# å¯¾æ•°å¤‰æ›ã‚’å…ƒã«æˆ»ã™\n",
    "final_predictions = np.expm1(ensemble_preds)\n",
    "\n",
    "print(f\"\\nğŸ“Š äºˆæ¸¬ä¾¡æ ¼çµ±è¨ˆ:\")\n",
    "print(f\"  Mean: ${final_predictions.mean():,.0f}\")\n",
    "print(f\"  Median: ${np.median(final_predictions):,.0f}\")\n",
    "print(f\"  Min: ${final_predictions.min():,.0f}\")\n",
    "print(f\"  Max: ${final_predictions.max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 8. æ®‹å·®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬\n",
    "train_preds = (weights[0] * model_lgb.predict(X) + \n",
    "               weights[1] * model_xgb.predict(X) + \n",
    "               weights[2] * model_cat.predict(X))\n",
    "\n",
    "residuals = y - train_preds\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. æ®‹å·®ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "axes[0, 0].hist(residuals, bins=50, edgecolor='black')\n",
    "axes[0, 0].set_title('Residuals Distribution')\n",
    "axes[0, 0].set_xlabel('Residual')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. æ®‹å·® vs äºˆæ¸¬å€¤\n",
    "axes[0, 1].scatter(train_preds, residuals, alpha=0.5)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 1].set_title('Residuals vs Predicted')\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Residual')\n",
    "\n",
    "# 3. Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot')\n",
    "\n",
    "# 4. å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤\n",
    "axes[1, 1].scatter(y, train_preds, alpha=0.5)\n",
    "axes[1, 1].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "axes[1, 1].set_title('Actual vs Predicted')\n",
    "axes[1, 1].set_xlabel('Actual')\n",
    "axes[1, 1].set_ylabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# RÂ²ã‚¹ã‚³ã‚¢\n",
    "r2 = r2_score(y, train_preds)\n",
    "print(f\"\\nğŸ“Š RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¤ 9. Kaggleæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "submission_dir = Path('../submissions')\n",
    "submission_dir.mkdir(exist_ok=True)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'SalePrice': final_predictions\n",
    "})\n",
    "\n",
    "submission_path = submission_dir / 'house_prices_submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"âœ… æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {submission_path}\")\n",
    "print(f\"\\næœ€åˆã®10è¡Œ:\")\n",
    "display(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 10. ã¾ã¨ã‚\n",
    "\n",
    "### å­¦ã‚“ã ã“ã¨\n",
    "\n",
    "1. âœ… Target transformationï¼ˆå¯¾æ•°å¤‰æ›ï¼‰ã®é‡è¦æ€§\n",
    "2. âœ… Outlier detectionï¼ˆIsolation Forestï¼‰\n",
    "3. âœ… Skewness correctionï¼ˆBox-Coxå¤‰æ›ï¼‰\n",
    "4. âœ… GBDTå›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMã€XGBoostã€CatBoostï¼‰\n",
    "5. âœ… RMSLEè©•ä¾¡æŒ‡æ¨™\n",
    "6. âœ… æ®‹å·®åˆ†æã«ã‚ˆã‚‹è¨ºæ–­\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "- **ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯19**: æ™‚ç³»åˆ—äºˆæ¸¬Ã—GBDT\n",
    "- **ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯20**: Optunaã§æœ€é©åŒ–ã‚’ã•ã‚‰ã«æ·±ãå­¦ã¶\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ  Happy House Hunting! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

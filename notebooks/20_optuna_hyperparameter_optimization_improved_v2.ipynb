{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20. Optuna自動ハイパーパラメータ最適化 (Optuna Hyperparameter Optimization)\n",
    "\n",
    "## 概要\n",
    "Optunaを使った効率的なハイパーパラメータ最適化の手法を学びます。\n",
    "\n",
    "## 学習目標\n",
    "- Optunaの基本的な使い方を理解できる\n",
    "- ベイズ最適化の原理を理解できる\n",
    "- GridSearch/RandomSearchとの違いを理解できる\n",
    "- Pruning（枝刈り）で効率を上げられる\n",
    "- 並列最適化を実行できる\n",
    "- 最適化結果を可視化・分析できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 設定\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Optunaとは\n",
    "\n",
    "### ハイパーパラメータ最適化の課題\n",
    "\n",
    "従来の手法の問題点：\n",
    "- **GridSearch**: 探索空間が広いと計算コストが膨大\n",
    "- **RandomSearch**: 効率が悪く、最適解に到達しにくい\n",
    "\n",
    "### Optunaの特徴\n",
    "\n",
    "1. **ベイズ最適化**\n",
    "   - 過去の試行結果を学習\n",
    "   - 有望な領域を効率的に探索\n",
    "\n",
    "2. **Pruning（枝刈り）**\n",
    "   - 見込みのない試行を早期終了\n",
    "   - 計算時間を大幅削減\n",
    "\n",
    "3. **並列最適化**\n",
    "   - 複数プロセスで同時実行\n",
    "   - スケーラビリティが高い\n",
    "\n",
    "4. **フレームワーク非依存**\n",
    "   - scikit-learn、PyTorch、TensorFlowなど対応\n",
    "   - 柔軟な統合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基本的な使い方\n",
    "\n",
    "### Optunaの基本構造\n",
    "\n",
    "```python\n",
    "def objective(trial):\n",
    "    # パラメータの提案\n",
    "    param = trial.suggest_float('param', 0.0, 1.0)\n",
    "    \n",
    "    # モデルの学習と評価\n",
    "    score = train_and_evaluate(param)\n",
    "    \n",
    "    # 最大化したいスコアを返す\n",
    "    return score\n",
    "\n",
    "# 最適化の実行\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの準備\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"訓練データ: {X_train.shape}\")\n",
    "print(f\"テストデータ: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本的なOptuna最適化の例\n",
    "def objective_rf(trial):\n",
    "    \"\"\"\n",
    "    RandomForestのハイパーパラメータを最適化する目的関数\n",
    "    \"\"\"\n",
    "    # パラメータの提案\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # モデルの学習と評価\n",
    "    model = RandomForestClassifier(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Studyの作成と最適化\n",
    "study_rf = optuna.create_study(direction='maximize', study_name='rf_optimization')\n",
    "study_rf.optimize(objective_rf, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n最適化完了！\")\n",
    "print(f\"最良スコア: {study_rf.best_value:.4f}\")\n",
    "print(f\"\\n最良パラメータ:\")\n",
    "for key, value in study_rf.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適モデルでテストデータを評価\n",
    "best_model = RandomForestClassifier(**study_rf.best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"テスト精度: {test_accuracy:.4f}\")\n",
    "print(\"\\n分類レポート:\")\n",
    "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 最適化の可視化\n",
    "\n",
    "### Optunaの可視化機能\n",
    "\n",
    "最適化の過程を理解するための可視化ツールが豊富に用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化履歴の可視化\n",
    "fig = plot_optimization_history(study_rf)\n",
    "fig.update_layout(title='Optimization History', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"このグラフから分かること:\")\n",
    "print(\"- 試行回数とともにスコアが改善されている\")\n",
    "print(\"- 最良スコアの更新頻度\")\n",
    "print(\"- 探索の収束状況\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの重要度\n",
    "fig = plot_param_importances(study_rf)\n",
    "fig.update_layout(title='Parameter Importances', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nパラメータ重要度の解釈:\")\n",
    "print(\"- 重要度が高いパラメータ: チューニングの優先度が高い\")\n",
    "print(\"- 重要度が低いパラメータ: デフォルト値でも十分かもしれない\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 並行座標プロット\n",
    "fig = plot_parallel_coordinate(study_rf)\n",
    "fig.update_layout(title='Parallel Coordinate Plot', width=900, height=500)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n並行座標プロットの読み方:\")\n",
    "print(\"- 各線が1回の試行を表す\")\n",
    "print(\"- 色が濃いほどスコアが高い\")\n",
    "print(\"- パラメータ間の関係性が見える\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GridSearch vs RandomSearch vs Optuna\n",
    "\n",
    "### 3つの手法を比較\n",
    "\n",
    "同じ問題に対して、3つの手法で最適化を行い、効率を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import time\n",
    "\n",
    "# パラメータ空間の定義\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth': list(range(3, 21)),\n",
    "    'min_samples_split': list(range(2, 21)),\n",
    "    'min_samples_leaf': list(range(1, 11)),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# GridSearch (限定的なグリッド)\n",
    "print(\"GridSearchCV実行中...\")\n",
    "param_grid_limited = {\n",
    "    'n_estimators': [50, 150, 250],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 5],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "start = time.time()\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_limited, cv=3, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "results['GridSearch'] = {\n",
    "    'time': time.time() - start,\n",
    "    'score': grid.best_score_,\n",
    "    'n_trials': len(grid.cv_results_['params'])\n",
    "}\n",
    "\n",
    "# RandomizedSearch\n",
    "print(\"RandomizedSearchCV実行中...\")\n",
    "start = time.time()\n",
    "random = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_dist, \n",
    "                            n_iter=50, cv=3, random_state=42, n_jobs=-1)\n",
    "random.fit(X_train, y_train)\n",
    "results['RandomSearch'] = {\n",
    "    'time': time.time() - start,\n",
    "    'score': random.best_score_,\n",
    "    'n_trials': 50\n",
    "}\n",
    "\n",
    "# Optuna (すでに実行済み)\n",
    "results['Optuna'] = {\n",
    "    'time': sum(trial.duration.total_seconds() for trial in study_rf.trials),\n",
    "    'score': study_rf.best_value,\n",
    "    'n_trials': len(study_rf.trials)\n",
    "}\n",
    "\n",
    "# 結果の比較\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\n比較結果:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 実行時間の比較\n",
    "axes[0].bar(comparison_df.index, comparison_df['time'])\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Execution Time Comparison')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# スコアの比較\n",
    "axes[1].bar(comparison_df.index, comparison_df['score'])\n",
    "axes[1].set_ylabel('CV Score')\n",
    "axes[1].set_title('Best Score Comparison')\n",
    "axes[1].set_ylim(comparison_df['score'].min() * 0.98, comparison_df['score'].max() * 1.01)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n結論:\")\n",
    "print(f\"Optunaは{comparison_df.loc['Optuna', 'n_trials']}試行で最良スコア{comparison_df.loc['Optuna', 'score']:.4f}を達成\")\n",
    "print(f\"効率性: {comparison_df.loc['Optuna', 'score'] / comparison_df.loc['Optuna', 'time']:.6f} (score/second)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pruning（枝刈り）\n",
    "\n",
    "### Pruningとは\n",
    "\n",
    "学習の途中で、見込みのない試行を早期終了する機能です。\n",
    "\n",
    "**利点:**\n",
    "- 計算時間の大幅削減\n",
    "- より多くのパラメータを試せる\n",
    "- リソースの効率的利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import OptunaSearchCV\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "def objective_with_pruning(trial):\n",
    "    \"\"\"\n",
    "    Pruning機能付きの目的関数\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    \n",
    "    # 各フォールドでPruningを検討\n",
    "    scores = []\n",
    "    for i, (train_idx, val_idx) in enumerate([(slice(0, 300), slice(300, 400)),\n",
    "                                                (slice(100, 400), slice(0, 100))]):\n",
    "        X_t, X_v = X_train[train_idx], X_train[val_idx]\n",
    "        y_t, y_v = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model.fit(X_t, y_t)\n",
    "        score = model.score(X_v, y_v)\n",
    "        scores.append(score)\n",
    "        \n",
    "        # 中間報告とPruning判定\n",
    "        trial.report(score, i)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Pruner付きStudy\n",
    "study_pruned = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=MedianPruner(n_startup_trials=10, n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "study_pruned.optimize(objective_with_pruning, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n最良スコア: {study_pruned.best_value:.4f}\")\n",
    "print(f\"完了した試行: {len([t for t in study_pruned.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"Pruneされた試行: {len([t for t in study_pruned.trials if t.state == optuna.trial.TrialState.PRUNED])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 複数モデルの同時最適化\n",
    "\n",
    "### モデル選択も最適化\n",
    "\n",
    "どのモデルが最適かも自動で選択できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_multi_model(trial):\n",
    "    \"\"\"\n",
    "    複数のモデルから最適なものを選択\n",
    "    \"\"\"\n",
    "    # モデルの選択\n",
    "    model_name = trial.suggest_categorical('model', ['RandomForest', 'GradientBoosting', 'MLP'])\n",
    "    \n",
    "    if model_name == 'RandomForest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('rf_n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('rf_max_depth', 3, 15),\n",
    "            'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = RandomForestClassifier(**params)\n",
    "    \n",
    "    elif model_name == 'GradientBoosting':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('gb_n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('gb_learning_rate', 0.01, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('gb_max_depth', 3, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params)\n",
    "    \n",
    "    else:  # MLP\n",
    "        params = {\n",
    "            'hidden_layer_sizes': trial.suggest_categorical('mlp_hidden', [(50,), (100,), (100, 50)]),\n",
    "            'alpha': trial.suggest_float('mlp_alpha', 1e-5, 1e-1, log=True),\n",
    "            'learning_rate_init': trial.suggest_float('mlp_lr', 1e-4, 1e-1, log=True),\n",
    "            'max_iter': 500,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = MLPClassifier(**params)\n",
    "    \n",
    "    # 評価\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# 最適化\n",
    "study_multi = optuna.create_study(direction='maximize')\n",
    "study_multi.optimize(objective_multi_model, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n最良モデル: {study_multi.best_params['model']}\")\n",
    "print(f\"最良スコア: {study_multi.best_value:.4f}\")\n",
    "print(f\"\\n最良パラメータ:\")\n",
    "for key, value in study_multi.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. まとめ\n",
    "\n",
    "### 本ノートブックで学んだこと\n",
    "\n",
    "1. **Optunaの基礎**\n",
    "   - 目的関数の定義\n",
    "   - Studyの作成と最適化\n",
    "   - パラメータの提案方法\n",
    "\n",
    "2. **可視化**\n",
    "   - 最適化履歴\n",
    "   - パラメータ重要度\n",
    "   - 並行座標プロット\n",
    "\n",
    "3. **比較**\n",
    "   - GridSearch vs RandomSearch vs Optuna\n",
    "   - 効率性と精度のトレードオフ\n",
    "\n",
    "4. **Pruning**\n",
    "   - 早期終了による効率化\n",
    "   - MedianPrunerの使用\n",
    "\n",
    "5. **複数モデル最適化**\n",
    "   - モデル選択も含めた最適化\n",
    "   - 条件分岐の実装\n",
    "\n",
    "### Optunaを使うべきとき\n",
    "\n",
    "- ✅ 探索空間が広い\n",
    "- ✅ 計算コストを抑えたい\n",
    "- ✅ 最先端の性能が必要\n",
    "- ✅ 複数のモデルを比較したい\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "- Notebook 21でSHAPによるモデル解釈を学ぶ\n",
    "- 実際のKaggleコンペでOptunaを活用\n",
    "- より高度な最適化戦略を探求"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

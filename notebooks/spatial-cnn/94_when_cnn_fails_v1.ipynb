{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 94. CNNが苦手なケース：帰納バイアスの限界\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このノートブックでは、以下を学びます：\n",
    "\n",
    "1. **CNNの帰納バイアスが合わないケース**\n",
    "2. **回転・スケール変換への弱さ**\n",
    "3. **長距離依存関係の問題**\n",
    "4. **テクスチャバイアス**\n",
    "\n",
    "## 目次\n",
    "\n",
    "1. [帰納バイアスの限界](#section1)\n",
    "2. [回転に対する弱さ](#section2)\n",
    "3. [長距離依存関係](#section3)\n",
    "4. [テクスチャバイアス](#section4)\n",
    "5. [まとめ](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate, zoom\n",
    "import japanize_matplotlib\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## 1. 帰納バイアスの限界\n",
    "\n",
    "CNNの帰納バイアスは画像認識に強力ですが、すべての問題に適しているわけではありません。\n",
    "\n",
    "### CNNが仮定していること\n",
    "\n",
    "1. **局所的なパターンが重要** → 大域的な関係が重要な場合に弱い\n",
    "2. **平行移動等変** → 回転・スケール変化には対応しない\n",
    "3. **テクスチャが重要** → 形状ベースの認識に弱い可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cnn_limitations():\n",
    "    \"\"\"CNNの限界を可視化\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    \n",
    "    # 1. 回転に対する非等変性\n",
    "    ax = axes[0, 0]\n",
    "    img = np.zeros((32, 32))\n",
    "    img[10:22, 14:18] = 1  # 縦長の矩形\n",
    "    \n",
    "    ax.imshow(img, cmap='Blues')\n",
    "    ax.set_title('回転に非等変\\n同じ「縦棒」でも', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = axes[0, 1]\n",
    "    img_rot = rotate(img, 45, reshape=False)\n",
    "    ax.imshow(img_rot, cmap='Blues')\n",
    "    ax.set_title('45°回転すると\\n異なる特徴として検出', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = axes[0, 2]\n",
    "    ax.text(0.5, 0.5, '回転等変でない\\n\\nデータ拡張で\\n対処が一般的', \n",
    "           fontsize=12, ha='center', va='center', transform=ax.transAxes,\n",
    "           bbox=dict(boxstyle='round', facecolor='lightyellow'))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 2. 長距離依存関係\n",
    "    ax = axes[1, 0]\n",
    "    img2 = np.zeros((32, 32))\n",
    "    img2[4:8, 4:8] = 1\n",
    "    img2[24:28, 24:28] = 1\n",
    "    \n",
    "    ax.imshow(img2, cmap='Reds')\n",
    "    ax.annotate('', xy=(26, 26), xytext=(6, 6),\n",
    "               arrowprops=dict(arrowstyle='<->', color='blue', lw=2))\n",
    "    ax.set_title('長距離依存関係\\nこの2つの関係は？', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = axes[1, 1]\n",
    "    ax.text(0.5, 0.6, '受容野の限界\\n\\n初期層では\\n遠い点を同時に\\n見れない', \n",
    "           fontsize=11, ha='center', va='center', transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.2, '解決策:\\n・深い層を使う\\n・Attention機構', \n",
    "           fontsize=10, ha='center', va='center', transform=ax.transAxes,\n",
    "           bbox=dict(boxstyle='round', facecolor='lightgreen'))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = axes[1, 2]\n",
    "    # テクスチャバイアスの例\n",
    "    np.random.seed(42)\n",
    "    texture = np.random.rand(32, 32) * 0.5\n",
    "    # 猫の形（シルエット）にテクスチャを適用\n",
    "    shape = np.zeros((32, 32))\n",
    "    shape[8:24, 10:22] = 1  # 体\n",
    "    shape[4:12, 12:20] = 1  # 頭\n",
    "    \n",
    "    combined = texture * shape\n",
    "    ax.imshow(combined, cmap='gray')\n",
    "    ax.set_title('テクスチャバイアス\\nCNNは形状より\\nテクスチャを重視しがち', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('CNNの帰納バイアスの限界', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_cnn_limitations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "## 2. 回転に対する弱さ\n",
    "\n",
    "CNNは平行移動には等変ですが、回転には等変ではありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_rotation_problem():\n",
    "    \"\"\"回転問題のデモ\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "    \n",
    "    # 元画像（数字「6」風）\n",
    "    img = np.zeros((28, 28))\n",
    "    # 丸\n",
    "    y, x = np.ogrid[:28, :28]\n",
    "    center = (18, 14)\n",
    "    r = 6\n",
    "    mask = (x - center[0])**2 + (y - center[1])**2 < r**2\n",
    "    img[mask] = 1\n",
    "    # 上の棒\n",
    "    img[4:18, 12:16] = 1\n",
    "    \n",
    "    angles = [0, 30, 60, 90, 180]\n",
    "    \n",
    "    for idx, angle in enumerate(angles):\n",
    "        rotated = rotate(img, angle, reshape=False)\n",
    "        \n",
    "        axes[0, idx].imshow(rotated, cmap='gray_r')\n",
    "        axes[0, idx].set_title(f'{angle}°回転', fontsize=12)\n",
    "        axes[0, idx].axis('off')\n",
    "        \n",
    "        # 縦エッジフィルタの応答\n",
    "        kernel = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=float)\n",
    "        from scipy.signal import correlate2d\n",
    "        response = correlate2d(rotated, kernel, mode='same')\n",
    "        \n",
    "        axes[1, idx].imshow(response, cmap='RdBu')\n",
    "        axes[1, idx].set_title(f'縦エッジ応答', fontsize=10)\n",
    "        axes[1, idx].axis('off')\n",
    "    \n",
    "    axes[0, 0].set_ylabel('入力', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('フィルタ応答', fontsize=12)\n",
    "    \n",
    "    plt.suptitle('回転に対するCNNの問題\\n同じカーネルでは回転後のパターンを同様に検出できない', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"観察:\")\n",
    "    print(\"- 縦エッジカーネルは0°では縦エッジを検出\")\n",
    "    print(\"- 90°回転すると、元の縦エッジは横エッジになり検出されない\")\n",
    "    print(\"- 回転等変にするには回転したカーネルも必要\")\n",
    "\n",
    "demonstrate_rotation_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rotation_solutions():\n",
    "    \"\"\"回転問題の解決策\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"回転に対する解決策\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    solutions = [\n",
    "        (\"1. データ拡張\", \n",
    "         \"訓練時にランダム回転を適用\",\n",
    "         \"最も一般的、簡単だが計算コスト増\"),\n",
    "        \n",
    "        (\"2. 回転等変ネットワーク\",\n",
    "         \"Group Equivariant CNN (G-CNN)\",\n",
    "         \"理論的に美しいが実装が複雑\"),\n",
    "        \n",
    "        (\"3. Spatial Transformer Network\",\n",
    "         \"入力を正規化する層を学習\",\n",
    "         \"柔軟だが学習が難しい場合も\"),\n",
    "        \n",
    "        (\"4. 回転不変な特徴\",\n",
    "         \"Global Poolingで位置情報を捨てる\",\n",
    "         \"情報損失があるが簡単\")\n",
    "    ]\n",
    "    \n",
    "    for name, desc, note in solutions:\n",
    "        print(f\"\\n{name}\")\n",
    "        print(f\"  説明: {desc}\")\n",
    "        print(f\"  備考: {note}\")\n",
    "\n",
    "show_rotation_solutions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## 3. 長距離依存関係\n",
    "\n",
    "CNNの受容野は層を重ねないと広がりません。初期層では遠く離れた点の関係を捉えられません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_long_range_problem():\n",
    "    \"\"\"長距離依存関係の問題\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # 例: 2つの点の関係\n",
    "    ax = axes[0]\n",
    "    img = np.zeros((32, 32))\n",
    "    img[5:9, 5:9] = 1    # 左上\n",
    "    img[23:27, 23:27] = 1  # 右下\n",
    "    \n",
    "    ax.imshow(img, cmap='Reds')\n",
    "    ax.annotate('', xy=(25, 25), xytext=(7, 7),\n",
    "               arrowprops=dict(arrowstyle='<->', color='blue', lw=2))\n",
    "    ax.set_title('問題: 遠く離れた点の関係\\n距離 ≈ 25ピクセル', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 受容野の成長\n",
    "    ax = axes[1]\n",
    "    layers = range(1, 11)\n",
    "    rf_3x3 = [1 + 2*n for n in layers]  # 3x3カーネル\n",
    "    rf_5x5 = [1 + 4*n for n in layers]  # 5x5カーネル\n",
    "    \n",
    "    ax.plot(layers, rf_3x3, 'b-o', label='3×3カーネル')\n",
    "    ax.plot(layers, rf_5x5, 'r-s', label='5×5カーネル')\n",
    "    ax.axhline(y=25, color='green', linestyle='--', label='必要なRF=25')\n",
    "    \n",
    "    ax.set_xlabel('層数')\n",
    "    ax.set_ylabel('受容野サイズ')\n",
    "    ax.set_title('受容野の成長\\n25ピクセルに達するまで', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 解決策\n",
    "    ax = axes[2]\n",
    "    solutions = [\n",
    "        '1. 深い層を使う',\n",
    "        '2. Dilated Convolution',\n",
    "        '3. Poolingで解像度を下げる',\n",
    "        '4. Self-Attention (ViT)',\n",
    "    ]\n",
    "    \n",
    "    for i, sol in enumerate(solutions):\n",
    "        ax.text(0.1, 0.8 - i*0.2, sol, fontsize=12, transform=ax.transAxes)\n",
    "    \n",
    "    ax.set_title('解決策', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('長距離依存関係の問題', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demonstrate_long_range_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_dilated_convolution():\n",
    "    \"\"\"Dilated Convolutionによる受容野拡大\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # 通常の畳み込み\n",
    "    ax = axes[0]\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            color = 'lightblue' if 2 <= i <= 4 and 2 <= j <= 4 else 'white'\n",
    "            rect = plt.Rectangle((j, 6-i), 0.9, 0.9, facecolor=color, edgecolor='gray')\n",
    "            ax.add_patch(rect)\n",
    "    ax.set_xlim(-0.5, 7.5)\n",
    "    ax.set_ylim(-0.5, 7.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('通常の3×3畳み込み\\nRF = 3', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Dilation=2\n",
    "    ax = axes[1]\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            is_kernel = (i in [1, 3, 5]) and (j in [1, 3, 5])\n",
    "            color = 'lightblue' if is_kernel else 'white'\n",
    "            rect = plt.Rectangle((j, 6-i), 0.9, 0.9, facecolor=color, edgecolor='gray')\n",
    "            ax.add_patch(rect)\n",
    "    ax.set_xlim(-0.5, 7.5)\n",
    "    ax.set_ylim(-0.5, 7.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('Dilated Conv (d=2)\\nRF = 5', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Dilation=3\n",
    "    ax = axes[2]\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            is_kernel = (i in [0, 3, 6]) and (j in [0, 3, 6])\n",
    "            color = 'lightblue' if is_kernel else 'white'\n",
    "            rect = plt.Rectangle((j, 6-i), 0.9, 0.9, facecolor=color, edgecolor='gray')\n",
    "            ax.add_patch(rect)\n",
    "    ax.set_xlim(-0.5, 7.5)\n",
    "    ax.set_ylim(-0.5, 7.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('Dilated Conv (d=3)\\nRF = 7', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Dilated Convolution: パラメータを増やさずに受容野を拡大', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demonstrate_dilated_convolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "## 4. テクスチャバイアス\n",
    "\n",
    "CNNは形状よりもテクスチャを重視する傾向があります（Geirhos et al., 2019）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_texture_bias():\n",
    "    \"\"\"テクスチャバイアスのデモ\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 猫のシルエット（簡略）\n",
    "    cat_shape = np.zeros((64, 64))\n",
    "    cat_shape[20:50, 20:45] = 1  # 体\n",
    "    cat_shape[10:25, 25:40] = 1  # 頭\n",
    "    cat_shape[5:12, 22:28] = 1   # 左耳\n",
    "    cat_shape[5:12, 35:41] = 1   # 右耳\n",
    "    \n",
    "    # 象のシルエット（簡略）\n",
    "    elephant_shape = np.zeros((64, 64))\n",
    "    elephant_shape[20:50, 15:55] = 1  # 体\n",
    "    elephant_shape[15:35, 45:55] = 1  # 頭\n",
    "    elephant_shape[35:55, 8:15] = 1   # 前脚\n",
    "    elephant_shape[35:55, 48:55] = 1  # 後脚\n",
    "    elephant_shape[20:30, 52:62] = 1  # 鼻\n",
    "    \n",
    "    # テクスチャ\n",
    "    cat_texture = np.random.rand(64, 64) * 0.5 + 0.3  # 猫風（縞模様風）\n",
    "    elephant_texture = np.random.rand(64, 64) * 0.3 + 0.5  # 象風（灰色）\n",
    "    \n",
    "    # 通常の画像\n",
    "    axes[0, 0].imshow(cat_shape * cat_texture, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, 0].set_title('猫（形状）+ 猫テクスチャ\\n→ 猫として認識', fontsize=11)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(elephant_shape * elephant_texture, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, 1].set_title('象（形状）+ 象テクスチャ\\n→ 象として認識', fontsize=11)\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # テクスチャと形状を交換\n",
    "    axes[1, 0].imshow(cat_shape * elephant_texture, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, 0].set_title('猫（形状）+ 象テクスチャ\\n人間: 猫 / CNN: 象?', fontsize=11)\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(elephant_shape * cat_texture, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, 1].set_title('象（形状）+ 猫テクスチャ\\n人間: 象 / CNN: 猫?', fontsize=11)\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # 説明\n",
    "    axes[0, 2].text(0.5, 0.5, 'テクスチャバイアス\\n\\nCNNは局所的な\\nテクスチャパターンを\\n重視しがち', \n",
    "                   fontsize=12, ha='center', va='center', transform=axes[0, 2].transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightyellow'))\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    axes[1, 2].text(0.5, 0.5, '人間は形状を重視\\nCNNはテクスチャを重視\\n\\n解決策:\\n・Shape-biased訓練\\n・データ拡張', \n",
    "                   fontsize=11, ha='center', va='center', transform=axes[1, 2].transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgreen'))\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle('テクスチャバイアス：CNNと人間の認識の違い', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demonstrate_texture_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 5. まとめ\n",
    "\n",
    "### CNNの限界\n",
    "\n",
    "| 問題 | 原因 | 解決策 |\n",
    "|------|------|--------|\n",
    "| 回転に弱い | 平行移動のみ等変 | データ拡張、G-CNN |\n",
    "| 長距離依存 | 受容野が局所的 | 深い層、Dilated Conv、Attention |\n",
    "| テクスチャバイアス | 局所パターン重視 | Shape-biased訓練 |\n",
    "\n",
    "### 重要なポイント\n",
    "\n",
    "- **帰納バイアスは両刃の剣**: 適切なら効率的、不適切なら限界に\n",
    "- **問題に応じたアーキテクチャ選択**が重要\n",
    "- **Vision Transformer**など新しいアーキテクチャが登場"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次のノートブック\n",
    "\n",
    "次のノートブックでは、**CNNを超えて**ーVision TransformerやMLP-Mixerなど新しいアーキテクチャについて学びます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

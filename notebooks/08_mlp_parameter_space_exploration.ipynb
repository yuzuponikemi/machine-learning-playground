{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 08: MLP Parameter Space Exploration\n",
    "\n",
    "Comprehensive hyperparameter tuning for MLPClassifier.\n",
    "\n",
    "## Learning Objectives\n",
    "- Systematically explore MLP hyperparameters\n",
    "- Use GridSearchCV for parameter optimization\n",
    "- Visualize parameter effects with heatmaps\n",
    "- Understand parameter interactions\n",
    "- Find optimal model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_moons\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, RandomizedSearchCV, \n",
    "    cross_val_score, learning_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Complex Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-class classification data\n",
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"  Training samples: {X_train.shape[0]}\")\n",
    "print(f\"  Test samples: {X_test.shape[0]}\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")\n",
    "print(f\"  Classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Architecture Search (hidden_layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different architectures\n",
    "architectures = [\n",
    "    # Single layer\n",
    "    (10,), (25,), (50,), (100,), (200,),\n",
    "    # Two layers\n",
    "    (25, 10), (50, 25), (100, 50), (200, 100),\n",
    "    # Three layers\n",
    "    (50, 25, 10), (100, 50, 25), (200, 100, 50),\n",
    "    # Four layers\n",
    "    (100, 75, 50, 25)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for arch in architectures:\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=arch,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(mlp, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Fit and test\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    test_acc = mlp.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Count parameters\n",
    "    n_params = sum(w.size + b.size for w, b in zip(mlp.coefs_, mlp.intercepts_))\n",
    "    \n",
    "    results.append({\n",
    "        'architecture': str(arch),\n",
    "        'n_layers': len(arch),\n",
    "        'n_params': n_params,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_acc': test_acc,\n",
    "        'n_iter': mlp.n_iter_\n",
    "    })\n",
    "\n",
    "df_arch = pd.DataFrame(results).sort_values('cv_mean', ascending=False)\n",
    "print(\"Architecture Comparison (sorted by CV accuracy):\")\n",
    "print(df_arch.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize architecture results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of CV scores\n",
    "df_sorted = df_arch.sort_values('cv_mean')\n",
    "colors = ['C0' if l == 1 else 'C1' if l == 2 else 'C2' if l == 3 else 'C3' \n",
    "          for l in df_sorted['n_layers']]\n",
    "\n",
    "bars = axes[0].barh(range(len(df_sorted)), df_sorted['cv_mean'], \n",
    "                    xerr=df_sorted['cv_std'], color=colors, alpha=0.7)\n",
    "axes[0].set_yticks(range(len(df_sorted)))\n",
    "axes[0].set_yticklabels(df_sorted['architecture'])\n",
    "axes[0].set_xlabel('CV Accuracy')\n",
    "axes[0].set_title('Architecture Comparison')\n",
    "\n",
    "# Accuracy vs Parameters\n",
    "for n_layers in [1, 2, 3, 4]:\n",
    "    subset = df_arch[df_arch['n_layers'] == n_layers]\n",
    "    axes[1].scatter(subset['n_params'], subset['cv_mean'], \n",
    "                    s=100, label=f'{n_layers} layers', alpha=0.7)\n",
    "axes[1].set_xlabel('Number of Parameters')\n",
    "axes[1].set_ylabel('CV Accuracy')\n",
    "axes[1].set_title('Accuracy vs Model Complexity')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Learning Rate and Alpha Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search: learning_rate_init vs alpha\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "results_grid = np.zeros((len(learning_rates), len(alphas)))\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    for j, alpha in enumerate(alphas):\n",
    "        mlp = MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            alpha=alpha,\n",
    "            learning_rate_init=lr,\n",
    "            max_iter=500,\n",
    "            early_stopping=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        cv_scores = cross_val_score(mlp, X_train_scaled, y_train, cv=3, scoring='accuracy')\n",
    "        results_grid[i, j] = cv_scores.mean()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(results_grid, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "            xticklabels=alphas, yticklabels=learning_rates)\n",
    "plt.xlabel('Alpha (L2 Regularization)')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('MLP: Learning Rate vs Alpha (CV Accuracy)')\n",
    "plt.show()\n",
    "\n",
    "# Find best combination\n",
    "best_idx = np.unravel_index(np.argmax(results_grid), results_grid.shape)\n",
    "print(f\"Best learning_rate: {learning_rates[best_idx[0]]}\")\n",
    "print(f\"Best alpha: {alphas[best_idx[1]]}\")\n",
    "print(f\"Best CV accuracy: {results_grid[best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Comprehensive GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "}\n",
    "\n",
    "# Create base model\n",
    "mlp = MLPClassifier(\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    mlp, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best results\n",
    "print(\"GridSearchCV Results:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nBest Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {grid_search.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Select relevant columns\n",
    "cols = ['param_hidden_layer_sizes', 'param_activation', 'param_alpha', \n",
    "        'param_learning_rate_init', 'mean_test_score', 'std_test_score', \n",
    "        'mean_train_score', 'rank_test_score']\n",
    "results_summary = results_df[cols].sort_values('rank_test_score')\n",
    "\n",
    "print(\"\\nTop 10 Parameter Combinations:\")\n",
    "print(results_summary.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GridSearchCV results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Effect of architecture\n",
    "arch_results = results_df.groupby('param_hidden_layer_sizes')['mean_test_score'].agg(['mean', 'std'])\n",
    "arch_labels = [str(a) for a in arch_results.index]\n",
    "axes[0, 0].bar(arch_labels, arch_results['mean'], yerr=arch_results['std'], alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Architecture')\n",
    "axes[0, 0].set_ylabel('Mean CV Accuracy')\n",
    "axes[0, 0].set_title('Effect of Architecture')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Effect of activation\n",
    "act_results = results_df.groupby('param_activation')['mean_test_score'].agg(['mean', 'std'])\n",
    "axes[0, 1].bar(act_results.index, act_results['mean'], yerr=act_results['std'], alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Activation')\n",
    "axes[0, 1].set_ylabel('Mean CV Accuracy')\n",
    "axes[0, 1].set_title('Effect of Activation Function')\n",
    "\n",
    "# 3. Effect of alpha\n",
    "alpha_results = results_df.groupby('param_alpha')['mean_test_score'].agg(['mean', 'std'])\n",
    "axes[1, 0].errorbar(range(len(alpha_results)), alpha_results['mean'], \n",
    "                    yerr=alpha_results['std'], marker='o', capsize=5)\n",
    "axes[1, 0].set_xticks(range(len(alpha_results)))\n",
    "axes[1, 0].set_xticklabels([f'{a:.4f}' for a in alpha_results.index])\n",
    "axes[1, 0].set_xlabel('Alpha')\n",
    "axes[1, 0].set_ylabel('Mean CV Accuracy')\n",
    "axes[1, 0].set_title('Effect of Regularization (Alpha)')\n",
    "\n",
    "# 4. Train vs Test score\n",
    "axes[1, 1].scatter(results_df['mean_train_score'], results_df['mean_test_score'], alpha=0.5)\n",
    "axes[1, 1].plot([0.8, 1], [0.8, 1], 'r--', lw=1)\n",
    "axes[1, 1].set_xlabel('Mean Train Score')\n",
    "axes[1, 1].set_ylabel('Mean Test Score')\n",
    "axes[1, 1].set_title('Train vs Test Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Detailed Parameter Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture vs Alpha heatmap\n",
    "pivot_arch_alpha = results_df.pivot_table(\n",
    "    values='mean_test_score',\n",
    "    index='param_hidden_layer_sizes',\n",
    "    columns='param_alpha',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_arch_alpha, annot=True, fmt='.3f', cmap='YlOrRd')\n",
    "plt.title('Architecture vs Alpha (Mean CV Accuracy)')\n",
    "plt.ylabel('Architecture')\n",
    "plt.xlabel('Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate vs Alpha for best architecture\n",
    "best_arch = grid_search.best_params_['hidden_layer_sizes']\n",
    "\n",
    "# More detailed search for learning rate and alpha\n",
    "lr_range = [0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "alpha_range = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "\n",
    "detailed_results = np.zeros((len(lr_range), len(alpha_range)))\n",
    "\n",
    "for i, lr in enumerate(lr_range):\n",
    "    for j, alpha in enumerate(alpha_range):\n",
    "        mlp = MLPClassifier(\n",
    "            hidden_layer_sizes=best_arch,\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            alpha=alpha,\n",
    "            learning_rate_init=lr,\n",
    "            max_iter=500,\n",
    "            early_stopping=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        cv_scores = cross_val_score(mlp, X_train_scaled, y_train, cv=3)\n",
    "        detailed_results[i, j] = cv_scores.mean()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(detailed_results, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "            xticklabels=[f'{a:.4f}' for a in alpha_range],\n",
    "            yticklabels=lr_range)\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(f'Detailed LR vs Alpha Search (Architecture: {best_arch})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: RandomizedSearchCV for Larger Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "# Define parameter distributions\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (50,), (100,), (200,),\n",
    "        (50, 25), (100, 50), (200, 100),\n",
    "        (100, 50, 25), (200, 100, 50)\n",
    "    ],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': loguniform(1e-5, 1e-1),\n",
    "    'learning_rate_init': loguniform(1e-4, 1e-1),\n",
    "    'batch_size': [32, 64, 128, 256]\n",
    "}\n",
    "\n",
    "# Randomized search\n",
    "mlp = MLPClassifier(\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    mlp,\n",
    "    param_distributions,\n",
    "    n_iter=50,  # Number of parameter settings to sample\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from randomized search\n",
    "print(\"RandomizedSearchCV Results:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nBest Parameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {param}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV Score: {random_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {random_search.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Learning Curves for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Generate learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_model, X_train_scaled, y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "test_mean = test_scores.mean(axis=1)\n",
    "test_std = test_scores.std(axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.1, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Cross-validation score')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, \n",
    "                 alpha=0.1, color='green')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve for Best MLP Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "final_model = MLPClassifier(\n",
    "    **grid_search.best_params_,\n",
    "    solver='adam',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report\n",
    "print(\"Final Model Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model details\n",
    "print(\"\\nFinal Model Details:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Architecture: {final_model.hidden_layer_sizes}\")\n",
    "print(f\"Activation: {final_model.activation}\")\n",
    "print(f\"Alpha: {final_model.alpha}\")\n",
    "print(f\"Learning rate: {final_model.learning_rate_init}\")\n",
    "print(f\"Iterations: {final_model.n_iter_}\")\n",
    "print(f\"Final loss: {final_model.loss_:.6f}\")\n",
    "\n",
    "# Parameter count\n",
    "n_params = sum(w.size + b.size for w, b in zip(final_model.coefs_, final_model.intercepts_))\n",
    "print(f\"Total parameters: {n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(final_model.loss_curve_, 'b-', linewidth=1)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Final Model Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Parameter Space Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMLP Parameter Space Summary:\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"ARCHITECTURE (hidden_layer_sizes)\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  • Start: (50,) or (100,)\")\n",
    "print(\"  • Medium: (100, 50) or (50, 25)\")\n",
    "print(\"  • Deep: (100, 50, 25)\")\n",
    "print(\"  • Tip: Pyramid structure (decreasing sizes) often works well\")\n",
    "print()\n",
    "print(\"ACTIVATION\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  • relu: Default choice, fast training\")\n",
    "print(\"  • tanh: Better for normalized data\")\n",
    "print()\n",
    "print(\"ALPHA (L2 Regularization)\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  • Range: 0.0001 to 0.1\")\n",
    "print(\"  • Start: 0.001\")\n",
    "print(\"  • Increase if overfitting, decrease if underfitting\")\n",
    "print()\n",
    "print(\"LEARNING_RATE_INIT\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  • Range: 0.0001 to 0.1\")\n",
    "print(\"  • Start: 0.001 for Adam\")\n",
    "print(\"  • Reduce if loss oscillates\")\n",
    "print()\n",
    "print(\"BATCH_SIZE\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  • Range: 32 to 256\")\n",
    "print(\"  • Smaller: More noise, better generalization\")\n",
    "print(\"  • Larger: Faster training, smoother convergence\")\n",
    "print()\n",
    "print(\"SOLVER\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  • adam: Best default choice\")\n",
    "print(\"  • sgd: When you need momentum/learning rate schedules\")\n",
    "print(\"  • lbfgs: For small datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "### Parameter Exploration Techniques\n",
    "- Manual parameter sweeps\n",
    "- GridSearchCV for exhaustive search\n",
    "- RandomizedSearchCV for large parameter spaces\n",
    "\n",
    "### Key Parameters for MLP\n",
    "- **hidden_layer_sizes**: Architecture definition\n",
    "- **alpha**: L2 regularization strength\n",
    "- **learning_rate_init**: Initial learning rate\n",
    "- **activation**: Activation function\n",
    "- **batch_size**: Mini-batch size\n",
    "\n",
    "### Visualization Methods\n",
    "- Heatmaps for parameter interactions\n",
    "- Bar plots for comparing configurations\n",
    "- Learning curves for diagnostics\n",
    "\n",
    "### Key Takeaways\n",
    "- Start with moderate architecture, tune from there\n",
    "- Use GridSearchCV for small parameter spaces\n",
    "- Use RandomizedSearchCV for large spaces\n",
    "- Always validate with learning curves\n",
    "- Early stopping prevents overfitting\n",
    "\n",
    "### Next Steps\n",
    "Continue to **Notebook 09** for MLP regression with waveform prediction!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

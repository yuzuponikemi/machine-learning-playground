{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬34ç« : EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \n",
    "\n",
    "## ğŸ“‹ ã“ã®ç« ã§å­¦ã¶ã“ã¨\n",
    "\n",
    "ã“ã®ç« ã‚’çµ‚ãˆã‚‹ã¨ã€ä»¥ä¸‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š\n",
    "\n",
    "- [ ] KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®æ¦‚å¿µã‚’ç†è§£ã§ãã‚‹\n",
    "- [ ] ELBOï¼ˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ä¸‹ç•Œï¼‰ã‚’èª¬æ˜ã§ãã‚‹\n",
    "- [ ] EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å°å‡ºã‚’ç†è§£ã§ãã‚‹\n",
    "- [ ] GMMã«EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã§ãã‚‹\n",
    "- [ ] EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã§ãã‚‹\n",
    "\n",
    "## ğŸ¯ å‰æçŸ¥è­˜\n",
    "\n",
    "ã“ã®ç« ã‚’å­¦ã¶ã«ã¯ä»¥ä¸‹ã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ï¼š\n",
    "\n",
    "- âœ… Notebook 33ï¼ˆæ··åˆã‚¬ã‚¦ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼‰\n",
    "- âœ… æœ€å°¤æ¨å®šã®åŸºç¤\n",
    "- âœ… ç¢ºç‡ã®åŸºç¤ï¼ˆãƒ™ã‚¤ã‚ºã®å®šç†ã€å‘¨è¾ºåŒ–ï¼‰\n",
    "\n",
    "â±ï¸ **æ¨å®šå­¦ç¿’æ™‚é–“**: 150-180åˆ†  \n",
    "ğŸ“Š **é›£æ˜“åº¦**: â˜…â˜…â˜…â˜…â˜†ï¼ˆä¸Šç´šï¼‰  \n",
    "ğŸ“ **ã‚«ãƒ†ã‚´ãƒª**: å®Ÿè·µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒŸ ã¯ã˜ã‚ã«\n",
    "\n",
    "å‰ç« ã§ã¯ã€GMMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šãŒã€Œå¯¾æ•°ã®ä¸­ã«å’ŒãŒã‚ã‚‹ã€ãŸã‚è§£æçš„ã«è§£ã‘ãªã„ã“ã¨ã‚’å­¦ã³ã¾ã—ãŸã€‚\n",
    "\n",
    "**EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆExpectation-Maximization Algorithmï¼‰**ã¯ã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®åå¾©æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™ã€‚\n",
    "\n",
    "### ğŸ¤” EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é‡è¦æ€§\n",
    "\n",
    "EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã§æœ€ã‚‚é‡è¦ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®1ã¤ã§ã™ï¼š\n",
    "\n",
    "1. **GMM**: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨å¯†åº¦æ¨å®š\n",
    "2. **éš ã‚Œãƒãƒ«ã‚³ãƒ•ãƒ¢ãƒ‡ãƒ«ï¼ˆHMMï¼‰**: ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®è§£æ\n",
    "3. **æ½œåœ¨ãƒ‡ã‚£ãƒªã‚¯ãƒ¬é…åˆ†ï¼ˆLDAï¼‰**: ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«\n",
    "4. **VAE**: EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å¤‰åˆ†è¿‘ä¼¼ç‰ˆã‚’ä½¿ç”¨\n",
    "\n",
    "EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯ã€VAEã‚„æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç†è§£ã¸ã®é‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ç’°å¢ƒè¨­å®š\n",
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€ã‚°ãƒ©ãƒ•ã®è¡¨ç¤ºè¨­å®šã‚’è¡Œã„ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.special import logsumexp\n",
    "import warnings\n",
    "\n",
    "# è­¦å‘Šã‚’éè¡¨ç¤º\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "def setup_japanese_font():\n",
    "    \"\"\"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šã™ã‚‹\"\"\"\n",
    "    japanese_fonts = [\n",
    "        'Hiragino Sans', 'Hiragino Maru Gothic Pro', 'AppleGothic',\n",
    "        'Yu Gothic', 'MS Gothic',\n",
    "        'Noto Sans CJK JP', 'IPAexGothic', 'TakaoPGothic',\n",
    "    ]\n",
    "    available_fonts = set(f.name for f in fm.fontManager.ttflist)\n",
    "    for font in japanese_fonts:\n",
    "        if font in available_fonts:\n",
    "            plt.rcParams['font.family'] = font\n",
    "            plt.rcParams['axes.unicode_minus'] = False\n",
    "            return font\n",
    "    return None\n",
    "\n",
    "font_used = setup_japanese_font()\n",
    "if font_used:\n",
    "    print(f\"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ: {font_used}\")\n",
    "\n",
    "# å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹\n",
    "\n",
    "### ğŸ¤” KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¨ã¯ï¼Ÿ\n",
    "\n",
    "**KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼ˆKullback-Leibler Divergenceï¼‰**ã¯ã€2ã¤ã®ç¢ºç‡åˆ†å¸ƒãŒã©ã‚Œã ã‘ç•°ãªã‚‹ã‹ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã™ã€‚\n",
    "\n",
    "$$D_{KL}(q \\| p) = \\int q(x) \\log \\frac{q(x)}{p(x)} dx = \\mathbb{E}_{q}\\left[\\log \\frac{q(x)}{p(x)}\\right]$$\n",
    "\n",
    "### ğŸ“Š KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®æ€§è³ª\n",
    "\n",
    "1. **éè² æ€§**: $D_{KL}(q \\| p) \\geq 0$\n",
    "2. **ç­‰å·æ¡ä»¶**: $D_{KL}(q \\| p) = 0 \\Leftrightarrow q = p$\n",
    "3. **éå¯¾ç§°æ€§**: $D_{KL}(q \\| p) \\neq D_{KL}(p \\| q)$ï¼ˆè·é›¢ã§ã¯ãªã„ï¼ï¼‰\n",
    "\n",
    "### ğŸ¤” ç›´æ„Ÿçš„ãªç†è§£\n",
    "\n",
    "KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã€Œ$q$ã‚’ä½¿ã£ã¦$p$ã‚’è¿‘ä¼¼ã—ãŸã¨ãã®æƒ…å ±æå¤±ã€ã¨è§£é‡ˆã§ãã¾ã™ã€‚\n",
    "\n",
    "- $D_{KL}(q \\| p)$: $p$ãŒçœŸã®åˆ†å¸ƒã§ã€$q$ã§è¿‘ä¼¼ã™ã‚‹å ´åˆ\n",
    "- å€¤ãŒå¤§ãã„ã»ã©ã€$q$ã«ã‚ˆã‚‹$p$ã®è¿‘ä¼¼ãŒæ‚ªã„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®å¯è¦–åŒ–\n",
    "# 2ã¤ã®æ­£è¦åˆ†å¸ƒé–“ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’è¨ˆç®—ãƒ»å¯è¦–åŒ–ã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "def kl_divergence_normal(mu_q, sigma_q, mu_p, sigma_p):\n",
    "    \"\"\"\n",
    "    2ã¤ã®1æ¬¡å…ƒæ­£è¦åˆ†å¸ƒé–“ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹\n",
    "    D_KL(q || p) where q = N(mu_q, sigma_q^2), p = N(mu_p, sigma_p^2)\n",
    "    \n",
    "    è§£æè§£:\n",
    "    D_KL(q || p) = log(sigma_p/sigma_q) + (sigma_q^2 + (mu_q - mu_p)^2) / (2*sigma_p^2) - 1/2\n",
    "    \"\"\"\n",
    "    return (np.log(sigma_p/sigma_q) + \n",
    "            (sigma_q**2 + (mu_q - mu_p)**2) / (2*sigma_p**2) - 0.5)\n",
    "\n",
    "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "mu_p, sigma_p = 0, 1  # çœŸã®åˆ†å¸ƒ p\n",
    "mu_q, sigma_q = 1, 1.5  # è¿‘ä¼¼åˆ†å¸ƒ q\n",
    "\n",
    "# KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’è¨ˆç®—\n",
    "kl_q_p = kl_divergence_normal(mu_q, sigma_q, mu_p, sigma_p)\n",
    "kl_p_q = kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "x = np.linspace(-5, 6, 1000)\n",
    "p = stats.norm.pdf(x, mu_p, sigma_p)\n",
    "q = stats.norm.pdf(x, mu_q, sigma_q)\n",
    "\n",
    "# å·¦: 2ã¤ã®åˆ†å¸ƒ\n",
    "axes[0].plot(x, p, 'b-', linewidth=2, label=f'p(x) = N({mu_p}, {sigma_p}Â²)')\n",
    "axes[0].plot(x, q, 'r-', linewidth=2, label=f'q(x) = N({mu_q}, {sigma_q}Â²)')\n",
    "axes[0].fill_between(x, p, alpha=0.3, color='blue')\n",
    "axes[0].fill_between(x, q, alpha=0.3, color='red')\n",
    "axes[0].set_xlabel('x', fontsize=12)\n",
    "axes[0].set_ylabel('ç¢ºç‡å¯†åº¦', fontsize=12)\n",
    "axes[0].set_title('2ã¤ã®æ­£è¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# ä¸­å¤®: log(q/p)ã®å¯è¦–åŒ–\n",
    "log_ratio = np.log(q / p)\n",
    "axes[1].plot(x, log_ratio, 'g-', linewidth=2)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].fill_between(x, log_ratio, where=log_ratio >= 0, alpha=0.3, color='green')\n",
    "axes[1].fill_between(x, log_ratio, where=log_ratio < 0, alpha=0.3, color='red')\n",
    "axes[1].set_xlabel('x', fontsize=12)\n",
    "axes[1].set_ylabel('log(q(x)/p(x))', fontsize=12)\n",
    "axes[1].set_title('log(q/p): KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®è¢«ç©åˆ†é–¢æ•°', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(-3, 3)\n",
    "\n",
    "# å³: KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®éå¯¾ç§°æ€§\n",
    "mu_q_range = np.linspace(-3, 3, 100)\n",
    "kl_values = [kl_divergence_normal(mu, 1, 0, 1) for mu in mu_q_range]\n",
    "\n",
    "axes[2].plot(mu_q_range, kl_values, 'purple', linewidth=2)\n",
    "axes[2].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[2].set_xlabel('q ã®å¹³å‡ Î¼_q', fontsize=12)\n",
    "axes[2].set_ylabel('D_KL(q || p)', fontsize=12)\n",
    "axes[2].set_title('å¹³å‡ã®é•ã„ã¨KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹\\n(Ïƒ_q = Ïƒ_p = 1)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®è¨ˆç®—çµæœ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"D_KL(q || p) = {kl_q_p:.4f}\")\n",
    "print(f\"D_KL(p || q) = {kl_p_q:.4f}\")\n",
    "print(f\"\\nâ†’ éå¯¾ç§°æ€§: D_KL(q || p) â‰  D_KL(p || q)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ELBOï¼ˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ä¸‹ç•Œï¼‰\n",
    "\n",
    "### ğŸ¤” å•é¡Œã®è¨­å®š\n",
    "\n",
    "æ½œåœ¨å¤‰æ•° $z$ ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã§ã€è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ $X$ ã®å¯¾æ•°å°¤åº¦ã‚’æœ€å¤§åŒ–ã—ãŸã„ï¼š\n",
    "\n",
    "$$\\log p(X | \\theta) = \\log \\int p(X, z | \\theta) dz$$\n",
    "\n",
    "ã“ã®ç©åˆ†ã¯ä¸€èˆ¬ã«è§£æçš„ã«è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆGMMã®å ´åˆã€å’Œã«ãªã‚Šã¾ã™ï¼‰ã€‚\n",
    "\n",
    "### ğŸ“Š ELBOã®å°å‡º\n",
    "\n",
    "ä»»æ„ã®åˆ†å¸ƒ $q(z)$ ã‚’å°å…¥ã—ã¦ã€å¯¾æ•°å°¤åº¦ã‚’åˆ†è§£ã—ã¾ã™ï¼š\n",
    "\n",
    "$$\\log p(X) = \\log \\int p(X, z) dz = \\log \\int q(z) \\frac{p(X, z)}{q(z)} dz$$\n",
    "\n",
    "Jensenã®ä¸ç­‰å¼ï¼ˆ$\\log$ ã¯å‡¹é–¢æ•°ï¼‰ã‚’é©ç”¨ï¼š\n",
    "\n",
    "$$\\log p(X) \\geq \\int q(z) \\log \\frac{p(X, z)}{q(z)} dz = \\mathcal{L}(q, \\theta)$$\n",
    "\n",
    "ã“ã®ä¸‹ç•Œ $\\mathcal{L}(q, \\theta)$ ã‚’**ELBOï¼ˆEvidence Lower BOundï¼‰**ã¨å‘¼ã³ã¾ã™ã€‚\n",
    "\n",
    "### ğŸ“Š ELBOã®åˆ†è§£\n",
    "\n",
    "ELBOã¯2é€šã‚Šã«åˆ†è§£ã§ãã¾ã™ï¼š\n",
    "\n",
    "**åˆ†è§£1**:\n",
    "$$\\mathcal{L}(q, \\theta) = \\mathbb{E}_{q}[\\log p(X, z)] - \\mathbb{E}_{q}[\\log q(z)]$$\n",
    "$$= \\mathbb{E}_{q}[\\log p(X, z)] + H[q]$$\n",
    "\n",
    "**åˆ†è§£2**:\n",
    "$$\\log p(X) = \\mathcal{L}(q, \\theta) + D_{KL}(q(z) \\| p(z|X))$$\n",
    "\n",
    "â†’ ELBOã¯å¯¾æ•°å°¤åº¦ã‹ã‚‰KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’å¼•ã„ãŸã‚‚ã®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ELBOã®å¯è¦–åŒ–\n",
    "# å¯¾æ•°å°¤åº¦ã¨ELBOã®é–¢ä¿‚ã‚’å›³ç¤ºã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# æ¦‚å¿µå›³ã‚’æç”»\n",
    "# å¯¾æ•°å°¤åº¦ï¼ˆå›ºå®šå€¤ã¨ã—ã¦è¡¨ç¤ºï¼‰\n",
    "log_likelihood = 5\n",
    "\n",
    "# æ§˜ã€…ãªqã§ã®ELBOã¨KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹\n",
    "np.random.seed(42)\n",
    "n_points = 50\n",
    "kl_values = np.abs(np.random.normal(0, 2, n_points))  # KLã¯å¸¸ã«éè² \n",
    "elbo_values = log_likelihood - kl_values\n",
    "\n",
    "# ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "x_pos = np.arange(n_points)\n",
    "ax.bar(x_pos, elbo_values, color='steelblue', alpha=0.7, label='ELBO')\n",
    "ax.bar(x_pos, kl_values, bottom=elbo_values, color='coral', alpha=0.7, label='D_KL(q || p(z|X))')\n",
    "ax.axhline(y=log_likelihood, color='green', linewidth=3, linestyle='--', label=f'log p(X) = {log_likelihood}')\n",
    "\n",
    "ax.set_xlabel('ç•°ãªã‚‹ q(z) ã®é¸æŠ', fontsize=12)\n",
    "ax.set_ylabel('å€¤', fontsize=12)\n",
    "ax.set_title('ELBOã¨å¯¾æ•°å°¤åº¦ã®é–¢ä¿‚\\nlog p(X) = ELBO + D_KL(q || p(z|X))', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(-2, 7)\n",
    "\n",
    "# æœ€é©ãªqã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆKL=0ã®ã¨ãï¼‰\n",
    "best_idx = np.argmin(kl_values)\n",
    "ax.bar(best_idx, elbo_values[best_idx], color='green', alpha=0.9)\n",
    "ax.annotate('æœ€é©ãª q\\n(q = p(z|X))', xy=(best_idx, log_likelihood), \n",
    "            xytext=(best_idx+5, log_likelihood+0.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='green'),\n",
    "            fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ELBOã®é‡è¦ãªæ€§è³ª\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. ELBO â‰¤ log p(X) ï¼ˆå¸¸ã«å¯¾æ•°å°¤åº¦ã®ä¸‹ç•Œï¼‰\")\n",
    "print(\"2. q(z) = p(z|X) ã®ã¨ãã€ELBO = log p(X) ï¼ˆç­‰å·æˆç«‹ï¼‰\")\n",
    "print(\"3. D_KL â‰¥ 0 ãªã®ã§ã€ã‚®ãƒ£ãƒƒãƒ—ã¯å¸¸ã«éè² \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å°å‡º\n",
    "\n",
    "### ğŸ“Š EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚¢ã‚¤ãƒ‡ã‚¢\n",
    "\n",
    "å¯¾æ•°å°¤åº¦ã‚’ç›´æ¥æœ€å¤§åŒ–ã§ããªã„ã®ã§ã€ä»£ã‚ã‚Šã«ELBOã‚’æœ€å¤§åŒ–ã—ã¾ã™ï¼š\n",
    "\n",
    "$$\\log p(X|\\theta) \\geq \\mathcal{L}(q, \\theta)$$\n",
    "\n",
    "EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€$q$ ã¨ $\\theta$ ã‚’äº¤äº’ã«æœ€é©åŒ–ã—ã¾ã™ï¼š\n",
    "\n",
    "1. **Eã‚¹ãƒ†ãƒƒãƒ—**: $\\theta$ ã‚’å›ºå®šã—ã¦ã€$q$ ã‚’æœ€é©åŒ–\n",
    "2. **Mã‚¹ãƒ†ãƒƒãƒ—**: $q$ ã‚’å›ºå®šã—ã¦ã€$\\theta$ ã‚’æœ€é©åŒ–\n",
    "\n",
    "### ğŸ“Š Eã‚¹ãƒ†ãƒƒãƒ—ï¼ˆExpectation Stepï¼‰\n",
    "\n",
    "$\\theta^{(t)}$ ã‚’å›ºå®šã—ãŸã¨ãã€ELBOã‚’æœ€å¤§åŒ–ã™ã‚‹ $q$ ã¯ï¼š\n",
    "\n",
    "$$q^*(z) = p(z | X, \\theta^{(t)})$$\n",
    "\n",
    "â†’ ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®**äº‹å¾Œåˆ†å¸ƒ**\n",
    "\n",
    "ã“ã®ã¨ãã€$D_{KL}(q \\| p(z|X)) = 0$ ã¨ãªã‚Šã€ELBO = log p(X) ã¨ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "### ğŸ“Š Mã‚¹ãƒ†ãƒƒãƒ—ï¼ˆMaximization Stepï¼‰\n",
    "\n",
    "$q = p(z | X, \\theta^{(t)})$ ã‚’å›ºå®šã—ã¦ã€$\\theta$ ã«ã¤ã„ã¦ELBOã‚’æœ€å¤§åŒ–ï¼š\n",
    "\n",
    "$$\\theta^{(t+1)} = \\arg\\max_{\\theta} \\mathbb{E}_{q}[\\log p(X, z | \\theta)]$$\n",
    "\n",
    "ã“ã®æœŸå¾…å€¤ã¯ã€Œå®Œå…¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾æ•°å°¤åº¦ã®æœŸå¾…å€¤ã€ã¨å‘¼ã°ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¦‚å¿µå›³\n",
    "# E ã‚¹ãƒ†ãƒƒãƒ—ã¨ M ã‚¹ãƒ†ãƒƒãƒ—ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# E ã‚¹ãƒ†ãƒƒãƒ—ã®å›³\n",
    "ax = axes[0]\n",
    "theta_fixed = 2\n",
    "q_range = np.linspace(0.5, 3.5, 100)\n",
    "\n",
    "# ç–‘ä¼¼çš„ãªELBOæ›²ç·šï¼ˆqã«ã¤ã„ã¦ï¼‰\n",
    "elbo_curve = -0.5 * (q_range - theta_fixed)**2 + 3\n",
    "log_p = 3.5  # å¯¾æ•°å°¤åº¦ï¼ˆå›ºå®šï¼‰\n",
    "\n",
    "ax.plot(q_range, elbo_curve, 'b-', linewidth=2, label='ELBO(q)')\n",
    "ax.axhline(y=log_p, color='green', linestyle='--', linewidth=2, label='log p(X)')\n",
    "ax.axvline(x=theta_fixed, color='red', linestyle=':', alpha=0.7)\n",
    "ax.scatter([theta_fixed], [3], color='red', s=150, zorder=5, marker='*')\n",
    "ax.fill_between(q_range, elbo_curve, log_p, alpha=0.2, color='coral', label='KL divergence')\n",
    "\n",
    "ax.set_xlabel('q', fontsize=12)\n",
    "ax.set_ylabel('å€¤', fontsize=12)\n",
    "ax.set_title('E ã‚¹ãƒ†ãƒƒãƒ—: q ã‚’æœ€é©åŒ–\\n(Î¸ ã‚’å›ºå®š)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.annotate('q* = p(z|X,Î¸)', xy=(theta_fixed, 3), xytext=(theta_fixed+0.8, 2),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'), fontsize=11)\n",
    "\n",
    "# M ã‚¹ãƒ†ãƒƒãƒ—ã®å›³\n",
    "ax = axes[1]\n",
    "theta_range = np.linspace(0, 4, 100)\n",
    "q_fixed = 2\n",
    "\n",
    "# ç–‘ä¼¼çš„ãªæœŸå¾…å¯¾æ•°å°¤åº¦æ›²ç·šï¼ˆÎ¸ã«ã¤ã„ã¦ï¼‰\n",
    "expected_ll = -0.3 * (theta_range - 2.5)**2 + 2\n",
    "\n",
    "ax.plot(theta_range, expected_ll, 'purple', linewidth=2, label='E_q[log p(X,z|Î¸)]')\n",
    "ax.axvline(x=2.5, color='red', linestyle=':', alpha=0.7)\n",
    "ax.scatter([2.5], [2], color='red', s=150, zorder=5, marker='*')\n",
    "\n",
    "ax.set_xlabel('Î¸', fontsize=12)\n",
    "ax.set_ylabel('æœŸå¾…å¯¾æ•°å°¤åº¦', fontsize=12)\n",
    "ax.set_title('M ã‚¹ãƒ†ãƒƒãƒ—: Î¸ ã‚’æœ€é©åŒ–\\n(q ã‚’å›ºå®š)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.annotate('Î¸* = argmax', xy=(2.5, 2), xytext=(3.2, 1),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'), fontsize=11)\n",
    "\n",
    "# åæŸã®æ§˜å­\n",
    "ax = axes[2]\n",
    "iterations = np.arange(10)\n",
    "# å¯¾æ•°å°¤åº¦ãŒå˜èª¿å¢—åŠ ã™ã‚‹æ§˜å­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ\n",
    "log_likelihood_curve = 3.5 - 2 * np.exp(-0.5 * iterations)\n",
    "\n",
    "ax.plot(iterations, log_likelihood_curve, 'go-', linewidth=2, markersize=8, label='log p(X|Î¸)')\n",
    "ax.axhline(y=3.5, color='gray', linestyle='--', alpha=0.5, label='åæŸå€¤')\n",
    "ax.set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=12)\n",
    "ax.set_ylabel('å¯¾æ•°å°¤åº¦', fontsize=12)\n",
    "ax.set_title('EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åæŸ\\nï¼ˆå˜èª¿å¢—åŠ ãŒä¿è¨¼ã•ã‚Œã‚‹ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã¾ã¨ã‚\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nã€E ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(\"  ç¾åœ¨ã®Î¸ã§äº‹å¾Œåˆ†å¸ƒ q(z) = p(z|X,Î¸) ã‚’è¨ˆç®—\")\n",
    "print(\"  â†’ GMMã§ã¯ã€è²¬ä»»ç‡ã€ã®è¨ˆç®—ã«å¯¾å¿œ\")\n",
    "print(\"\\nã€M ã‚¹ãƒ†ãƒƒãƒ—ã€‘\")\n",
    "print(\"  E_q[log p(X,z|Î¸)] ã‚’æœ€å¤§åŒ–ã™ã‚‹Î¸ã‚’è¨ˆç®—\")\n",
    "print(\"  â†’ GMMã§ã¯æ··åˆä¿‚æ•°ã€å¹³å‡ã€å…±åˆ†æ•£ã®æ›´æ–°ã«å¯¾å¿œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. GMMã¸ã®EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é©ç”¨\n",
    "\n",
    "### ğŸ“Š GMMã®è¨­å®š\n",
    "\n",
    "- è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿: $X = \\{\\mathbf{x}_1, ..., \\mathbf{x}_N\\}$\n",
    "- æ½œåœ¨å¤‰æ•°: $Z = \\{z_1, ..., z_N\\}$ã€$z_n \\in \\{1, ..., K\\}$\n",
    "- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: $\\theta = \\{\\pi_k, \\boldsymbol{\\mu}_k, \\Sigma_k\\}_{k=1}^K$\n",
    "\n",
    "### ğŸ“Š Eã‚¹ãƒ†ãƒƒãƒ—: è²¬ä»»ç‡ã®è¨ˆç®—\n",
    "\n",
    "$$\\gamma_{nk} = p(z_n = k | \\mathbf{x}_n, \\theta) = \\frac{\\pi_k \\mathcal{N}(\\mathbf{x}_n | \\boldsymbol{\\mu}_k, \\Sigma_k)}{\\sum_{j=1}^{K} \\pi_j \\mathcal{N}(\\mathbf{x}_n | \\boldsymbol{\\mu}_j, \\Sigma_j)}$$\n",
    "\n",
    "### ğŸ“Š Mã‚¹ãƒ†ãƒƒãƒ—: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°\n",
    "\n",
    "**æ··åˆä¿‚æ•°**:\n",
    "$$\\pi_k^{\\text{new}} = \\frac{N_k}{N}, \\quad N_k = \\sum_{n=1}^{N} \\gamma_{nk}$$\n",
    "\n",
    "**å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«**:\n",
    "$$\\boldsymbol{\\mu}_k^{\\text{new}} = \\frac{1}{N_k} \\sum_{n=1}^{N} \\gamma_{nk} \\mathbf{x}_n$$\n",
    "\n",
    "**å…±åˆ†æ•£è¡Œåˆ—**:\n",
    "$$\\Sigma_k^{\\text{new}} = \\frac{1}{N_k} \\sum_{n=1}^{N} \\gamma_{nk} (\\mathbf{x}_n - \\boldsymbol{\\mu}_k^{\\text{new}})(\\mathbf{x}_n - \\boldsymbol{\\mu}_k^{\\text{new}})^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GMMç”¨EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…\n",
    "# ã‚¹ã‚¯ãƒ©ãƒƒãƒã§EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "class GMMFromScratch:\n",
    "    \"\"\"\n",
    "    EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹æ··åˆã‚¬ã‚¦ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆGMMï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components, max_iter=100, tol=1e-6, random_state=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_components : int\n",
    "            æ··åˆæˆåˆ†ã®æ•°\n",
    "        max_iter : int\n",
    "            æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°\n",
    "        tol : float\n",
    "            åæŸåˆ¤å®šã®é–¾å€¤\n",
    "        random_state : int\n",
    "            ä¹±æ•°ã‚·ãƒ¼ãƒ‰\n",
    "        \"\"\"\n",
    "        self.K = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "        self.weights_ = None\n",
    "        self.means_ = None\n",
    "        self.covariances_ = None\n",
    "        \n",
    "        # å±¥æ­´\n",
    "        self.log_likelihoods_ = []\n",
    "        self.n_iter_ = 0\n",
    "    \n",
    "    def _initialize(self, X):\n",
    "        \"\"\"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸåŒ–\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        N, d = X.shape\n",
    "        \n",
    "        # æ··åˆä¿‚æ•°: å‡ç­‰ã«åˆæœŸåŒ–\n",
    "        self.weights_ = np.ones(self.K) / self.K\n",
    "        \n",
    "        # å¹³å‡: ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’é¸æŠ\n",
    "        indices = np.random.choice(N, self.K, replace=False)\n",
    "        self.means_ = X[indices].copy()\n",
    "        \n",
    "        # å…±åˆ†æ•£è¡Œåˆ—: ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã®å…±åˆ†æ•£ã§åˆæœŸåŒ–\n",
    "        self.covariances_ = np.array([np.cov(X.T) for _ in range(self.K)])\n",
    "    \n",
    "    def _e_step(self, X):\n",
    "        \"\"\"\n",
    "        Eã‚¹ãƒ†ãƒƒãƒ—: è²¬ä»»ç‡ã‚’è¨ˆç®—\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        responsibilities : array, shape (N, K)\n",
    "            å„ãƒ‡ãƒ¼ã‚¿ç‚¹ã®å„æˆåˆ†ã¸ã®è²¬ä»»ç‡\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        log_resp = np.zeros((N, self.K))\n",
    "        \n",
    "        for k in range(self.K):\n",
    "            # å¯¾æ•°ç¢ºç‡å¯†åº¦ã‚’è¨ˆç®—ï¼ˆæ•°å€¤å®‰å®šæ€§ã®ãŸã‚ï¼‰\n",
    "            log_resp[:, k] = (np.log(self.weights_[k]) + \n",
    "                             self._log_multivariate_normal(X, self.means_[k], self.covariances_[k]))\n",
    "        \n",
    "        # å¯¾æ•°è²¬ä»»ç‡ã‚’æ­£è¦åŒ–ï¼ˆlogsumexpã‚’ä½¿ç”¨ï¼‰\n",
    "        log_resp_normalized = log_resp - logsumexp(log_resp, axis=1, keepdims=True)\n",
    "        \n",
    "        return np.exp(log_resp_normalized)\n",
    "    \n",
    "    def _m_step(self, X, resp):\n",
    "        \"\"\"\n",
    "        Mã‚¹ãƒ†ãƒƒãƒ—: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array, shape (N, d)\n",
    "            ãƒ‡ãƒ¼ã‚¿\n",
    "        resp : array, shape (N, K)\n",
    "            è²¬ä»»ç‡\n",
    "        \"\"\"\n",
    "        N, d = X.shape\n",
    "        \n",
    "        # N_k: å„æˆåˆ†ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹å®ŸåŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "        N_k = resp.sum(axis=0)  # shape: (K,)\n",
    "        \n",
    "        # æ··åˆä¿‚æ•°ã®æ›´æ–°\n",
    "        self.weights_ = N_k / N\n",
    "        \n",
    "        # å¹³å‡ã®æ›´æ–°\n",
    "        self.means_ = (resp.T @ X) / N_k[:, np.newaxis]  # shape: (K, d)\n",
    "        \n",
    "        # å…±åˆ†æ•£è¡Œåˆ—ã®æ›´æ–°\n",
    "        for k in range(self.K):\n",
    "            diff = X - self.means_[k]  # shape: (N, d)\n",
    "            # é‡ã¿ä»˜ãå…±åˆ†æ•£\n",
    "            weighted_cov = (resp[:, k:k+1] * diff).T @ diff / N_k[k]\n",
    "            # æ­£å‰‡åŒ–ï¼ˆæ•°å€¤å®‰å®šæ€§ã®ãŸã‚ï¼‰\n",
    "            self.covariances_[k] = weighted_cov + 1e-6 * np.eye(d)\n",
    "    \n",
    "    def _log_multivariate_normal(self, X, mean, cov):\n",
    "        \"\"\"å¤šæ¬¡å…ƒæ­£è¦åˆ†å¸ƒã®å¯¾æ•°ç¢ºç‡å¯†åº¦\"\"\"\n",
    "        d = len(mean)\n",
    "        diff = X - mean\n",
    "        \n",
    "        # ã‚³ãƒ¬ã‚¹ã‚­ãƒ¼åˆ†è§£ã§å®‰å®šã«è¨ˆç®—\n",
    "        try:\n",
    "            L = np.linalg.cholesky(cov)\n",
    "            log_det = 2 * np.sum(np.log(np.diag(L)))\n",
    "            y = np.linalg.solve(L, diff.T).T\n",
    "            mahal = np.sum(y**2, axis=1)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # ã‚³ãƒ¬ã‚¹ã‚­ãƒ¼åˆ†è§£ãŒå¤±æ•—ã—ãŸå ´åˆ\n",
    "            log_det = np.log(np.linalg.det(cov) + 1e-10)\n",
    "            cov_inv = np.linalg.pinv(cov)\n",
    "            mahal = np.sum(diff @ cov_inv * diff, axis=1)\n",
    "        \n",
    "        log_pdf = -0.5 * (d * np.log(2 * np.pi) + log_det + mahal)\n",
    "        return log_pdf\n",
    "    \n",
    "    def _compute_log_likelihood(self, X):\n",
    "        \"\"\"å¯¾æ•°å°¤åº¦ã‚’è¨ˆç®—\"\"\"\n",
    "        N = X.shape[0]\n",
    "        log_prob = np.zeros((N, self.K))\n",
    "        \n",
    "        for k in range(self.K):\n",
    "            log_prob[:, k] = (np.log(self.weights_[k]) + \n",
    "                             self._log_multivariate_normal(X, self.means_[k], self.covariances_[k]))\n",
    "        \n",
    "        return np.sum(logsumexp(log_prob, axis=1))\n",
    "    \n",
    "    def fit(self, X, verbose=False):\n",
    "        \"\"\"\n",
    "        EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array, shape (N, d)\n",
    "            è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "        verbose : bool\n",
    "            é€²æ—ã‚’è¡¨ç¤ºã™ã‚‹ã‹\n",
    "        \"\"\"\n",
    "        # åˆæœŸåŒ–\n",
    "        self._initialize(X)\n",
    "        \n",
    "        # åˆæœŸå¯¾æ•°å°¤åº¦\n",
    "        prev_ll = self._compute_log_likelihood(X)\n",
    "        self.log_likelihoods_ = [prev_ll]\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            # E ã‚¹ãƒ†ãƒƒãƒ—\n",
    "            resp = self._e_step(X)\n",
    "            \n",
    "            # M ã‚¹ãƒ†ãƒƒãƒ—\n",
    "            self._m_step(X, resp)\n",
    "            \n",
    "            # å¯¾æ•°å°¤åº¦ã‚’è¨ˆç®—\n",
    "            curr_ll = self._compute_log_likelihood(X)\n",
    "            self.log_likelihoods_.append(curr_ll)\n",
    "            \n",
    "            if verbose and iteration % 10 == 0:\n",
    "                print(f\"Iteration {iteration}: log-likelihood = {curr_ll:.4f}\")\n",
    "            \n",
    "            # åæŸåˆ¤å®š\n",
    "            if abs(curr_ll - prev_ll) < self.tol:\n",
    "                if verbose:\n",
    "                    print(f\"Converged at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "            prev_ll = curr_ll\n",
    "            self.n_iter_ = iteration + 1\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"å„ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’æœ€ã‚‚è²¬ä»»ç‡ãŒé«˜ã„æˆåˆ†ã«å‰²ã‚Šå½“ã¦\"\"\"\n",
    "        resp = self._e_step(X)\n",
    "        return np.argmax(resp, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"è²¬ä»»ç‡ã‚’è¿”ã™\"\"\"\n",
    "        return self._e_step(X)\n",
    "\n",
    "print(\"âœ… GMMFromScratch ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œã¨ãƒ†ã‚¹ãƒˆ\n",
    "# å®Ÿè£…ã—ãŸGMMã‚’ä½¿ã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆ3æˆåˆ†ã®GMMï¼‰\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 500\n",
    "true_weights = [0.4, 0.35, 0.25]\n",
    "true_means = [\n",
    "    np.array([0, 0]),\n",
    "    np.array([4, 4]),\n",
    "    np.array([-3, 4]),\n",
    "]\n",
    "true_covs = [\n",
    "    np.array([[1, 0.5], [0.5, 1]]),\n",
    "    np.array([[1.5, -0.5], [-0.5, 0.8]]),\n",
    "    np.array([[0.8, 0], [0, 1.2]]),\n",
    "]\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ\n",
    "samples = []\n",
    "true_labels = []\n",
    "for i in range(n_samples):\n",
    "    k = np.random.choice(3, p=true_weights)\n",
    "    x = np.random.multivariate_normal(true_means[k], true_covs[k])\n",
    "    samples.append(x)\n",
    "    true_labels.append(k)\n",
    "\n",
    "X = np.array(samples)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œ\n",
    "gmm_scratch = GMMFromScratch(n_components=3, max_iter=100, random_state=42)\n",
    "gmm_scratch.fit(X, verbose=True)\n",
    "\n",
    "# çµæœã‚’è¡¨ç¤º\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¨å®šçµæœ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nåæŸã¾ã§ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {gmm_scratch.n_iter_}\")\n",
    "print(f\"\\næ¨å®šã•ã‚ŒãŸæ··åˆä¿‚æ•°: {gmm_scratch.weights_.round(3)}\")\n",
    "print(f\"çœŸã®æ··åˆä¿‚æ•°: {true_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åæŸéç¨‹ã‚’å¯è¦–åŒ–\n",
    "# å¯¾æ•°å°¤åº¦ã®æ¨ç§»ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’è¡¨ç¤ºã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# å·¦ä¸Š: å¯¾æ•°å°¤åº¦ã®æ¨ç§»\n",
    "ax = axes[0, 0]\n",
    "ax.plot(gmm_scratch.log_likelihoods_, 'bo-', linewidth=2, markersize=4)\n",
    "ax.set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=12)\n",
    "ax.set_ylabel('å¯¾æ•°å°¤åº¦', fontsize=12)\n",
    "ax.set_title('EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åæŸ\\nï¼ˆå¯¾æ•°å°¤åº¦ã¯å˜èª¿å¢—åŠ ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# å³ä¸Š: çœŸã®ãƒ©ãƒ™ãƒ«\n",
    "ax = axes[0, 1]\n",
    "colors = ['steelblue', 'coral', 'green']\n",
    "for k in range(3):\n",
    "    mask = true_labels == k\n",
    "    ax.scatter(X[mask, 0], X[mask, 1], c=colors[k], alpha=0.6, s=30, label=f'æˆåˆ† {k+1}')\n",
    "    ax.scatter(true_means[k][0], true_means[k][1], c=colors[k], s=300, \n",
    "              marker='*', edgecolors='black', linewidths=2)\n",
    "ax.set_xlabel('Xâ‚', fontsize=12)\n",
    "ax.set_ylabel('Xâ‚‚', fontsize=12)\n",
    "ax.set_title('çœŸã®ãƒ©ãƒ™ãƒ«\\nï¼ˆâ˜… = çœŸã®å¹³å‡ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# å·¦ä¸‹: æ¨å®šã•ã‚ŒãŸãƒ©ãƒ™ãƒ«\n",
    "ax = axes[1, 0]\n",
    "predicted_labels = gmm_scratch.predict(X)\n",
    "for k in range(3):\n",
    "    mask = predicted_labels == k\n",
    "    ax.scatter(X[mask, 0], X[mask, 1], c=colors[k], alpha=0.6, s=30, label=f'æˆåˆ† {k+1}')\n",
    "    ax.scatter(gmm_scratch.means_[k, 0], gmm_scratch.means_[k, 1], c=colors[k], s=300, \n",
    "              marker='X', edgecolors='black', linewidths=2)\n",
    "ax.set_xlabel('Xâ‚', fontsize=12)\n",
    "ax.set_ylabel('Xâ‚‚', fontsize=12)\n",
    "ax.set_title('EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµæœ\\nï¼ˆX = æ¨å®šã•ã‚ŒãŸå¹³å‡ï¼‰', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# å³ä¸‹: ç¢ºç‡å¯†åº¦ã®ç­‰é«˜ç·š\n",
    "ax = axes[1, 1]\n",
    "x = np.linspace(-6, 8, 200)\n",
    "y = np.linspace(-3, 8, 200)\n",
    "X_grid, Y_grid = np.meshgrid(x, y)\n",
    "XY = np.column_stack([X_grid.ravel(), Y_grid.ravel()])\n",
    "\n",
    "# æ¨å®šã•ã‚ŒãŸGMMã®å¯†åº¦ã‚’è¨ˆç®—\n",
    "Z = np.zeros(XY.shape[0])\n",
    "for k in range(3):\n",
    "    rv = stats.multivariate_normal(gmm_scratch.means_[k], gmm_scratch.covariances_[k])\n",
    "    Z += gmm_scratch.weights_[k] * rv.pdf(XY)\n",
    "Z = Z.reshape(X_grid.shape)\n",
    "\n",
    "ax.contourf(X_grid, Y_grid, Z, levels=20, cmap='viridis', alpha=0.7)\n",
    "ax.contour(X_grid, Y_grid, Z, levels=10, colors='white', alpha=0.5)\n",
    "ax.scatter(X[:, 0], X[:, 1], c='white', alpha=0.2, s=10)\n",
    "for k in range(3):\n",
    "    ax.scatter(gmm_scratch.means_[k, 0], gmm_scratch.means_[k, 1], c='red', s=200, \n",
    "              marker='*', edgecolors='white', linewidths=2)\n",
    "ax.set_xlabel('Xâ‚', fontsize=12)\n",
    "ax.set_ylabel('Xâ‚‚', fontsize=12)\n",
    "ax.set_title('æ¨å®šã•ã‚ŒãŸGMMå¯†åº¦', fontsize=14, fontweight='bold')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åæŸæ€§è³ª\n",
    "\n",
    "### ğŸ“Š åæŸã®ä¿è¨¼\n",
    "\n",
    "EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¯ä»¥ä¸‹ã®é‡è¦ãªæ€§è³ªãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "1. **å˜èª¿å¢—åŠ æ€§**: å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§å¯¾æ•°å°¤åº¦ã¯æ¸›å°‘ã—ãªã„\n",
    "   $$\\log p(X | \\theta^{(t+1)}) \\geq \\log p(X | \\theta^{(t)})$$\n",
    "\n",
    "2. **åæŸã®ä¿è¨¼**: å±€æ‰€æœ€é©è§£ã«åæŸã™ã‚‹ï¼ˆãŸã ã—å¤§åŸŸæœ€é©ã¨ã¯é™ã‚‰ãªã„ï¼‰\n",
    "\n",
    "3. **åˆæœŸå€¤ä¾å­˜æ€§**: çµæœã¯åˆæœŸå€¤ã«ä¾å­˜ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# åˆæœŸå€¤ã®å½±éŸ¿\n",
    "# ç•°ãªã‚‹åˆæœŸå€¤ã§ã®åæŸã‚’æ¯”è¼ƒã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# 6ã¤ã®ç•°ãªã‚‹åˆæœŸå€¤ã§å®Ÿé¨“\n",
    "seeds = [42, 123, 456, 789, 101, 202]\n",
    "\n",
    "for idx, seed in enumerate(seeds):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    # EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œ\n",
    "    gmm = GMMFromScratch(n_components=3, max_iter=100, random_state=seed)\n",
    "    gmm.fit(X)\n",
    "    \n",
    "    # å¯¾æ•°å°¤åº¦ã®æ¨ç§»ã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    ax.plot(gmm.log_likelihoods_, 'o-', linewidth=2, markersize=3)\n",
    "    ax.set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=11)\n",
    "    ax.set_ylabel('å¯¾æ•°å°¤åº¦', fontsize=11)\n",
    "    final_ll = gmm.log_likelihoods_[-1]\n",
    "    ax.set_title(f'åˆæœŸå€¤ seed={seed}\\næœ€çµ‚å¯¾æ•°å°¤åº¦: {final_ll:.2f}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('åˆæœŸå€¤ã«ã‚ˆã‚‹EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åæŸã®é•ã„', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ ãƒã‚¤ãƒ³ãƒˆ:\")\n",
    "print(\"  - åˆæœŸå€¤ã«ã‚ˆã£ã¦åæŸå…ˆï¼ˆå±€æ‰€æœ€é©è§£ï¼‰ãŒç•°ãªã‚‹ã“ã¨ãŒã‚ã‚‹\")\n",
    "print(\"  - å®Ÿå‹™ã§ã¯è¤‡æ•°ã®åˆæœŸå€¤ã§å®Ÿè¡Œã—ã€æœ€è‰¯ã®çµæœã‚’é¸ã¶\")\n",
    "print(\"  - sklearn ã® GaussianMixture ã¯ n_init ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã“ã‚Œã‚’è¡Œã†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å¯è¦–åŒ–\n",
    "# å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’è¡¨ç¤ºã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "# æ–°ã—ã„GMMã‚’ä½œæˆï¼ˆé€”ä¸­çµŒéã‚’ä¿å­˜ã™ã‚‹ãŸã‚ï¼‰\n",
    "class GMMWithHistory(GMMFromScratch):\n",
    "    def fit_with_history(self, X):\n",
    "        \"\"\"å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’ä¿å­˜ã—ãªãŒã‚‰ãƒ•ã‚£ãƒƒãƒˆ\"\"\"\n",
    "        self._initialize(X)\n",
    "        \n",
    "        self.history_ = {\n",
    "            'means': [self.means_.copy()],\n",
    "            'labels': [self.predict(X)],\n",
    "            'log_likelihood': [self._compute_log_likelihood(X)]\n",
    "        }\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            resp = self._e_step(X)\n",
    "            self._m_step(X, resp)\n",
    "            \n",
    "            self.history_['means'].append(self.means_.copy())\n",
    "            self.history_['labels'].append(self.predict(X))\n",
    "            self.history_['log_likelihood'].append(self._compute_log_likelihood(X))\n",
    "            \n",
    "            if iteration > 0:\n",
    "                if abs(self.history_['log_likelihood'][-1] - self.history_['log_likelihood'][-2]) < self.tol:\n",
    "                    break\n",
    "        \n",
    "        return self\n",
    "\n",
    "# å®Ÿè¡Œ\n",
    "np.random.seed(42)\n",
    "gmm_history = GMMWithHistory(n_components=3, max_iter=50, random_state=123)\n",
    "gmm_history.fit_with_history(X)\n",
    "\n",
    "# ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 0, 1, 2, 5, 10, æœ€çµ‚ ã‚’è¡¨ç¤º\n",
    "iterations_to_show = [0, 1, 2, 5, 10, len(gmm_history.history_['means'])-1]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax_idx, iter_idx in enumerate(iterations_to_show):\n",
    "    ax = axes[ax_idx]\n",
    "    \n",
    "    labels = gmm_history.history_['labels'][iter_idx]\n",
    "    means = gmm_history.history_['means'][iter_idx]\n",
    "    ll = gmm_history.history_['log_likelihood'][iter_idx]\n",
    "    \n",
    "    for k in range(3):\n",
    "        mask = labels == k\n",
    "        ax.scatter(X[mask, 0], X[mask, 1], c=colors[k], alpha=0.5, s=20)\n",
    "        ax.scatter(means[k, 0], means[k, 1], c=colors[k], s=200, \n",
    "                  marker='*', edgecolors='black', linewidths=2)\n",
    "    \n",
    "    ax.set_xlabel('Xâ‚', fontsize=11)\n",
    "    ax.set_ylabel('Xâ‚‚', fontsize=11)\n",
    "    ax.set_title(f'Iteration {iter_idx}\\nlog L = {ll:.2f}', fontsize=12, fontweight='bold')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(-6, 8)\n",
    "    ax.set_ylim(-3, 8)\n",
    "\n",
    "plt.suptitle('EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åæŸéç¨‹', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨VAEã®é–¢ä¿‚\n",
    "\n",
    "### ğŸ“Š EMã¨VAEã®å¯¾å¿œ\n",
    "\n",
    "VAEï¼ˆå¤‰åˆ†ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰ã¯ã€EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è€ƒãˆæ–¹ã‚’æ‹¡å¼µã—ãŸã‚‚ã®ã§ã™ï¼š\n",
    "\n",
    "| æ¦‚å¿µ | GMM + EM | VAE |\n",
    "|------|----------|-----|\n",
    "| æ½œåœ¨å¤‰æ•° | é›¢æ•£ï¼ˆã©ã®æˆåˆ†ã‹ï¼‰ | é€£ç¶šï¼ˆæ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ |\n",
    "| ãƒ‡ã‚³ãƒ¼ãƒ€ | $p(x|z) = \\mathcal{N}(\\mu_k, \\Sigma_k)$ | ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ |\n",
    "| äº‹å¾Œåˆ†å¸ƒ | $p(z|x)$ ã‚’è§£æçš„ã«è¨ˆç®— | ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§è¿‘ä¼¼ |\n",
    "| æœ€é©åŒ– | ELBOã‚’äº¤äº’æœ€é©åŒ– | ELBOã‚’å‹¾é…é™ä¸‹ã§æœ€é©åŒ– |\n",
    "\n",
    "VAEã®æå¤±é–¢æ•°ã¯ã¾ã•ã«ELBOã®è² å€¤ã§ã™ï¼š\n",
    "\n",
    "$$\\mathcal{L}_{VAE} = -\\mathcal{L}_{ELBO} = -\\mathbb{E}_{q}[\\log p(x|z)] + D_{KL}(q(z|x) \\| p(z))$$\n",
    "\n",
    "â†’ å†æ§‹æˆèª¤å·® + KLæ­£å‰‡åŒ–é …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EMã¨VAEã®é–¢ä¿‚ã‚’å›³è§£\n",
    "# æ¦‚å¿µçš„ãªå¯¾å¿œã‚’å¯è¦–åŒ–ã—ã¾ã™\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å·¦: GMMã®æ½œåœ¨å¤‰æ•°ï¼ˆé›¢æ•£ï¼‰\n",
    "ax = axes[0]\n",
    "ax.text(0.5, 0.95, 'GMM + EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', ha='center', fontsize=14, fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "# æ½œåœ¨å¤‰æ•°ï¼ˆé›¢æ•£ï¼‰\n",
    "for i, (x, label) in enumerate(zip([0.2, 0.5, 0.8], ['z=1', 'z=2', 'z=3'])):\n",
    "    circle = plt.Circle((x, 0.7), 0.08, color=colors[i], alpha=0.7)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(x, 0.7, label, ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.text(0.5, 0.85, 'æ½œåœ¨å¤‰æ•° zï¼ˆé›¢æ•£ï¼‰', ha='center', fontsize=11)\n",
    "\n",
    "# çŸ¢å°\n",
    "for x in [0.2, 0.5, 0.8]:\n",
    "    ax.annotate('', xy=(x, 0.45), xytext=(x, 0.6),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# ãƒ‡ã‚³ãƒ¼ãƒ€\n",
    "for i, x in enumerate([0.2, 0.5, 0.8]):\n",
    "    ax.text(x, 0.35, f'N(Î¼{i+1}, Î£{i+1})', ha='center', fontsize=10,\n",
    "           bbox=dict(boxstyle='round', facecolor=colors[i], alpha=0.3))\n",
    "\n",
    "# è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿\n",
    "ax.text(0.5, 0.15, 'xï¼ˆè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ï¼‰', ha='center', fontsize=12,\n",
    "       bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "\n",
    "for x in [0.2, 0.5, 0.8]:\n",
    "    ax.annotate('', xy=(0.5, 0.2), xytext=(x, 0.3),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1))\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "# å³: VAEã®æ½œåœ¨å¤‰æ•°ï¼ˆé€£ç¶šï¼‰\n",
    "ax = axes[1]\n",
    "ax.text(0.5, 0.95, 'VAE', ha='center', fontsize=14, fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "# æ½œåœ¨ç©ºé–“ï¼ˆé€£ç¶šï¼‰\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "r = 0.15\n",
    "ax.fill(0.5 + r*np.cos(theta), 0.7 + r*0.7*np.sin(theta), alpha=0.3, color='purple')\n",
    "ax.text(0.5, 0.7, 'z âˆˆ â„^d', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "ax.text(0.5, 0.88, 'æ½œåœ¨å¤‰æ•° zï¼ˆé€£ç¶šï¼‰', ha='center', fontsize=11)\n",
    "\n",
    "# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€\n",
    "ax.annotate('', xy=(0.3, 0.65), xytext=(0.3, 0.25),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=2))\n",
    "ax.text(0.15, 0.45, 'Encoder\\nq(z|x)', ha='center', fontsize=10, color='blue')\n",
    "\n",
    "# ãƒ‡ã‚³ãƒ¼ãƒ€\n",
    "ax.annotate('', xy=(0.7, 0.25), xytext=(0.7, 0.55),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "ax.text(0.85, 0.45, 'Decoder\\np(x|z)', ha='center', fontsize=10, color='red')\n",
    "\n",
    "# è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿\n",
    "ax.text(0.5, 0.15, 'xï¼ˆè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ï¼‰', ha='center', fontsize=12,\n",
    "       bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‹ã‚‰VAEã¸\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. æ½œåœ¨å¤‰æ•°ã‚’é›¢æ•£ã‹ã‚‰é€£ç¶šã«æ‹¡å¼µ\")\n",
    "print(\"2. ãƒ‡ã‚³ãƒ¼ãƒ€ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«\")\n",
    "print(\"3. äº‹å¾Œåˆ†å¸ƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§è¿‘ä¼¼\")\n",
    "print(\"4. ELBOã‚’å‹¾é…é™ä¸‹æ³•ã§æœ€é©åŒ–\")\n",
    "print(\"\\nâ†’ ã“ã‚ŒãŒVAEã®åŸºæœ¬çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã§ã™ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ã¾ã¨ã‚\n",
    "\n",
    "### ğŸ¯ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å­¦ã‚“ã ã“ã¨\n",
    "\n",
    "**KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹**\n",
    "- âœ“ 2ã¤ã®åˆ†å¸ƒã®ã€Œé•ã„ã€ã‚’æ¸¬ã‚‹æŒ‡æ¨™\n",
    "- âœ“ éè² æ€§ã€éå¯¾ç§°æ€§ã‚’æŒã¤\n",
    "- âœ“ $D_{KL}(q \\| p) = \\mathbb{E}_q[\\log(q/p)]$\n",
    "\n",
    "**ELBO**\n",
    "- âœ“ å¯¾æ•°å°¤åº¦ã®ä¸‹ç•Œ: $\\log p(X) \\geq \\mathcal{L}(q, \\theta)$\n",
    "- âœ“ $\\log p(X) = \\mathcal{L} + D_{KL}(q \\| p(z|X))$\n",
    "- âœ“ $q = p(z|X)$ ã®ã¨ãç­‰å·æˆç«‹\n",
    "\n",
    "**EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **\n",
    "- âœ“ E ã‚¹ãƒ†ãƒƒãƒ—: $q(z) = p(z|X, \\theta^{(t)})$ ã‚’è¨ˆç®—ï¼ˆè²¬ä»»ç‡ï¼‰\n",
    "- âœ“ M ã‚¹ãƒ†ãƒƒãƒ—: $\\theta$ ã‚’æ›´æ–°ï¼ˆæ··åˆä¿‚æ•°ã€å¹³å‡ã€å…±åˆ†æ•£ï¼‰\n",
    "- âœ“ å¯¾æ•°å°¤åº¦ã¯å˜èª¿å¢—åŠ ã€å±€æ‰€æœ€é©è§£ã«åæŸ\n",
    "\n",
    "### ğŸ“Š GMMã®EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆ\n",
    "\n",
    "| ã‚¹ãƒ†ãƒƒãƒ— | è¨ˆç®—å†…å®¹ |\n",
    "|---------|----------|\n",
    "| **E ã‚¹ãƒ†ãƒƒãƒ—** | $\\gamma_{nk} = \\frac{\\pi_k \\mathcal{N}(x_n \\| \\mu_k, \\Sigma_k)}{\\sum_j \\pi_j \\mathcal{N}(x_n \\| \\mu_j, \\Sigma_j)}$ |\n",
    "| **M ã‚¹ãƒ†ãƒƒãƒ— (Ï€)** | $\\pi_k = N_k / N$ |\n",
    "| **M ã‚¹ãƒ†ãƒƒãƒ— (Î¼)** | $\\mu_k = \\frac{1}{N_k}\\sum_n \\gamma_{nk} x_n$ |\n",
    "| **M ã‚¹ãƒ†ãƒƒãƒ— (Î£)** | $\\Sigma_k = \\frac{1}{N_k}\\sum_n \\gamma_{nk}(x_n - \\mu_k)(x_n - \\mu_k)^T$ |\n",
    "\n",
    "### ğŸ”§ å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ\n",
    "\n",
    "```python\n",
    "# æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã«å¯¾æ•°ç©ºé–“ã§è¨ˆç®—\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "# E ã‚¹ãƒ†ãƒƒãƒ—\n",
    "log_resp = log_weights + log_pdf  # å¯¾æ•°è²¬ä»»ç‡ï¼ˆéæ­£è¦åŒ–ï¼‰\n",
    "log_resp = log_resp - logsumexp(log_resp, axis=1, keepdims=True)  # æ­£è¦åŒ–\n",
    "resp = np.exp(log_resp)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼\n",
    "\n",
    "#### ã‚¨ãƒ©ãƒ¼ #1: å…±åˆ†æ•£è¡Œåˆ—ã®ç‰¹ç•°æ€§\n",
    "\n",
    "```python\n",
    "# âŒ å•é¡Œ: å…±åˆ†æ•£è¡Œåˆ—ãŒç‰¹ç•°ã«ãªã‚‹\n",
    "# 1ã¤ã®æˆåˆ†ã«ãƒ‡ãƒ¼ã‚¿ãŒé›†ä¸­ã™ã‚‹ã¨ç™ºç”Ÿ\n",
    "\n",
    "# âœ… è§£æ±ºç­–: æ­£å‰‡åŒ–ã‚’è¿½åŠ \n",
    "covariance = weighted_cov + 1e-6 * np.eye(d)\n",
    "```\n",
    "\n",
    "#### ã‚¨ãƒ©ãƒ¼ #2: ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼\n",
    "\n",
    "```python\n",
    "# âŒ å•é¡Œ: ç¢ºç‡å¯†åº¦ãŒéå¸¸ã«å°ã•ããªã‚‹\n",
    "resp = weights * pdf  # ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã®å¯èƒ½æ€§\n",
    "\n",
    "# âœ… è§£æ±ºç­–: å¯¾æ•°ç©ºé–“ã§è¨ˆç®—\n",
    "log_resp = np.log(weights) + log_pdf\n",
    "log_resp = log_resp - logsumexp(log_resp, axis=1, keepdims=True)\n",
    "resp = np.exp(log_resp)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ è‡ªå·±è©•ä¾¡ã‚¯ã‚¤ã‚º\n",
    "\n",
    "### Q1: EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå¯¾æ•°å°¤åº¦ã‚’ç›´æ¥æœ€å¤§åŒ–ã›ãšã€ELBOã‚’æœ€å¤§åŒ–ã™ã‚‹ç†ç”±ã¯ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: å¯¾æ•°å°¤åº¦ã«æ½œåœ¨å¤‰æ•°ã«ã¤ã„ã¦ã®å’Œï¼ˆã¾ãŸã¯ç©åˆ†ï¼‰ãŒå«ã¾ã‚Œã‚‹ãŸã‚ã€è§£æçš„ã«æœ€å¤§åŒ–ã§ããªã„ã‹ã‚‰\n",
    "\n",
    "$$\\log p(X) = \\log \\sum_z p(X, z)$$\n",
    "\n",
    "å¯¾æ•°ã®ä¸­ã«å’ŒãŒã‚ã‚‹ã¨ã€å¾®åˆ†ã—ã¦ã‚‚é–‰å½¢å¼ã®è§£ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã€‚ELBOã‚’ä½¿ã†ã“ã¨ã§ã€ã“ã®å•é¡Œã‚’å›é¿ã§ãã¾ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q2: Eã‚¹ãƒ†ãƒƒãƒ—ã¨Mã‚¹ãƒ†ãƒƒãƒ—ã€ãã‚Œãã‚Œä½•ã‚’æœ€é©åŒ–ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**:\n",
    "\n",
    "- **E ã‚¹ãƒ†ãƒƒãƒ—**: $\\theta$ ã‚’å›ºå®šã—ã¦ã€$q(z)$ ã‚’æœ€é©åŒ–\n",
    "  - æœ€é©è§£: $q^*(z) = p(z|X, \\theta)$ï¼ˆäº‹å¾Œåˆ†å¸ƒï¼‰\n",
    "  - GMMã§ã¯è²¬ä»»ç‡ã®è¨ˆç®—ã«å¯¾å¿œ\n",
    "\n",
    "- **M ã‚¹ãƒ†ãƒƒãƒ—**: $q(z)$ ã‚’å›ºå®šã—ã¦ã€$\\theta$ ã‚’æœ€é©åŒ–\n",
    "  - å®Œå…¨ãƒ‡ãƒ¼ã‚¿ã®æœŸå¾…å¯¾æ•°å°¤åº¦ã‚’æœ€å¤§åŒ–\n",
    "  - GMMã§ã¯æ··åˆä¿‚æ•°ã€å¹³å‡ã€å…±åˆ†æ•£ã®æ›´æ–°ã«å¯¾å¿œ\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q3: EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å¿…ãšå¤§åŸŸæœ€é©è§£ã«åæŸã—ã¾ã™ã‹ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: ã„ã„ãˆã€å±€æ‰€æœ€é©è§£ã«åæŸã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™\n",
    "\n",
    "EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å¯¾æ•°å°¤åº¦ã‚’å˜èª¿ã«å¢—åŠ ã•ã›ã¾ã™ãŒã€åæŸå…ˆã¯åˆæœŸå€¤ã«ä¾å­˜ã—ã¾ã™ã€‚ãã®ãŸã‚ï¼š\n",
    "\n",
    "1. è¤‡æ•°ã®åˆæœŸå€¤ã§å®Ÿè¡Œã™ã‚‹ï¼ˆ`n_init`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰\n",
    "2. æœ€ã‚‚å¯¾æ•°å°¤åº¦ãŒé«˜ã„çµæœã‚’é¸ã¶\n",
    "\n",
    "ã¨ã„ã†æ–¹æ³•ãŒä¸€èˆ¬çš„ã§ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### Q4: VAEã®æå¤±é–¢æ•°ã¨ELBOã®é–¢ä¿‚ã¯ï¼Ÿ\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ’¡ ç­”ãˆã‚’è¦‹ã‚‹</summary>\n",
    "\n",
    "**ç­”ãˆ**: VAEã®æå¤±é–¢æ•° = -ELBO\n",
    "\n",
    "$$\\mathcal{L}_{VAE} = -\\mathbb{E}_{q(z|x)}[\\log p(x|z)] + D_{KL}(q(z|x) \\| p(z))$$\n",
    "\n",
    "- ç¬¬1é …: å†æ§‹æˆèª¤å·®ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ€ã®æ€§èƒ½ï¼‰\n",
    "- ç¬¬2é …: KLæ­£å‰‡åŒ–é …ï¼ˆæ½œåœ¨ç©ºé–“ã®æ­£å‰‡åŒ–ï¼‰\n",
    "\n",
    "ã“ã‚Œã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã¯ã€ELBOã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã¨åŒã˜ã§ã™ã€‚\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š ç·´ç¿’å•é¡Œ\n",
    "\n",
    "1. **1æ¬¡å…ƒGMM**: 1æ¬¡å…ƒã®GMMï¼ˆ2æˆåˆ†ï¼‰ã«å¯¾ã™ã‚‹EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã—ã€èº«é•·ãƒ‡ãƒ¼ã‚¿ï¼ˆç”·å¥³æ··åˆï¼‰ã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "2. **åæŸé€Ÿåº¦ã®æ¯”è¼ƒ**: ç•°ãªã‚‹åˆæœŸåŒ–æ–¹æ³•ï¼ˆãƒ©ãƒ³ãƒ€ãƒ  vs K-means++ï¼‰ã§ã®åæŸé€Ÿåº¦ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "3. **æˆåˆ†æ•°ã®æ¨å®š**: BICã‚’ä½¿ã£ã¦æœ€é©ãªæˆåˆ†æ•°ã‚’è‡ªå‹•çš„ã«é¸æŠã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… å­¦ç¿’ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n",
    "\n",
    "- [ ] KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®å®šç¾©ã¨æ€§è³ªã‚’èª¬æ˜ã§ãã‚‹\n",
    "- [ ] ELBOã¨å¯¾æ•°å°¤åº¦ã®é–¢ä¿‚ã‚’èª¬æ˜ã§ãã‚‹\n",
    "- [ ] EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®Eãƒ»Mã‚¹ãƒ†ãƒƒãƒ—ã‚’èª¬æ˜ã§ãã‚‹\n",
    "- [ ] GMMã®EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã§ãã‚‹\n",
    "- [ ] EMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨VAEã®é–¢ä¿‚ã‚’ç†è§£ã—ã¦ã„ã‚‹\n",
    "\n",
    "---\n",
    "\n",
    "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: Notebook 35ã§ã€**PyTorchåŸºç¤ã¨å‹¾é…æ³•**ã‚’å­¦ã³ã¾ã™ï¼\n",
    "\n",
    "ã“ã“ã‹ã‚‰ã¯PyTorchã‚’ä½¿ã£ãŸãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè£…ã«é€²ã¿ã¾ã™ã€‚VAEã‚„æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã®åŸºç¤ã‚’å›ºã‚ã¾ã—ã‚‡ã†ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

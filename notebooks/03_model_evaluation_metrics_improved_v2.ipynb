{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. モデル評価指標 (Model Evaluation Metrics)\n",
    "\n",
    "## 概要\n",
    "機械学習モデルの性能を正しく評価する方法を学びます。\n",
    "\n",
    "## 学習目標\n",
    "- 分類問題の評価指標を理解できる\n",
    "- 回帰問題の評価指標を理解できる\n",
    "- 混同行列とROC曲線を作成できる\n",
    "- クロスバリデーションを実行できる\n",
    "- 学習曲線を分析できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, roc_auc_score, auc,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "\n",
    "# 設定\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 分類問題の評価指標\n",
    "\n",
    "### 基本的な指標\n",
    "\n",
    "分類問題では、予測がどれだけ正確かを測る必要があります。\n",
    "\n",
    "**主な評価指標:**\n",
    "\n",
    "1. **正解率（Accuracy）**\n",
    "   - 全予測のうち、正しく分類した割合\n",
    "   - 式: (TP + TN) / (TP + TN + FP + FN)\n",
    "   - データが不均衡だと誤解を招く\n",
    "\n",
    "2. **適合率（Precision）**\n",
    "   - 陽性と予測したうち、実際に陽性だった割合\n",
    "   - 式: TP / (TP + FP)\n",
    "   - 偽陽性を減らしたい場合に重視\n",
    "\n",
    "3. **再現率（Recall）**\n",
    "   - 実際の陽性のうち、正しく予測できた割合\n",
    "   - 式: TP / (TP + FN)\n",
    "   - 偽陰性を減らしたい場合に重視\n",
    "\n",
    "4. **F1スコア**\n",
    "   - PrecisionとRecallの調和平均\n",
    "   - 式: 2 × (Precision × Recall) / (Precision + Recall)\n",
    "   - バランスの取れた指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類データ生成\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.7, 0.3],  # 不均衡データ\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# モデル学習\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 予測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 評価指標の計算\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"分類評価指標:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nクラス分布（テスト）: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 混同行列（Confusion Matrix）\n",
    "\n",
    "### 混同行列とは\n",
    "\n",
    "予測と実際のクラスの関係を表にしたものです。\n",
    "\n",
    "```\n",
    "                予測\n",
    "          Negative  Positive\n",
    "実際 Neg     TN        FP\n",
    "     Pos     FN        TP\n",
    "```\n",
    "\n",
    "- **TP (True Positive)**: 正しく陽性と予測\n",
    "- **TN (True Negative)**: 正しく陰性と予測\n",
    "- **FP (False Positive)**: 間違って陽性と予測（第1種の誤り）\n",
    "- **FN (False Negative)**: 間違って陰性と予測（第2種の誤り）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列の計算と可視化\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"混同行列:\")\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negatives:  {cm[0, 0]}\")\n",
    "print(f\"False Positives: {cm[0, 1]}\")\n",
    "print(f\"False Negatives: {cm[1, 0]}\")\n",
    "print(f\"True Positives:  {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詳細な分類レポート\n",
    "print(\"\\n詳細な分類レポート:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ROC曲線とAUC\n",
    "\n",
    "### ROC曲線とは\n",
    "\n",
    "**ROC (Receiver Operating Characteristic) 曲線**は、分類器の性能を可視化する方法です。\n",
    "\n",
    "- X軸: 偽陽性率（False Positive Rate） = FP / (FP + TN)\n",
    "- Y軸: 真陽性率（True Positive Rate） = TP / (TP + FN)\n",
    "\n",
    "### AUC (Area Under the Curve)\n",
    "\n",
    "ROC曲線の下の面積です。\n",
    "\n",
    "- **AUC = 1.0**: 完璧な分類器\n",
    "- **AUC = 0.5**: ランダムな分類器\n",
    "- **AUC < 0.5**: ランダムより悪い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC曲線の計算\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 回帰問題の評価指標\n",
    "\n",
    "### 主な評価指標\n",
    "\n",
    "回帰問題では、予測値と実際の値の誤差を測定します。\n",
    "\n",
    "1. **平均二乗誤差（MSE: Mean Squared Error）**\n",
    "   - 式: Σ(y_true - y_pred)² / n\n",
    "   - 大きな誤差に敏感\n",
    "   - 単位が元のデータの二乗\n",
    "\n",
    "2. **平均二乗平方根誤差（RMSE: Root Mean Squared Error）**\n",
    "   - 式: √MSE\n",
    "   - 元のデータと同じ単位\n",
    "   - 解釈しやすい\n",
    "\n",
    "3. **平均絶対誤差（MAE: Mean Absolute Error）**\n",
    "   - 式: Σ|y_true - y_pred| / n\n",
    "   - 外れ値に頑健\n",
    "\n",
    "4. **決定係数（R²: R-squared）**\n",
    "   - 式: 1 - (SS_res / SS_tot)\n",
    "   - 0〜1の範囲（負の値も可能）\n",
    "   - 1に近いほど良い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回帰データ生成\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    noise=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# データ分割\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# モデル学習\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# 予測\n",
    "y_pred_reg = reg_model.predict(X_test_reg)\n",
    "\n",
    "# 評価指標の計算\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"回帰評価指標:\")\n",
    "print(f\"  MSE:  {mse:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値 vs 実測値のプロット\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_reg, y_pred_reg, alpha=0.6, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
    "         [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title(f'Predictions vs True Values (R²={r2:.3f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test_reg - y_pred_reg\n",
    "plt.scatter(y_pred_reg, residuals, alpha=0.6, edgecolors='k', linewidth=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. クロスバリデーション\n",
    "\n",
    "### クロスバリデーションとは\n",
    "\n",
    "データを複数の分割（フォールド）に分け、それぞれを順番にテストデータとして使用する手法です。\n",
    "\n",
    "**利点:**\n",
    "- より信頼性の高い評価\n",
    "- データの使用効率が良い\n",
    "- 過学習の検出\n",
    "\n",
    "### k-Fold Cross Validation\n",
    "\n",
    "データをk個に分割し、k回の訓練・評価を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 複数の指標でクロスバリデーション\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model, X, y, cv=5, scoring=scoring, return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"5-Fold Cross Validation Results:\")\n",
    "print(\"=\"*50)\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "    train_scores = cv_results[f'train_{metric}']\n",
    "    test_scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.capitalize()}:\")\n",
    "    print(f\"  Train: {train_scores.mean():.4f} (+/- {train_scores.std():.4f})\")\n",
    "    print(f\"  Test:  {test_scores.mean():.4f} (+/- {test_scores.std():.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーションスコアの可視化\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "train_means = [cv_results[f'train_{m}'].mean() for m in metrics]\n",
    "test_means = [cv_results[f'test_{m}'].mean() for m in metrics]\n",
    "train_stds = [cv_results[f'train_{m}'].std() for m in metrics]\n",
    "test_stds = [cv_results[f'test_{m}'].std() for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x - width/2, train_means, width, yerr=train_stds, \n",
    "        label='Train', alpha=0.8, capsize=5)\n",
    "plt.bar(x + width/2, test_means, width, yerr=test_stds, \n",
    "        label='Test', alpha=0.8, capsize=5)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Cross-Validation Scores')\n",
    "plt.xticks(x, [m.capitalize() for m in metrics])\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 学習曲線\n",
    "\n",
    "### 学習曲線とは\n",
    "\n",
    "訓練データサイズを変えながら、モデルの性能がどう変化するかを示す曲線です。\n",
    "\n",
    "**学習曲線から分かること:**\n",
    "- 過学習の有無\n",
    "- データ量が十分か\n",
    "- モデルの複雑さは適切か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の計算\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# 平均と標準偏差の計算\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='b', label='Training score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.2, color='b')\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='r', label='Cross-validation score')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, \n",
    "                 alpha=0.2, color='r')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"学習曲線の解釈:\")\n",
    "if train_mean[-1] - test_mean[-1] > 0.1:\n",
    "    print(\"  ⚠ 過学習の可能性があります\")\n",
    "    print(\"  対策: 正則化の強化、モデルの簡略化、データの追加\")\n",
    "elif test_mean[-1] < 0.7:\n",
    "    print(\"  ⚠ 学習不足の可能性があります\")\n",
    "    print(\"  対策: モデルの複雑化、特徴量の追加、学習時間の延長\")\n",
    "else:\n",
    "    print(\"  ✓ 良好な学習状態です\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. まとめ\n",
    "\n",
    "### 本ノートブックで学んだこと\n",
    "\n",
    "1. **分類評価指標**\n",
    "   - Accuracy、Precision、Recall、F1スコア\n",
    "   - それぞれの使い分け\n",
    "\n",
    "2. **混同行列**\n",
    "   - TP、TN、FP、FNの理解\n",
    "   - 誤り のタイプの分析\n",
    "\n",
    "3. **ROC曲線とAUC**\n",
    "   - 分類器の性能可視化\n",
    "   - 閾値の調整\n",
    "\n",
    "4. **回帰評価指標**\n",
    "   - MSE、RMSE、MAE、R²\n",
    "   - 残差分析\n",
    "\n",
    "5. **クロスバリデーション**\n",
    "   - k-Fold CV\n",
    "   - より信頼性の高い評価\n",
    "\n",
    "6. **学習曲線**\n",
    "   - 過学習/学習不足の検出\n",
    "   - データ量の十分性の確認\n",
    "\n",
    "### 評価指標の選び方\n",
    "\n",
    "**分類問題:**\n",
    "- バランスの取れたデータ → Accuracy\n",
    "- 不均衡データ → F1、AUC\n",
    "- 偽陽性を減らしたい → Precision\n",
    "- 偽陰性を減らしたい → Recall\n",
    "\n",
    "**回帰問題:**\n",
    "- 一般的な用途 → RMSE\n",
    "- 外れ値に頑健 → MAE\n",
    "- モデルの説明力 → R²\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "- Notebook 04以降で具体的なモデルを学ぶ\n",
    "- 実際のデータセットで評価を実践\n",
    "- より高度な評価手法を探求"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
